{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e4be09ca3cc42afa0076edb237af35e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ba62082f070143c282656b6479ada387",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,977/250,000 \u001b[0m [ \u001b[33m0:15:33\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m318 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,977/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:15:33</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">318 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ba62082f070143c282656b6479ada387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1355937c6444a796c366f03ac5454d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_99dbbc36751040e6b193f87875433516",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,961/250,000 \u001b[0m [ \u001b[33m0:14:21\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m396 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,961/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:14:21</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">396 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "99dbbc36751040e6b193f87875433516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4aba92ae7004c789765fa8476a45db2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5b2254932b8344a4b05096574fa9db61",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,955/250,000 \u001b[0m [ \u001b[33m0:17:21\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m295 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,955/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:17:21</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">295 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "5b2254932b8344a4b05096574fa9db61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118f1666805b4808a4b6ed8bed7cee2d": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_fee621e3a4af4b8fa66e971402d58b46",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,999/250,000 \u001b[0m [ \u001b[33m1:02:57\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m73 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,999/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:02:57</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">73 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "fee621e3a4af4b8fa66e971402d58b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249fa69b69084c29a5393aff168209a4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_93f4c5ca18eb4d06a06965bab604121c",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250,000/250,000 \u001b[0m [ \u001b[33m1:06:06\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m43 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">250,000/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:06:06</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">43 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "93f4c5ca18eb4d06a06965bab604121c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b050b1abb84d47669f437f4a868af0d7": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7415cc88832d4e84a2ef894453a15dc8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,996/250,000 \u001b[0m [ \u001b[33m1:03:33\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m72 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,996/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:03:33</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">72 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "7415cc88832d4e84a2ef894453a15dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68d7d2e36bc41ada3b5d9b9d671a4db": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_35d7658e1b314d88b4ff3f5026e21d18",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,993/250,000 \u001b[0m [ \u001b[33m1:06:25\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m65 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,993/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:06:25</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">65 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "35d7658e1b314d88b4ff3f5026e21d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a39ec12f4364d129b1af30b2df450e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47b4eb8c436d4ef4a56cd231a5fde9c5",
              "IPY_MODEL_e237cfdde8864b0091b0338a6fbb7897",
              "IPY_MODEL_ac0fa7b246b94a30a15b811dc57b5f69"
            ],
            "layout": "IPY_MODEL_6b363522e6144e81835fe33b21b0f7ff"
          }
        },
        "47b4eb8c436d4ef4a56cd231a5fde9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eaff2fb330247308753a097399edb77",
            "placeholder": "​",
            "style": "IPY_MODEL_c8264842c9e240ff9bd92bbb97ae3533",
            "value": "Training HAC (no_her): 100%"
          }
        },
        "e237cfdde8864b0091b0338a6fbb7897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ce268efe714439384f9d753e70c7a08",
            "max": 250000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0dfc7d422e24f94995b905a39180766",
            "value": 250000
          }
        },
        "ac0fa7b246b94a30a15b811dc57b5f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb01a6677a1947c2b1ba7128ccff0f9d",
            "placeholder": "​",
            "style": "IPY_MODEL_ab09c87826784732b53f565d14e7902d",
            "value": " 250000/250000 [1:19:47&lt;00:00, 24.87it/s, success=0.0%, best=0.0%]"
          }
        },
        "6b363522e6144e81835fe33b21b0f7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eaff2fb330247308753a097399edb77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8264842c9e240ff9bd92bbb97ae3533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ce268efe714439384f9d753e70c7a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dfc7d422e24f94995b905a39180766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb01a6677a1947c2b1ba7128ccff0f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab09c87826784732b53f565d14e7902d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed17eaa1d9ff45d28009653339beadea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e21f6a0ec7b4864921690fce0373b23",
              "IPY_MODEL_3b7c4d7fd95848ad85175037996fe5c2",
              "IPY_MODEL_db58788c6a4244b5a85c30df31940e85"
            ],
            "layout": "IPY_MODEL_945693fd95f941aaa4d385fcc9f2d2da"
          }
        },
        "6e21f6a0ec7b4864921690fce0373b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95a40b64f1d42ee8fdc21b8cdff729d",
            "placeholder": "​",
            "style": "IPY_MODEL_53d8f912b5dd46a3a84a83cfc3de6c5a",
            "value": "Training HAC (with_her): 100%"
          }
        },
        "3b7c4d7fd95848ad85175037996fe5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef8180d9c7c4e00ab48e845e56e223a",
            "max": 250000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d600a384997e407ea7624c22a9cb0070",
            "value": 250000
          }
        },
        "db58788c6a4244b5a85c30df31940e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8575ecedced4490e8c5a56f5ce032d52",
            "placeholder": "​",
            "style": "IPY_MODEL_c3c940075ef74b118471b40295d4b0ff",
            "value": " 250000/250000 [1:19:45&lt;00:00, 56.36it/s, success=0.0%, best=0.0%]"
          }
        },
        "945693fd95f941aaa4d385fcc9f2d2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95a40b64f1d42ee8fdc21b8cdff729d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d8f912b5dd46a3a84a83cfc3de6c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef8180d9c7c4e00ab48e845e56e223a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d600a384997e407ea7624c22a9cb0070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8575ecedced4490e8c5a56f5ce032d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c940075ef74b118471b40295d4b0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0fc6c246c24d9f957447f715db8daa": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a1e2e2e4f1e042eaa7f7283beb910bc2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,999/250,000 \u001b[0m [ \u001b[33m2:18:53\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m217 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,999/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">2:18:53</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">217 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a1e2e2e4f1e042eaa7f7283beb910bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1006c9a3dffd4244acbfe4ba7f49c46b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_02e5de24fc314cbaaf65b301335bedcc",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,999/250,000 \u001b[0m [ \u001b[33m2:17:47\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m235 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,999/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">2:17:47</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">235 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "02e5de24fc314cbaaf65b301335bedcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcef836c5a46416fbdc65f616f7cde95": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cb83f85c67634eddb67fc9a4d2208e4b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250,000/250,000 \u001b[0m [ \u001b[33m2:21:57\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">250,000/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">2:21:57</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "cb83f85c67634eddb67fc9a4d2208e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0837e93eec144e4ca599f6916e46107f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_57fd1910e56e47deab1d44b46a276777",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m249,999/250,000 \u001b[0m [ \u001b[33m3:50:48\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m44 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">249,999/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">3:50:48</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">44 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "57fd1910e56e47deab1d44b46a276777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4a563835554606b89111bc165a5033": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0c9b2797044342669203413825346663",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250,000/250,000 \u001b[0m [ \u001b[33m2:59:53\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">250,000/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">2:59:53</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0c9b2797044342669203413825346663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276a25043691493caf6ac094fe4127c0": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_11f74208b1be4c789cfd5a1b420ae472",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m  46%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114,999/250,000 \u001b[0m [ \u001b[33m1:44:09\u001b[0m < \u001b[36m0:50:20\u001b[0m , \u001b[31m45 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">  46%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">114,999/250,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:44:09</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:50:20</span> , <span style=\"color: #800000; text-decoration-color: #800000\">45 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "11f74208b1be4c789cfd5a1b420ae472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k78LDWv-NIud"
      },
      "outputs": [],
      "source": [
        "    # HIERARCHICAL REINFORCEMENT LEARNING FOR SPARSE-REWARD NAVIGATION\n",
        "# PointMaze with DQN, HER, and HAC\n",
        "\n",
        "# # Hierarchical Reinforcement Learning for Sparse-Reward Navigation\n",
        "# ## PointMaze with DQN, HER, and HAC\n",
        "#\n",
        "# **Project Structure:**\n",
        "# - **Tier 1**: DQN backbone with discrete actions and clean training/evaluation pipeline\n",
        "# - **Tier 2**: Goal-conditioning + HER with ablation studies\n",
        "# - **Tier 3**: HAC-style Hierarchical RL for long-horizon navigation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# INSTALLATION CELL\n",
        "# ============================================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install gymnasium[mujoco] gymnasium-robotics stable-baselines3 sb3-contrib tensorboard matplotlib pandas seaborn tqdm moviepy imageio --quiet\n",
        "\n",
        "# For rendering in Colab - install EGL support\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq xvfb ffmpeg libegl1-mesa-dev libgl1-mesa-dev libgles2-mesa-dev > /dev/null 2>&1\n",
        "!pip install pyvirtualdisplay --quiet\n",
        "\n",
        "# Set environment variables for MuJoCo EGL rendering\n",
        "import os\n",
        "os.environ['MUJOCO_GL'] = 'egl'\n",
        "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
        "\n",
        "print(\"✓ Installation complete!\")\n",
        "print(\"✓ MuJoCo EGL rendering configured\")\n"
      ],
      "metadata": {
        "id": "c8EWUlHFNPTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77288669-395e-4126-fefc-91f5195bd845"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.5/852.5 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "✓ Installation complete!\n",
            "✓ MuJoCo EGL rendering configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# IMPORTS AND CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# === CRITICAL: Set MuJoCo rendering backend BEFORE any imports ===\n",
        "import os\n",
        "os.environ['MUJOCO_GL'] = 'egl'\n",
        "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
        "\n",
        "import gymnasium as gym\n",
        "import gymnasium_robotics\n",
        "from gymnasium.wrappers import RecordEpisodeStatistics\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from collections import deque, defaultdict\n",
        "from typing import Dict, List, Tuple, Optional, Any, Union, Callable\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Stable Baselines 3\n",
        "from stable_baselines3 import DQN, SAC\n",
        "from stable_baselines3.common.buffers import ReplayBuffer, DictReplayBuffer\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.her import HerReplayBuffer\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "# SB3-Contrib for TQC\n",
        "from sb3_contrib import TQC\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import HTML, display, clear_output\n",
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "# Video recording\n",
        "try:\n",
        "    from gymnasium.wrappers import RecordVideo\n",
        "    VIDEO_RECORDING_AVAILABLE = True\n",
        "except ImportError:\n",
        "    VIDEO_RECORDING_AVAILABLE = False\n",
        "    print(\"Warning: RecordVideo wrapper not available\")\n",
        "\n",
        "# Virtual display for headless rendering (Colab)\n",
        "try:\n",
        "    from pyvirtualdisplay import Display\n",
        "    virtual_display = Display(visible=0, size=(1400, 900))\n",
        "    virtual_display.start()\n",
        "    print(\"✓ Virtual display started for rendering\")\n",
        "except Exception as e:\n",
        "    print(f\"Virtual display not available: {e}\")\n",
        "\n",
        "# Device configuration\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✓ Using device: {DEVICE}\")\n",
        "\n",
        "# Gymnasium robotics registration\n",
        "gym.register_envs(gymnasium_robotics)\n",
        "print(\"✓ Gymnasium-Robotics environments registered\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyE08DTeNbaT",
        "outputId": "f484c6ba-6c70-463a-dc8b-c2a540a56ca1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Virtual display started for rendering\n",
            "✓ Using device: cuda\n",
            "✓ Gymnasium-Robotics environments registered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAZE CONFIGURATIONS\n",
        "# ============================================================================\n",
        "\n",
        "# Define maze configurations for experiments\n",
        "MAZE_CONFIGS = {\n",
        "    'small': {\n",
        "        'env_id': 'PointMaze_UMaze-v3',\n",
        "        'name': 'Small (UMaze)',\n",
        "        'max_episode_steps': 1000,\n",
        "        'subgoal_range_x': (-0.5, 5.5),  # Add margin for noise\n",
        "        'subgoal_range_y': (-0.5, 5.5),\n",
        "        'subgoal_period_k': 15,\n",
        "    },\n",
        "    'large': {\n",
        "        'env_id': 'PointMaze_Large-v3',\n",
        "        'name': 'Large',\n",
        "        'max_episode_steps': 10000,\n",
        "        'subgoal_range_x': (-0.5, 12.5),  # 12 columns\n",
        "        'subgoal_range_y': (-0.5, 9.5),   # 9 rows\n",
        "        'subgoal_period_k': 30,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✓ Maze configurations defined\")\n",
        "print(f\"  Small: {MAZE_CONFIGS['small']['env_id']}, K={MAZE_CONFIGS['small']['subgoal_period_k']}\")\n",
        "print(f\"  Large: {MAZE_CONFIGS['large']['env_id']}, K={MAZE_CONFIGS['large']['subgoal_period_k']}\")\n",
        "\n",
        "env = gym.make('PointMaze_Large-v3')\n",
        "for _ in range(100):\n",
        "    obs, _ = env.reset()\n",
        "    print(f\"Goal: {obs['desired_goal']}, Agent: {obs['achieved_goal']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE_rujx1rIOX",
        "outputId": "37104f6e-ab41-4738-e31a-2f5ae04dc76b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Maze configurations defined\n",
            "  Small: PointMaze_UMaze-v3, K=15\n",
            "  Large: PointMaze_Large-v3, K=30\n",
            "Goal: [0.63816989 2.09880119], Agent: [0.29512354 1.03547452]\n",
            "Goal: [-3.73278119 -2.86291071], Agent: [-2.2582964   0.97063479]\n",
            "Goal: [ 4.36884619 -0.84270338], Agent: [-3.45634769 -1.14221258]\n",
            "Goal: [0.25083709 2.94143897], Agent: [1.68996381 2.93087417]\n",
            "Goal: [ 0.3310573  -2.07129654], Agent: [-4.62788167  1.14421808]\n",
            "Goal: [2.27204214 3.13581523], Agent: [4.41320113 1.98275399]\n",
            "Goal: [-2.63439774  0.95884511], Agent: [ 3.62436534 -0.82519762]\n",
            "Goal: [-4.36276404 -3.00536897], Agent: [-3.54463308 -3.15588158]\n",
            "Goal: [0.72982642 2.77495494], Agent: [-4.32472292  0.11104339]\n",
            "Goal: [ 4.40838569 -0.76520801], Agent: [3.59451213 2.837149  ]\n",
            "Goal: [-0.32249804  0.90759788], Agent: [-4.3474648   1.15125564]\n",
            "Goal: [1.4916446  3.21525505], Agent: [-4.53985856  0.07958344]\n",
            "Goal: [ 1.36253305 -0.9139972 ], Agent: [-3.41913921 -1.9083425 ]\n",
            "Goal: [ 3.47244656 -2.78507505], Agent: [-1.55665101 -0.93246847]\n",
            "Goal: [ 3.53505156 -1.12372716], Agent: [-4.66978213 -1.22657203]\n",
            "Goal: [4.39201979 2.98004795], Agent: [3.37325248 3.06165339]\n",
            "Goal: [2.55864783 2.06431733], Agent: [ 1.34624236 -0.89377647]\n",
            "Goal: [-4.26153472  0.18785655], Agent: [ 4.34395491 -3.22051314]\n",
            "Goal: [-2.27781519  2.96421213], Agent: [-3.74397829  0.8114454 ]\n",
            "Goal: [ 3.52942381 -2.99714532], Agent: [0.40568505 2.76753019]\n",
            "Goal: [2.51857448 0.78955149], Agent: [-4.4596117   0.19030802]\n",
            "Goal: [0.53515154 1.04034502], Agent: [4.27942513 3.23245844]\n",
            "Goal: [-4.6151841   2.78289533], Agent: [-4.5379845  -2.89108328]\n",
            "Goal: [ 1.4471602  -0.93504634], Agent: [0.58412997 1.16086199]\n",
            "Goal: [3.51994804 1.08160583], Agent: [-4.45525763  3.07474652]\n",
            "Goal: [-4.31161944  1.04990766], Agent: [-3.46599573 -3.15323618]\n",
            "Goal: [-4.29871731 -2.97211986], Agent: [-4.40690547 -0.05790539]\n",
            "Goal: [-4.4719056   1.08467294], Agent: [2.317801   1.02998977]\n",
            "Goal: [-3.55117369  0.88285527], Agent: [ 4.26418134 -0.80914498]\n",
            "Goal: [-1.64306283  2.75672841], Agent: [-4.52151108  0.99757234]\n",
            "Goal: [ 4.50147012 -2.83716123], Agent: [-3.27556954  3.09291559]\n",
            "Goal: [4.34020975 2.83252962], Agent: [-3.5228676  -3.24727801]\n",
            "Goal: [ 1.58895188 -1.12991916], Agent: [-1.5542583  -1.91865975]\n",
            "Goal: [-4.55868411 -3.19963265], Agent: [ 0.67506381 -2.77706378]\n",
            "Goal: [-3.67794771  0.92206132], Agent: [ 0.62612377 -0.83081668]\n",
            "Goal: [-3.51312115 -0.75485578], Agent: [-1.3541891  -0.99192478]\n",
            "Goal: [-1.25881614  0.82409286], Agent: [ 3.53056835 -3.042407  ]\n",
            "Goal: [ 3.42865868 -2.83490849], Agent: [-4.61447849  0.89916783]\n",
            "Goal: [-4.57778411  0.15624131], Agent: [-0.43635146 -3.21933261]\n",
            "Goal: [4.40386658 1.87497617], Agent: [-1.26349633  2.23344592]\n",
            "Goal: [0.54364105 2.12670014], Agent: [3.57385348 1.08277022]\n",
            "Goal: [ 0.39706228 -1.83049624], Agent: [-3.51818041 -2.80216452]\n",
            "Goal: [-3.37555911 -1.2230077 ], Agent: [ 0.62494055 -1.82621558]\n",
            "Goal: [0.71627945 1.93526353], Agent: [1.34056908 2.90584407]\n",
            "Goal: [ 1.40970643 -0.77803777], Agent: [2.39061008 2.18388617]\n",
            "Goal: [ 0.53745017 -1.75451164], Agent: [-2.72457486  0.98948345]\n",
            "Goal: [-4.62440132 -1.04258866], Agent: [-0.71128545 -2.9057262 ]\n",
            "Goal: [ 0.44843158 -3.23177579], Agent: [ 4.7261098  -0.09688588]\n",
            "Goal: [0.38814901 0.75970112], Agent: [-0.65126343  1.21162316]\n",
            "Goal: [-1.64246181  2.76786714], Agent: [-1.48968671  2.12298122]\n",
            "Goal: [-1.32320431  2.79994886], Agent: [-1.45480193 -1.15967737]\n",
            "Goal: [-0.54460671 -2.77591897], Agent: [-1.65991925 -2.909952  ]\n",
            "Goal: [-1.48631052  1.18166097], Agent: [4.62457005 3.21004178]\n",
            "Goal: [-1.74882336  1.94005965], Agent: [-3.33427399 -1.75343539]\n",
            "Goal: [3.62031029 0.84620908], Agent: [-1.46483143  1.94896503]\n",
            "Goal: [-0.52640879  0.95904663], Agent: [ 1.58921794 -1.05097264]\n",
            "Goal: [ 4.56054833 -2.97107649], Agent: [-0.59711409  1.09332197]\n",
            "Goal: [-1.5016084  -0.92969826], Agent: [ 0.25769301 -0.91083177]\n",
            "Goal: [3.35176625 0.86427977], Agent: [-1.36991083 -2.87286643]\n",
            "Goal: [ 4.38227461 -0.03256563], Agent: [-1.41022982 -1.90146329]\n",
            "Goal: [ 3.44109436 -3.13287908], Agent: [-0.34829803 -3.24763991]\n",
            "Goal: [-1.25823301 -0.86351878], Agent: [-2.28557598  3.12024997]\n",
            "Goal: [4.48067805 1.16892274], Agent: [4.4675535  2.75532007]\n",
            "Goal: [-1.6917149  -2.13106941], Agent: [ 2.62628152 -0.8787551 ]\n",
            "Goal: [ 0.29898168 -1.19995737], Agent: [ 1.3782819  -0.94623208]\n",
            "Goal: [-3.73491908  2.79649785], Agent: [4.5204117  1.23903798]\n",
            "Goal: [ 4.43035116 -3.04526708], Agent: [ 2.39176467 -3.22309548]\n",
            "Goal: [1.56166999 3.11095876], Agent: [2.33090301 2.20933967]\n",
            "Goal: [2.39805922 2.12085051], Agent: [-2.41914187  1.09657105]\n",
            "Goal: [-4.27420166  0.91494221], Agent: [3.55743314 3.0589281 ]\n",
            "Goal: [-3.35706629 -1.85012624], Agent: [ 1.60554066 -0.94657481]\n",
            "Goal: [4.60122491 0.83550937], Agent: [ 4.67701036 -1.08982294]\n",
            "Goal: [-4.73073122 -1.0479564 ], Agent: [-1.3066244  -1.22523394]\n",
            "Goal: [-3.73926577 -2.77331536], Agent: [4.35348463 1.77538238]\n",
            "Goal: [ 0.47249778 -0.06455878], Agent: [-4.38509733 -1.03469715]\n",
            "Goal: [2.71697228 2.23826162], Agent: [ 0.38115428 -1.19365749]\n",
            "Goal: [ 2.59182564 -1.00150409], Agent: [4.45742381 3.11731785]\n",
            "Goal: [ 4.61400576 -2.96513986], Agent: [-1.40880705 -2.785819  ]\n",
            "Goal: [0.70310344 0.89365608], Agent: [4.42282744 3.04176376]\n",
            "Goal: [0.36696072 1.16330845], Agent: [ 4.61978458 -3.05023772]\n",
            "Goal: [4.4231669  1.88597461], Agent: [2.63604105 1.06493946]\n",
            "Goal: [-2.62194297  0.81753493], Agent: [2.68199728 2.05620292]\n",
            "Goal: [-4.46820185  2.76760941], Agent: [-1.64614253  0.88620431]\n",
            "Goal: [3.3773867  3.15068525], Agent: [1.6328839  2.92181676]\n",
            "Goal: [0.31536463 2.78985235], Agent: [-4.42420752  2.7995803 ]\n",
            "Goal: [ 2.73052467 -0.7633676 ], Agent: [-2.54978829  1.23363287]\n",
            "Goal: [-1.38713466 -2.93506451], Agent: [ 3.40549564 -0.76130713]\n",
            "Goal: [-3.7145698   0.81835093], Agent: [-3.61985301 -3.16851856]\n",
            "Goal: [ 4.42925671 -2.81053281], Agent: [-3.47855411  2.91366544]\n",
            "Goal: [-1.58399556  2.8594865 ], Agent: [-3.27339927  1.16300651]\n",
            "Goal: [-4.50285492  2.96570108], Agent: [ 3.52983499 -2.86239792]\n",
            "Goal: [-3.32017209  0.82316311], Agent: [-0.67239766  0.98360024]\n",
            "Goal: [-1.44314644 -2.87114021], Agent: [ 2.52148801 -1.84807635]\n",
            "Goal: [4.28991282 1.92711452], Agent: [-3.54163106 -1.18346286]\n",
            "Goal: [0.50768742 1.17053945], Agent: [ 2.56626184 -3.19442273]\n",
            "Goal: [ 1.72731577 -0.96768427], Agent: [-4.68026998  2.87799336]\n",
            "Goal: [ 2.25399554 -1.97276872], Agent: [-3.52816351  2.94781995]\n",
            "Goal: [ 4.35561031 -0.21555289], Agent: [2.42495665 2.1713186 ]\n",
            "Goal: [0.69395108 2.84335348], Agent: [ 1.45090733 -0.79648552]\n",
            "Goal: [-4.49414499  0.24234232], Agent: [-1.49952605  2.93820898]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXPERIMENT CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# [FAST MODE] Set to True for progress report (faster training, 1 seed)\n",
        "# [FULL MODE] Set to False for final report (full training, 3+ seeds)\n",
        "# =============================================================================\n",
        "FAST_MODE = True\n",
        "\n",
        "@dataclass\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Central configuration for all experiments.\"\"\"\n",
        "\n",
        "    # === Environment Settings (will be overridden per maze) ===\n",
        "    maze_map: str = \"PointMaze_Large-v3\"\n",
        "    maze_size: str = \"large\"  # 'small' or 'large'\n",
        "    max_episode_steps: int = 1000\n",
        "    continuing_task: bool = False\n",
        "\n",
        "    # === Discrete Action Settings (for DQN only) ===\n",
        "    n_discrete_actions: int = 4  # up, down, left, right\n",
        "    action_magnitude: float = 1.0\n",
        "\n",
        "    # === Continuous Action Settings (for HAC) ===\n",
        "    action_dim: int = 2  # Continuous action dimension for PointMaze\n",
        "    action_scale: float = 1.0  # Max action magnitude\n",
        "\n",
        "    # === Training Settings ===\n",
        "    total_timesteps: int = 250_000 if FAST_MODE else 500_000\n",
        "    learning_rate: float = 1e-3\n",
        "    buffer_size: int = 250_000 if FAST_MODE else 500_000\n",
        "    batch_size: int = 256\n",
        "    learning_starts: int = 10000\n",
        "    tau: float = 0.005\n",
        "    gamma: float = 0.99\n",
        "    train_freq: int = 4\n",
        "    gradient_steps: int = 1\n",
        "\n",
        "    # === DQN-Specific Settings ===\n",
        "    exploration_fraction: float = 0.5\n",
        "    exploration_initial_eps: float = 1.0\n",
        "    exploration_final_eps: float = 0.1\n",
        "    target_update_interval: int = 1000\n",
        "\n",
        "    # === HER Settings ===\n",
        "    her_strategy: str = \"future\"\n",
        "    her_n_sampled_goal: int = 4\n",
        "\n",
        "    # === HAC (Hierarchical) Settings ===\n",
        "    subgoal_period_k: int = 15\n",
        "    subgoal_dim: int = 2\n",
        "    subgoal_range_x: Tuple[float, float] = (-0.5, 8.5)\n",
        "    subgoal_range_y: Tuple[float, float] = (-0.5, 8.5)\n",
        "    high_level_lr: float = 3e-4\n",
        "    low_level_lr: float = 3e-4\n",
        "\n",
        "    # === HAC Reward Scaling ===\n",
        "    high_reward_scale: float = 1.0  # Scale for high-level rewards\n",
        "    low_reward_scale: float = 1.0   # Scale for low-level rewards\n",
        "    subgoal_test_penalty_scale: float = 1.0  # Penalty = -1.0 * scale (not -K!)\n",
        "\n",
        "    # === TD3 Settings for continuous low-level ===\n",
        "    policy_noise: float = 0.2\n",
        "    noise_clip: float = 0.5\n",
        "    policy_delay: int = 2\n",
        "    exploration_noise: float = 0.1\n",
        "\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # === Evaluation Settings ===\n",
        "    eval_freq: int = 5_000\n",
        "    n_eval_episodes: int = 20 if FAST_MODE else 50\n",
        "    deterministic_eval: bool = True\n",
        "\n",
        "    # === Reward Settings ===\n",
        "    use_dense_reward: bool = True\n",
        "    success_threshold: float = 0.5\n",
        "    subgoal_threshold: float = 0.5\n",
        "\n",
        "    # === Reproducibility ===\n",
        "    seeds: List[int] = field(default_factory=lambda: [42] if FAST_MODE else [42, 123, 456])\n",
        "\n",
        "    # === Network Architecture ===\n",
        "    policy_kwargs: Dict = field(default_factory=lambda: {\n",
        "        \"net_arch\": [256, 256]\n",
        "    })\n",
        "\n",
        "    # === Logging ===\n",
        "    log_dir: str = \"./logs\"\n",
        "    save_models: bool = True\n",
        "\n",
        "    def update_for_maze(self, maze_size: str):\n",
        "        \"\"\"Update config for specific maze size.\"\"\"\n",
        "        maze_cfg = MAZE_CONFIGS[maze_size]\n",
        "        self.maze_size = maze_size\n",
        "        self.maze_map = maze_cfg['env_id']\n",
        "        self.max_episode_steps = maze_cfg['max_episode_steps']\n",
        "        self.subgoal_range_x = maze_cfg['subgoal_range_x']\n",
        "        self.subgoal_range_y = maze_cfg['subgoal_range_y']\n",
        "        self.subgoal_period_k = maze_cfg['subgoal_period_k']\n",
        "        return self\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        d = asdict(self)\n",
        "        d['seeds'] = list(d['seeds'])\n",
        "        return d\n",
        "\n",
        "\n",
        "# Create default config\n",
        "config = ExperimentConfig()\n",
        "print(f\"\\n✓ Configuration loaded (FAST_MODE={FAST_MODE})\")\n",
        "print(f\"  Total timesteps: {config.total_timesteps:,}\")\n",
        "print(f\"  Seeds: {config.seeds}\")\n",
        "print(f\"  Action scale: {config.action_scale} (PointMaze expects [-1, 1])\")\n",
        "print(f\"  Max grad norm: {config.max_grad_norm}\")\n",
        "\n",
        "test_env = gym.make('PointMaze_UMaze-v3')\n",
        "env_threshold = getattr(test_env.unwrapped, 'goal_distance_threshold', 'unknown')\n",
        "print(f\"  Environment's goal_distance_threshold: {env_threshold}\")\n",
        "print(f\"  Config success_threshold: {config.success_threshold}\")\n",
        "if env_threshold != 'unknown' and abs(env_threshold - config.success_threshold) > 0.01:\n",
        "    print(\"  ⚠️ WARNING: Threshold mismatch!\")\n",
        "test_env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL_oVYU3Nc0k",
        "outputId": "b628ebc0-e78d-47ed-9a11-0bf9f6705cac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Configuration loaded (FAST_MODE=True)\n",
            "  Total timesteps: 250,000\n",
            "  Seeds: [42]\n",
            "  Action scale: 1.0 (PointMaze expects [-1, 1])\n",
            "  Max grad norm: 1.0\n",
            "  Environment's goal_distance_threshold: unknown\n",
            "  Config success_threshold: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DISCRETE ACTION WRAPPER (FOR DQN ONLY)\n",
        "# ============================================================================\n",
        "\n",
        "class DiscreteActionWrapper(gym.ActionWrapper):\n",
        "    \"\"\"\n",
        "    Converts continuous action space to discrete.\n",
        "    ONLY used for DQN-based methods, NOT for HAC.\n",
        "\n",
        "    Actions:\n",
        "    0: Up (+y)\n",
        "    1: Down (-y)\n",
        "    2: Left (-x)\n",
        "    3: Right (+x)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env: gym.Env, n_actions: int = 4, magnitude: float = 1.0, repeat: int = 5):\n",
        "        super().__init__(env)\n",
        "        self.n_actions = n_actions\n",
        "        self.magnitude = min(magnitude, 1.0)\n",
        "        self.repeat = repeat\n",
        "\n",
        "        # Define action mappings\n",
        "        self.action_map = {\n",
        "            0: np.array([0.0, self.magnitude]),    # up (+y)\n",
        "            1: np.array([0.0, -self.magnitude]),   # down (-y)\n",
        "            2: np.array([-self.magnitude, 0.0]),   # left (-x)\n",
        "            3: np.array([self.magnitude, 0.0]),    # right (+x)\n",
        "        }\n",
        "\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(n_actions)\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Repeat the action multiple times to simulate meaningful movement.\"\"\"\n",
        "        total_reward = 0.0\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        info = {}\n",
        "        success_achieved = False  # Track success across all repeats\n",
        "        steps_taken = 0\n",
        "\n",
        "        cont_action = self.action(action)\n",
        "\n",
        "        for _ in range(self.repeat):\n",
        "            obs, reward, term, trunc, info = self.env.step(cont_action)\n",
        "            total_reward += reward\n",
        "            steps_taken += 1\n",
        "            terminated = terminated or term\n",
        "            truncated = truncated or trunc\n",
        "            if info.get('is_success', False):  # Track success\n",
        "                success_achieved = True\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        info['is_success'] = success_achieved  # Preserve success flag\n",
        "        info['actual_steps'] = steps_taken\n",
        "\n",
        "        return obs, total_reward / (i + 1), terminated, truncated, info\n",
        "\n",
        "    def action(self, action) -> np.ndarray:\n",
        "        \"\"\"Convert discrete action to continuous.\"\"\"\n",
        "        if isinstance(action, np.ndarray):\n",
        "            action = int(action.item())\n",
        "        elif not isinstance(action, int):\n",
        "            action = int(action)\n",
        "\n",
        "        if action not in self.action_map:  # Add this check\n",
        "            raise ValueError(f\"Invalid action {action}, must be in {list(self.action_map.keys())}\")\n",
        "\n",
        "        return self.action_map[action]\n",
        "\n",
        "\n",
        "print(\"✓ DiscreteActionWrapper defined (for DQN methods only)\")\n",
        "print(\"Action mapping:\")\n",
        "for idx, act in DiscreteActionWrapper(gym.make('PointMaze_UMaze-v3'), magnitude=1.0).action_map.items():\n",
        "    print(f\"  {idx}: {act}\")"
      ],
      "metadata": {
        "id": "BnueziOxNeL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26eb4b1-ca8d-4d29-b872-722021852b41"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ DiscreteActionWrapper defined (for DQN methods only)\n",
            "Action mapping:\n",
            "  0: [0. 1.]\n",
            "  1: [ 0. -1.]\n",
            "  2: [-1.  0.]\n",
            "  3: [1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ENVIRONMENT UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "class DenseRewardWrapper(gym.Wrapper):\n",
        "    \"\"\"Adds dense reward shaping to help learning.\"\"\"\n",
        "\n",
        "    def __init__(self, env: gym.Env, success_bonus: float = 1.0, replace_reward=True):\n",
        "        super().__init__(env)\n",
        "        self.success_bonus = success_bonus\n",
        "        self._prev_distance = None\n",
        "        self.replace_reward = replace_reward\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs, info = self.env.reset(**kwargs)\n",
        "        achieved = obs['achieved_goal']\n",
        "        desired = obs['desired_goal']\n",
        "        self._prev_distance = np.linalg.norm(achieved - desired)\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "        achieved = obs['achieved_goal']\n",
        "        desired = obs['desired_goal']\n",
        "        current_distance = np.linalg.norm(achieved - desired)\n",
        "\n",
        "        dense_reward = self._prev_distance - current_distance\n",
        "        self._prev_distance = current_distance\n",
        "\n",
        "        if info.get('is_success', False):\n",
        "            dense_reward += self.success_bonus\n",
        "\n",
        "        # Compute final reward\n",
        "        if self.replace_reward:\n",
        "            final_reward = dense_reward\n",
        "        else:\n",
        "            final_reward = reward + dense_reward\n",
        "\n",
        "        info['original_reward'] = reward\n",
        "        info['dense_reward'] = dense_reward\n",
        "\n",
        "        return obs, dense_reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "def make_env(\n",
        "    config,\n",
        "    seed: int = 42,\n",
        "    use_discrete: bool = True,\n",
        "    use_dense_reward: bool = None,\n",
        "    render_mode: Optional[str] = None\n",
        ") -> gym.Env:\n",
        "    \"\"\"\n",
        "    Create environment with all wrappers applied.\n",
        "\n",
        "    Args:\n",
        "        config: Experiment configuration\n",
        "        seed: Random seed\n",
        "        use_discrete: If True, wrap with DiscreteActionWrapper (for DQN)\n",
        "                      If False, keep continuous actions (for HAC)\n",
        "        use_dense_reward: Whether to use dense reward shaping\n",
        "        render_mode: Rendering mode for visualization\n",
        "    \"\"\"\n",
        "    if use_dense_reward is None:\n",
        "        use_dense_reward = config.use_dense_reward\n",
        "\n",
        "    env = gym.make(\n",
        "        config.maze_map,\n",
        "        max_episode_steps=config.max_episode_steps,\n",
        "        continuing_task=config.continuing_task,\n",
        "        render_mode=render_mode\n",
        "    )\n",
        "\n",
        "    env.action_space.seed(seed)\n",
        "    env.observation_space.seed(seed)\n",
        "\n",
        "    if use_dense_reward:\n",
        "        env = DenseRewardWrapper(env)\n",
        "\n",
        "    # Only apply discrete wrapper for DQN methods\n",
        "    if use_discrete:\n",
        "        env = DiscreteActionWrapper(\n",
        "            env,\n",
        "            n_actions=config.n_discrete_actions,\n",
        "            magnitude=1.0,\n",
        "            repeat=1\n",
        "        )\n",
        "\n",
        "    env = RecordEpisodeStatistics(env)\n",
        "    env = Monitor(env)\n",
        "    env.reset(seed=seed)\n",
        "    return env\n",
        "\n",
        "\n",
        "def get_env_info(env: gym.Env) -> Dict:\n",
        "    \"\"\"Get environment information for logging.\"\"\"\n",
        "    obs, _ = env.reset()\n",
        "    return {\n",
        "        \"observation_shape\": obs['observation'].shape,\n",
        "        \"achieved_goal_shape\": obs['achieved_goal'].shape,\n",
        "        \"desired_goal_shape\": obs['desired_goal'].shape,\n",
        "        \"action_space\": env.action_space,\n",
        "    }\n",
        "\n",
        "\n",
        "# Test environment creation for both maze sizes\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Testing Environment Creation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for maze_size in ['small', 'large']:\n",
        "    test_config = ExperimentConfig().update_for_maze(maze_size)\n",
        "\n",
        "    # Test discrete env (for DQN)\n",
        "    test_env_discrete = make_env(test_config, seed=42, use_discrete=True)\n",
        "    info_discrete = get_env_info(test_env_discrete)\n",
        "    print(f\"\\n{MAZE_CONFIGS[maze_size]['name']} Maze (Discrete - for DQN):\")\n",
        "    print(f\"  Env: {test_config.maze_map}\")\n",
        "    print(f\"  Action space: {info_discrete['action_space']}\")\n",
        "    test_env_discrete.close()\n",
        "\n",
        "    # Test continuous env (for HAC)\n",
        "    test_env_cont = make_env(test_config, seed=42, use_discrete=False)\n",
        "    info_cont = get_env_info(test_env_cont)\n",
        "    print(f\"\\n{MAZE_CONFIGS[maze_size]['name']} Maze (Continuous - for HAC):\")\n",
        "    print(f\"  Env: {test_config.maze_map}\")\n",
        "    print(f\"  Action space: {info_cont['action_space']}\")\n",
        "    test_env_cont.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU2WVMUUNgJD",
        "outputId": "cf622920-12e0-4622-c3ee-5b6d3a815da9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing Environment Creation\n",
            "============================================================\n",
            "\n",
            "Small (UMaze) Maze (Discrete - for DQN):\n",
            "  Env: PointMaze_UMaze-v3\n",
            "  Action space: Discrete(4)\n",
            "\n",
            "Small (UMaze) Maze (Continuous - for HAC):\n",
            "  Env: PointMaze_UMaze-v3\n",
            "  Action space: Box(-1.0, 1.0, (2,), float32)\n",
            "\n",
            "Large Maze (Discrete - for DQN):\n",
            "  Env: PointMaze_Large-v3\n",
            "  Action space: Discrete(4)\n",
            "\n",
            "Large Maze (Continuous - for HAC):\n",
            "  Env: PointMaze_Large-v3\n",
            "  Action space: Box(-1.0, 1.0, (2,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG: Environment sanity check\n",
        "print(\"=\" * 50)\n",
        "print(\"ENVIRONMENT SANITY CHECK\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_config = ExperimentConfig().update_for_maze('small')\n",
        "env = gym.make(test_config.maze_map, max_episode_steps=test_config.max_episode_steps)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "print(f\"Action space: {env.action_space}\")\n",
        "print(f\"Action range: [{env.action_space.low}, {env.action_space.high}]\")\n",
        "print(f\"\\n--- Observations ---\")\n",
        "print(f\"Observation keys: {list(obs.keys())}\")\n",
        "print(f\"obs['observation'] shape: {obs['observation'].shape} → [x, y, vx, vy]\")\n",
        "print(f\"obs['achieved_goal'] shape: {obs['achieved_goal'].shape}\")\n",
        "print(f\"obs['desired_goal'] shape: {obs['desired_goal'].shape}\")\n",
        "print(f\"\\n--- Initial State ---\")\n",
        "print(f\"Agent position: {obs['achieved_goal']}\")\n",
        "print(f\"Goal position: {obs['desired_goal']}\")\n",
        "print(f\"Initial distance: {np.linalg.norm(obs['achieved_goal'] - obs['desired_goal']):.3f}\")\n",
        "print(f\"\\n--- Thresholds ---\")\n",
        "env_threshold = getattr(env.unwrapped, 'goal_distance_threshold', 'unknown')\n",
        "print(f\"Env goal_distance_threshold: {env_threshold}\")\n",
        "print(f\"Config success_threshold: {test_config.success_threshold}\")\n",
        "\n",
        "# Quick random rollout\n",
        "print(f\"\\n--- Random Policy Test (100 steps) ---\")\n",
        "min_dist = float('inf')\n",
        "for i in range(100):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, term, trunc, info = env.step(action)\n",
        "    dist = np.linalg.norm(obs['achieved_goal'] - obs['desired_goal'])\n",
        "    min_dist = min(min_dist, dist)\n",
        "    if info.get('is_success'):\n",
        "        print(f\"SUCCESS at step {i}!\")\n",
        "        break\n",
        "else:\n",
        "    print(f\"No success (expected for random policy)\")\n",
        "    print(f\"Minimum distance achieved: {min_dist:.3f}\")\n",
        "\n",
        "env.close()\n",
        "print(\"\\n✓ Environment sanity check complete\")"
      ],
      "metadata": {
        "id": "c46crqTiEtY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538e3009-a637-4d55-93b1-a77c77d4d4d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "ENVIRONMENT SANITY CHECK\n",
            "==================================================\n",
            "Action space: Box(-1.0, 1.0, (2,), float32)\n",
            "Action range: [[-1. -1.], [1. 1.]]\n",
            "\n",
            "--- Observations ---\n",
            "Observation keys: ['observation', 'achieved_goal', 'desired_goal']\n",
            "obs['observation'] shape: (4,) → [x, y, vx, vy]\n",
            "obs['achieved_goal'] shape: (2,)\n",
            "obs['desired_goal'] shape: (2,)\n",
            "\n",
            "--- Initial State ---\n",
            "Agent position: [-0.90965481 -0.89559609]\n",
            "Goal position: [1.13118718 0.93073104]\n",
            "Initial distance: 2.739\n",
            "\n",
            "--- Thresholds ---\n",
            "Env goal_distance_threshold: unknown\n",
            "Config success_threshold: 0.5\n",
            "\n",
            "--- Random Policy Test (100 steps) ---\n",
            "No success (expected for random policy)\n",
            "Minimum distance achieved: 2.484\n",
            "\n",
            "✓ Environment sanity check complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG: DiscreteActionWrapper behavior\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"DISCRETE ACTION WRAPPER CHECK\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_config = ExperimentConfig().update_for_maze('small')\n",
        "test_env = make_env(test_config, seed=42, use_discrete=True, use_dense_reward=True)\n",
        "obs, _ = test_env.reset()\n",
        "\n",
        "print(f\"Wrapped action space: {test_env.action_space} (n={test_env.action_space.n})\")\n",
        "\n",
        "# Test each action direction once\n",
        "action_names = {0: 'UP (+y)', 1: 'DOWN (-y)', 2: 'LEFT (-x)', 3: 'RIGHT (+x)'}\n",
        "print(\"\\n--- Single-step action test ---\")\n",
        "for action_idx in range(min(4, test_env.action_space.n)):\n",
        "    obs, _ = test_env.reset()\n",
        "    start = obs['achieved_goal'].copy()\n",
        "    obs, reward, _, _, _ = test_env.step(action_idx)\n",
        "    delta = obs['achieved_goal'] - start\n",
        "    print(f\"Action {action_idx} ({action_names[action_idx]:10s}): Δx={delta[0]:+.3f}, Δy={delta[1]:+.3f}, r={reward:.3f}\")\n",
        "\n",
        "# Test repeated UP action\n",
        "print(\"\\n--- Repeated UP action (10 steps) ---\")\n",
        "obs, _ = test_env.reset()\n",
        "print(f\"Start: {obs['achieved_goal']}\")\n",
        "for i in range(10):\n",
        "    obs, reward, term, trunc, info = test_env.step(0)\n",
        "    if term or trunc:\n",
        "        print(f\"Step {i+1}: Episode ended (success={info.get('is_success')})\")\n",
        "        break\n",
        "print(f\"End:   {obs['achieved_goal']}\")\n",
        "print(f\"Total Y movement: {obs['achieved_goal'][1] - obs['achieved_goal'][1]:.3f}\")\n",
        "\n",
        "test_env.close()\n",
        "print(\"\\n✓ Discrete wrapper check complete\")"
      ],
      "metadata": {
        "id": "BHttUGntExI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0d3eaa-3a11-4c64-cbad-9385f3cc21ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "DISCRETE ACTION WRAPPER CHECK\n",
            "==================================================\n",
            "Wrapped action space: Discrete(4) (n=4)\n",
            "\n",
            "--- Single-step action test ---\n",
            "Action 0 (UP (+y)   ): Δx=+0.000, Δy=+0.002, r=-0.000\n",
            "Action 1 (DOWN (-y) ): Δx=+0.000, Δy=-0.002, r=0.000\n",
            "Action 2 (LEFT (-x) ): Δx=-0.002, Δy=+0.000, r=0.000\n",
            "Action 3 (RIGHT (+x)): Δx=+0.002, Δy=+0.000, r=0.000\n",
            "\n",
            "--- Repeated UP action (10 steps) ---\n",
            "Start: [-0.06477015 -1.01522209]\n",
            "End:   [-0.06477015 -0.88516345]\n",
            "Total Y movement: 0.000\n",
            "\n",
            "✓ Discrete wrapper check complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "@dataclass\n",
        "class EpisodeMetrics:\n",
        "    \"\"\"Metrics for a single evaluation episode.\"\"\"\n",
        "    success: bool\n",
        "    steps: int\n",
        "    total_reward: float\n",
        "    path_length: float\n",
        "    goal_distance: float\n",
        "    final_distance: float\n",
        "\n",
        "    @property\n",
        "    def path_efficiency(self) -> float:\n",
        "        if self.path_length > 0:\n",
        "            return self.goal_distance / self.path_length\n",
        "        return 0.0\n",
        "    @property\n",
        "    def normalized_steps(self) -> float:\n",
        "        \"\"\"Steps normalized by initial goal distance.\"\"\"\n",
        "        if self.goal_distance > 0:\n",
        "            return self.steps / self.goal_distance\n",
        "        return float('inf')\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AggregatedMetrics:\n",
        "    \"\"\"Aggregated metrics over multiple episodes.\"\"\"\n",
        "    success_rate: float\n",
        "    success_rate_std: float\n",
        "    mean_steps: float\n",
        "    std_steps: float\n",
        "    mean_steps_successful: float\n",
        "    mean_reward: float\n",
        "    std_reward: float\n",
        "    mean_path_efficiency: float\n",
        "    std_path_efficiency: float\n",
        "    n_episodes: int\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        return asdict(self)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return (\n",
        "            f\"Success: {self.success_rate:.1%}±{self.success_rate_std:.1%} | \"\n",
        "            f\"Steps: {self.mean_steps:.1f}±{self.std_steps:.1f} | \"\n",
        "            f\"Efficiency: {self.mean_path_efficiency:.2f}±{self.std_path_efficiency:.2f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "def aggregate_metrics(episodes: List[EpisodeMetrics]) -> AggregatedMetrics:\n",
        "    \"\"\"Aggregate episode metrics with proper handling of edge cases.\"\"\"\n",
        "    n = len(episodes)\n",
        "    successes = [ep.success for ep in episodes]\n",
        "    steps = [ep.steps for ep in episodes]\n",
        "    rewards = [ep.total_reward for ep in episodes]\n",
        "    efficiencies = [ep.path_efficiency for ep in episodes]\n",
        "\n",
        "    successful_steps = [ep.steps for ep in episodes if ep.success]\n",
        "\n",
        "    return AggregatedMetrics(\n",
        "        success_rate=np.mean(successes),\n",
        "        success_rate_std=np.std(successes) / np.sqrt(n),\n",
        "        mean_steps=np.mean(steps),\n",
        "        std_steps=np.std(steps),\n",
        "        mean_steps_successful=np.mean(successful_steps) if successful_steps else float('nan'),\n",
        "        mean_reward=np.mean(rewards),\n",
        "        std_reward=np.std(rewards),\n",
        "        mean_path_efficiency=np.mean(efficiencies),\n",
        "        std_path_efficiency=np.std(efficiencies),\n",
        "        n_episodes=n\n",
        "    )\n",
        "\n",
        "\n",
        "def set_seeds(seed: int):\n",
        "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "print(\"✓ Utility functions defined\")"
      ],
      "metadata": {
        "id": "wtXPJ2aENhdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889df6ed-1711-4609-e22f-0e460fb7be82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Utility functions defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LIVE TRAINING VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "class LiveLossPlotter:\n",
        "    \"\"\"Real-time loss plotting during training.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        update_freq: int = 100,\n",
        "        window_size: int = 1000,\n",
        "        figsize: Tuple[int, int] = (14, 5)\n",
        "    ):\n",
        "        self.update_freq = update_freq\n",
        "        self.window_size = window_size\n",
        "        self.figsize = figsize\n",
        "\n",
        "        self.losses = defaultdict(list)\n",
        "        self.steps = []\n",
        "        self.step_count = 0\n",
        "\n",
        "        self.eval_steps = []\n",
        "        self.eval_success_rates = []\n",
        "        self.eval_rewards = []\n",
        "\n",
        "        self.fig = None\n",
        "        self.axes = None\n",
        "\n",
        "    def setup(self):\n",
        "        self.fig, self.axes = plt.subplots(1, 3, figsize=self.figsize)\n",
        "\n",
        "        self.axes[0].set_title('Training Losses')\n",
        "        self.axes[0].set_xlabel('Steps')\n",
        "        self.axes[0].set_ylabel('Loss')\n",
        "        self.axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        self.axes[1].set_title('Success Rate')\n",
        "        self.axes[1].set_xlabel('Steps')\n",
        "        self.axes[1].set_ylabel('Success Rate (%)')\n",
        "        self.axes[1].set_ylim(0, 100)\n",
        "        self.axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        self.axes[2].set_title('Mean Reward')\n",
        "        self.axes[2].set_xlabel('Steps')\n",
        "        self.axes[2].set_ylabel('Reward')\n",
        "        self.axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "    def add_loss(self, step: int, losses_dict: Dict[str, float]):\n",
        "        self.step_count = step\n",
        "        self.steps.append(step)\n",
        "\n",
        "        for name, value in losses_dict.items():\n",
        "            self.losses[name].append(value)\n",
        "\n",
        "    def add_eval_metrics(self, step: int, success_rate: float, mean_reward: float):\n",
        "        self.eval_steps.append(step)\n",
        "        self.eval_success_rates.append(success_rate * 100)\n",
        "        self.eval_rewards.append(mean_reward)\n",
        "\n",
        "    def update_plot(self, force: bool = False):\n",
        "        if not force and self.step_count % self.update_freq != 0:\n",
        "            return\n",
        "\n",
        "        if self.fig is None:\n",
        "            self.setup()\n",
        "\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        self.axes[0].clear()\n",
        "        self.axes[0].set_title('Training Losses')\n",
        "        self.axes[0].set_xlabel('Steps')\n",
        "        self.axes[0].set_ylabel('Loss')\n",
        "        self.axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        start_idx = max(0, len(self.steps) - self.window_size)\n",
        "        display_steps = self.steps[start_idx:]\n",
        "\n",
        "        for name, values in self.losses.items():\n",
        "            display_values = values[start_idx:]\n",
        "            if len(display_values) > 0:\n",
        "                self.axes[0].plot(display_steps, display_values, label=name, alpha=0.8)\n",
        "\n",
        "        if self.losses:\n",
        "            self.axes[0].legend(loc='upper right', fontsize=8)\n",
        "\n",
        "        self.axes[1].clear()\n",
        "        self.axes[1].set_title('Success Rate')\n",
        "        self.axes[1].set_xlabel('Steps')\n",
        "        self.axes[1].set_ylabel('Success Rate (%)')\n",
        "        self.axes[1].set_ylim(0, 100)\n",
        "        self.axes[1].grid(True, alpha=0.3)\n",
        "        if self.eval_success_rates:\n",
        "            self.axes[1].plot(self.eval_steps, self.eval_success_rates, 'b-o', markersize=4)\n",
        "\n",
        "        self.axes[2].clear()\n",
        "        self.axes[2].set_title('Mean Reward')\n",
        "        self.axes[2].set_xlabel('Steps')\n",
        "        self.axes[2].set_ylabel('Reward')\n",
        "        self.axes[2].grid(True, alpha=0.3)\n",
        "        if self.eval_rewards:\n",
        "            self.axes[2].plot(self.eval_steps, self.eval_rewards, 'g-o', markersize=4)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        display(self.fig)\n",
        "\n",
        "    def close(self):\n",
        "        if self.fig is not None:\n",
        "            plt.close(self.fig)\n",
        "\n",
        "    def save_figure(self, path: str):\n",
        "        \"\"\"Save current figure to file.\"\"\"\n",
        "        if self.fig is not None:\n",
        "            self.fig.savefig(path, dpi=150, bbox_inches='tight')\n",
        "\n",
        "    def get_summary(self) -> Dict:\n",
        "        \"\"\"Get summary statistics for logging.\"\"\"\n",
        "        return {\n",
        "            'final_success_rate': self.eval_success_rates[-1] if self.eval_success_rates else 0,\n",
        "            'best_success_rate': max(self.eval_success_rates) if self.eval_success_rates else 0,\n",
        "            'final_reward': self.eval_rewards[-1] if self.eval_rewards else 0,\n",
        "            'total_steps': self.step_count,}\n",
        "\n",
        "\n",
        "print(\"✓ LiveLossPlotter defined\")"
      ],
      "metadata": {
        "id": "7YQRz4ISNi87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5ba304-43b9-4379-d76a-0f8f0b22a975"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ LiveLossPlotter defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EVALUATION CALLBACK FOR DQN\n",
        "# ============================================================================\n",
        "\n",
        "class LiveRenderCallback(BaseCallback):\n",
        "    \"\"\"Callback for live rendering and evaluation during training.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        eval_freq: int = 5000,\n",
        "        n_eval_episodes: int = 10,\n",
        "        plot_freq: int = 500,\n",
        "        success_threshold: float = 0.5,\n",
        "        verbose: int = 1\n",
        "    ):\n",
        "        super().__init__(verbose)\n",
        "        self.eval_env = eval_env\n",
        "        self.eval_freq = eval_freq\n",
        "        self.n_eval_episodes = n_eval_episodes\n",
        "        self.plot_freq = plot_freq\n",
        "        self.success_threshold = success_threshold\n",
        "\n",
        "        self.loss_plotter = LiveLossPlotter(update_freq=plot_freq)\n",
        "        self.eval_history = []\n",
        "        self.best_success_rate = 0.0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "\n",
        "        if self.n_calls % 10000 == 0:\n",
        "          eps_str = f\", epsilon={self.model.exploration_rate:.3f}\" if hasattr(self.model, 'exploration_rate') else \"\"\n",
        "          print(f\"Step {self.n_calls}{eps_str}\")\n",
        "\n",
        "        if self.n_calls % self.plot_freq == 0:\n",
        "            if hasattr(self.model, 'logger') and self.model.logger is not None:\n",
        "                try:\n",
        "                    loss = self.model.logger.name_to_value.get('train/loss', 0)\n",
        "                    self.loss_plotter.add_loss(self.n_calls, {'dqn_loss': loss})\n",
        "                except (AttributeError, KeyError):\n",
        "                    pass\n",
        "\n",
        "        if self.n_calls % self.eval_freq == 0:\n",
        "            metrics = self._evaluate()\n",
        "            self.eval_history.append(metrics)\n",
        "\n",
        "            if metrics['success_rate'] > self.best_success_rate:\n",
        "                self.best_success_rate = metrics['success_rate']\n",
        "\n",
        "            self.loss_plotter.add_eval_metrics(\n",
        "                self.n_calls,\n",
        "                metrics['success_rate'],\n",
        "                metrics.get('mean_reward', 0)\n",
        "            )\n",
        "            self.loss_plotter.update_plot(force=True)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _evaluate(self) -> Dict:\n",
        "        successes = []\n",
        "        steps_list = []\n",
        "        rewards_list = []\n",
        "        path_lengths = []\n",
        "        goal_distances = []\n",
        "\n",
        "        # threshold once per eval\n",
        "        threshold = getattr(self.eval_env.unwrapped, \"goal_distance_threshold\", None)\n",
        "        if threshold is None:\n",
        "            threshold = getattr(self, \"success_threshold\", 0.5)  # fallback\n",
        "\n",
        "        for ep_idx in range(self.n_eval_episodes):\n",
        "            obs, _ = self.eval_env.reset()\n",
        "\n",
        "            if not (isinstance(obs, dict) and (\"achieved_goal\" in obs) and (\"desired_goal\" in obs)):\n",
        "                raise ValueError(\"Eval env must return dict obs with achieved_goal & desired_goal for this evaluator.\")\n",
        "\n",
        "\n",
        "\n",
        "            start_pos = obs['achieved_goal'].copy()\n",
        "            goal_pos = obs['desired_goal'].copy()\n",
        "            goal_distance = np.linalg.norm(goal_pos - start_pos)\n",
        "\n",
        "            done = False\n",
        "            steps = 0\n",
        "            total_reward = 0\n",
        "            success = False\n",
        "            path_length = 0.0\n",
        "            prev_pos = start_pos.copy()\n",
        "\n",
        "\n",
        "            while not done:\n",
        "                action, _ = self.model.predict(obs, deterministic=True)\n",
        "                obs, reward, terminated, truncated, info = self.eval_env.step(action)\n",
        "                done = terminated or truncated\n",
        "                steps += 1\n",
        "                total_reward += reward\n",
        "\n",
        "                current_pos = obs['achieved_goal']\n",
        "                path_length += np.linalg.norm(current_pos - prev_pos)\n",
        "                prev_pos = current_pos.copy()\n",
        "\n",
        "                 # distance-based success + info-based success\n",
        "                dist = np.linalg.norm(obs[\"achieved_goal\"] - obs[\"desired_goal\"])\n",
        "                if info.get(\"is_success\", False) or info.get(\"success\", False) or dist < threshold:\n",
        "                    success = True\n",
        "\n",
        "\n",
        "\n",
        "            if ep_idx < 3:  # Print first 3 episodes only\n",
        "                final_dist = np.linalg.norm(obs['achieved_goal'] - obs['desired_goal'])\n",
        "\n",
        "                print(f\"  Eval ep: steps={steps}, final_dist={final_dist:.3f}, is_success={info.get('is_success')}, success_var={success}\")\n",
        "\n",
        "            successes.append(float(success))\n",
        "            steps_list.append(steps)\n",
        "            rewards_list.append(total_reward)\n",
        "            path_lengths.append(path_length)\n",
        "            goal_distances.append(goal_distance)\n",
        "\n",
        "        efficiencies = [gd / pl if pl > 0 else 0 for gd, pl in zip(goal_distances, path_lengths)]\n",
        "\n",
        "        return {\n",
        "            'timestep': self.n_calls,\n",
        "            'success_rate': np.mean(successes),\n",
        "            'success_rate_std': np.std(successes),\n",
        "            'mean_steps': np.mean(steps_list),\n",
        "            'std_steps': np.std(steps_list),\n",
        "            'mean_reward': np.mean(rewards_list),\n",
        "            'mean_path_efficiency': np.mean(efficiencies),\n",
        "        }\n",
        "\n",
        "    def get_eval_df(self) -> pd.DataFrame:\n",
        "        return pd.DataFrame(self.eval_history)\n",
        "\n",
        "    def _on_training_end(self):\n",
        "        self.loss_plotter.close()\n",
        "\n",
        "\n",
        "print(\"✓ LiveRenderCallback defined\")"
      ],
      "metadata": {
        "id": "Wn0L5kHMNkjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c8c210-5cec-4fd1-8e57-a0ce39904e58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ LiveRenderCallback defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TIER 1: DQN WITH DENSE REWARD\n",
        "# ============================================================================\n",
        "\n",
        "def train_dqn_live(\n",
        "    config: ExperimentConfig,\n",
        "    seed: int,\n",
        "    experiment_name: str = \"tier1_live\",\n",
        "    use_dense_reward: bool = None,\n",
        "    plot_freq: int = 500\n",
        ") -> Tuple[Any, pd.DataFrame]:\n",
        "    \"\"\"Train DQN with live loss plots.\"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    if use_dense_reward is None:\n",
        "        use_dense_reward = config.use_dense_reward\n",
        "\n",
        "    log_dir = os.path.join(config.log_dir, f\"{experiment_name}_{config.maze_size}_dqn_seed{seed}\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # DQN uses discrete actions\n",
        "    train_env = make_env(config, seed=seed, use_discrete=True, use_dense_reward=use_dense_reward)\n",
        "    eval_env = make_env(config, seed=seed + 1000, use_discrete=True, use_dense_reward=False)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"🎯 Training DQN (Dense Reward) - {MAZE_CONFIGS[config.maze_size]['name']} Maze\")\n",
        "    print(f\"Seed: {seed}, Total Steps: {config.total_timesteps:,}\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    model = DQN(\n",
        "        \"MultiInputPolicy\",\n",
        "        train_env,\n",
        "        learning_rate=config.learning_rate,\n",
        "        buffer_size=config.buffer_size,\n",
        "        batch_size=config.batch_size,\n",
        "        learning_starts=config.learning_starts,\n",
        "        tau=config.tau,\n",
        "        gamma=config.gamma,\n",
        "        train_freq=config.train_freq,\n",
        "        gradient_steps=config.gradient_steps,\n",
        "        exploration_fraction=config.exploration_fraction,\n",
        "        exploration_initial_eps=config.exploration_initial_eps,\n",
        "        exploration_final_eps=config.exploration_final_eps,\n",
        "        target_update_interval=config.target_update_interval,\n",
        "        policy_kwargs=config.policy_kwargs,\n",
        "        tensorboard_log=log_dir,\n",
        "        verbose=0,\n",
        "        seed=seed,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    live_callback = LiveRenderCallback(\n",
        "        eval_env=eval_env,\n",
        "        eval_freq=config.eval_freq,\n",
        "        n_eval_episodes=config.n_eval_episodes,\n",
        "        plot_freq=plot_freq,\n",
        "        success_threshold=config.success_threshold,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.learn(\n",
        "        total_timesteps=config.total_timesteps,\n",
        "        callback=live_callback,\n",
        "        progress_bar=True\n",
        "    )\n",
        "\n",
        "    if config.save_models:\n",
        "        model_path = os.path.join(log_dir, \"final_model\")\n",
        "        model.save(model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    eval_df = live_callback.get_eval_df()\n",
        "    eval_df['seed'] = seed\n",
        "    eval_df['algorithm'] = 'dqn_dense'\n",
        "    eval_df['maze_size'] = config.maze_size\n",
        "\n",
        "    train_env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "\n",
        "\n",
        "    return model, eval_df\n",
        "\n",
        "\n",
        "print(\"✓ train_dqn_live() defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHJfOpeQNl87",
        "outputId": "00b05d7c-1e52-488c-ae30-614379beea1f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ train_dqn_live() defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TIER 2: DQN + HER (WITH ABLATION)\n",
        "# ============================================================================\n",
        "\n",
        "def train_dqn_her_live(\n",
        "    config: ExperimentConfig,\n",
        "    seed: int,\n",
        "    use_her: bool = True,\n",
        "    experiment_name: str = \"tier2_live\",\n",
        "    plot_freq: int = 500\n",
        ") -> Tuple[Any, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Train DQN with or without HER.\n",
        "    \"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    her_str = \"with_her\" if use_her else \"no_her\"\n",
        "    log_dir = os.path.join(config.log_dir, f\"{experiment_name}_{config.maze_size}_dqn_{her_str}_seed{seed}\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # DQN uses discrete actions, sparse rewards for HER ablation\n",
        "    train_env = make_env(config, seed=seed, use_discrete=True, use_dense_reward=False)\n",
        "    eval_env = make_env(config, seed=seed + 1000, use_discrete=True, use_dense_reward=False)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"🎯 Training DQN {'WITH' if use_her else 'WITHOUT'} HER - {MAZE_CONFIGS[config.maze_size]['name']} Maze\")\n",
        "    print(f\"Seed: {seed}, Total Steps: {config.total_timesteps:,}\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    if use_her:\n",
        "        replay_buffer_class = HerReplayBuffer\n",
        "        replay_buffer_kwargs = {\n",
        "            \"n_sampled_goal\": config.her_n_sampled_goal,\n",
        "            \"goal_selection_strategy\": config.her_strategy,\n",
        "        }\n",
        "        print(f\"HER config: strategy={config.her_strategy}, n_sampled_goal={config.her_n_sampled_goal}\")\n",
        "    else:\n",
        "        replay_buffer_class = DictReplayBuffer\n",
        "        replay_buffer_kwargs = {}\n",
        "        print(\"Using standard DictReplayBuffer (no HER)\")\n",
        "\n",
        "    model = DQN(\n",
        "        \"MultiInputPolicy\",\n",
        "        train_env,\n",
        "        learning_rate=config.learning_rate,\n",
        "        buffer_size=config.buffer_size,\n",
        "        batch_size=config.batch_size,\n",
        "        learning_starts=config.learning_starts,\n",
        "        tau=config.tau,\n",
        "        gamma=config.gamma,\n",
        "        train_freq=config.train_freq,\n",
        "        gradient_steps=config.gradient_steps,\n",
        "        exploration_fraction=config.exploration_fraction,\n",
        "        exploration_initial_eps=config.exploration_initial_eps,\n",
        "        exploration_final_eps=config.exploration_final_eps,\n",
        "        target_update_interval=config.target_update_interval,\n",
        "        replay_buffer_class=replay_buffer_class,\n",
        "        replay_buffer_kwargs=replay_buffer_kwargs,\n",
        "        policy_kwargs=config.policy_kwargs,\n",
        "        tensorboard_log=log_dir,\n",
        "        verbose=0,\n",
        "        seed=seed,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    live_callback = LiveRenderCallback(\n",
        "        eval_env=eval_env,\n",
        "        eval_freq=config.eval_freq,\n",
        "        n_eval_episodes=config.n_eval_episodes,\n",
        "        plot_freq=plot_freq,\n",
        "        success_threshold=config.success_threshold,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.learn(\n",
        "        total_timesteps=config.total_timesteps,\n",
        "        callback=live_callback,\n",
        "        progress_bar=True\n",
        "    )\n",
        "\n",
        "    print(f\"Replay buffer class: {type(model.replay_buffer)}\")\n",
        "    print(f\"Buffer kwargs: {replay_buffer_kwargs}\")\n",
        "\n",
        "    if config.save_models:\n",
        "        model_path = os.path.join(log_dir, \"final_model\")\n",
        "        model.save(model_path)\n",
        "        print(f\"✓ Model saved to {model_path}\")\n",
        "\n",
        "    eval_df = live_callback.get_eval_df()\n",
        "    eval_df['seed'] = seed\n",
        "    eval_df['algorithm'] = f'dqn_{her_str}'\n",
        "    eval_df['use_her'] = use_her\n",
        "    eval_df['maze_size'] = config.maze_size\n",
        "\n",
        "    train_env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "    return model, eval_df\n",
        "\n",
        "\n",
        "print(\"✓ train_dqn_her_live() defined\")"
      ],
      "metadata": {
        "id": "-Jl58n0yNnXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cd91e9-5324-40de-c078-7a64bcc8a600"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ train_dqn_her_live() defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EVALUATION CALLBACK FOR CONTINUOUS ACTION METHODS (SAC, TQC)\n",
        "# ============================================================================\n",
        "\n",
        "class LiveRenderCallbackContinuous(BaseCallback):\n",
        "    \"\"\"Callback for live rendering and evaluation for continuous action methods.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        eval_freq: int = 5000,\n",
        "        n_eval_episodes: int = 10,\n",
        "        plot_freq: int = 500,\n",
        "        success_threshold: float = 0.5,\n",
        "        verbose: int = 1\n",
        "    ):\n",
        "        super().__init__(verbose)\n",
        "        self.eval_env = eval_env\n",
        "        self.eval_freq = eval_freq\n",
        "        self.n_eval_episodes = n_eval_episodes\n",
        "        self.plot_freq = plot_freq\n",
        "        self.success_threshold = success_threshold\n",
        "\n",
        "        self.loss_plotter = LiveLossPlotter(update_freq=plot_freq)\n",
        "        self.eval_history = []\n",
        "        self.best_success_rate = 0.0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.plot_freq == 0:\n",
        "            if hasattr(self.model, 'logger') and self.model.logger is not None:\n",
        "                try:\n",
        "                    losses = {}\n",
        "                    for key in ['train/actor_loss', 'train/critic_loss', 'train/ent_coef_loss']:\n",
        "                        val = self.model.logger.name_to_value.get(key, None)\n",
        "                        if val is not None:\n",
        "                            losses[key.split('/')[-1]] = val\n",
        "                    if losses:\n",
        "                        self.loss_plotter.add_loss(self.n_calls, losses)\n",
        "                except (AttributeError, KeyError):\n",
        "                    pass\n",
        "\n",
        "        if self.n_calls % self.eval_freq == 0:\n",
        "            metrics = self._evaluate()\n",
        "            self.eval_history.append(metrics)\n",
        "\n",
        "            if metrics['success_rate'] > self.best_success_rate:\n",
        "                self.best_success_rate = metrics['success_rate']\n",
        "\n",
        "            self.loss_plotter.add_eval_metrics(\n",
        "                self.n_calls,\n",
        "                metrics['success_rate'],\n",
        "                metrics.get('mean_reward', 0)\n",
        "            )\n",
        "            self.loss_plotter.update_plot(force=True)\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _evaluate(self) -> Dict:\n",
        "        successes = []\n",
        "        steps_list = []\n",
        "        rewards_list = []\n",
        "        path_lengths = []\n",
        "        goal_distances = []\n",
        "\n",
        "        threshold = getattr(self.eval_env.unwrapped, \"goal_distance_threshold\", None)\n",
        "        if threshold is None:\n",
        "            threshold = self.success_threshold\n",
        "\n",
        "        for ep_idx in range(self.n_eval_episodes):\n",
        "            obs, _ = self.eval_env.reset()\n",
        "            start_pos = obs['achieved_goal'].copy()\n",
        "            goal_pos = obs['desired_goal'].copy()\n",
        "            goal_distance = np.linalg.norm(goal_pos - start_pos)\n",
        "\n",
        "            done = False\n",
        "            steps = 0\n",
        "            total_reward = 0\n",
        "            success = False\n",
        "            path_length = 0.0\n",
        "            prev_pos = start_pos.copy()\n",
        "\n",
        "            while not done:\n",
        "                action, _ = self.model.predict(obs, deterministic=True)\n",
        "                obs, reward, terminated, truncated, info = self.eval_env.step(action)\n",
        "                done = terminated or truncated\n",
        "                steps += 1\n",
        "                total_reward += reward\n",
        "\n",
        "                current_pos = obs['achieved_goal']\n",
        "                path_length += np.linalg.norm(current_pos - prev_pos)\n",
        "                prev_pos = current_pos.copy()\n",
        "\n",
        "                dist = np.linalg.norm(obs[\"achieved_goal\"] - obs[\"desired_goal\"])\n",
        "                if info.get('is_success', False) or dist < threshold:\n",
        "                    success = True\n",
        "\n",
        "            if ep_idx < 3:  # Debug first 3 episodes\n",
        "                final_dist = np.linalg.norm(obs['achieved_goal'] - obs['desired_goal'])\n",
        "                print(f\"  Eval ep {ep_idx}: steps={steps}, final_dist={final_dist:.3f}, success={success}\")\n",
        "\n",
        "\n",
        "            successes.append(float(success))\n",
        "            steps_list.append(steps)\n",
        "            rewards_list.append(total_reward)\n",
        "            path_lengths.append(path_length)\n",
        "            goal_distances.append(goal_distance)\n",
        "\n",
        "        efficiencies = [gd / pl if pl > 0 else 0 for gd, pl in zip(goal_distances, path_lengths)]\n",
        "\n",
        "        return {\n",
        "            'timestep': self.n_calls,\n",
        "            'success_rate': np.mean(successes),\n",
        "            'success_rate_std': np.std(successes),\n",
        "            'mean_steps': np.mean(steps_list),\n",
        "            'std_steps': np.std(steps_list),\n",
        "            'mean_reward': np.mean(rewards_list),\n",
        "            'mean_path_efficiency': np.mean(efficiencies),\n",
        "        }\n",
        "\n",
        "    def get_eval_df(self) -> pd.DataFrame:\n",
        "        return pd.DataFrame(self.eval_history)\n",
        "\n",
        "    def _on_training_end(self):\n",
        "        self.loss_plotter.close()\n",
        "\n",
        "\n",
        "print(\"✓ LiveRenderCallbackContinuous defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1DExbwENo2z",
        "outputId": "a1a727b9-1968-4bc2-e056-ccf5bbcd245a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ LiveRenderCallbackContinuous defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SAC (Soft Actor-Critic) WITH/WITHOUT HER\n",
        "# ============================================================================\n",
        "\n",
        "def train_sac_live(\n",
        "    config: ExperimentConfig,\n",
        "    seed: int,\n",
        "    use_her: bool = True,\n",
        "    experiment_name: str = \"sac_live\",\n",
        "    plot_freq: int = 500\n",
        ") -> Tuple[Any, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Train SAC with or without HER.\n",
        "    Uses CONTINUOUS actions (native action space).\n",
        "    \"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    her_str = \"with_her\" if use_her else \"no_her\"\n",
        "    log_dir = os.path.join(config.log_dir, f\"{experiment_name}_{config.maze_size}_sac_{her_str}_seed{seed}\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # SAC uses CONTINUOUS actions (no discrete wrapper)\n",
        "    train_env = make_env(config, seed=seed, use_discrete=False, use_dense_reward=False)\n",
        "    eval_env = make_env(config, seed=seed + 1000, use_discrete=False, use_dense_reward=False)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"🎯 Training SAC {'WITH' if use_her else 'WITHOUT'} HER - {MAZE_CONFIGS[config.maze_size]['name']} Maze\")\n",
        "    print(f\"Seed: {seed}, Total Steps: {config.total_timesteps:,}\")\n",
        "    print(f\"Action Space: Continuous\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    if use_her:\n",
        "        replay_buffer_class = HerReplayBuffer\n",
        "        replay_buffer_kwargs = {\n",
        "            \"n_sampled_goal\": config.her_n_sampled_goal,\n",
        "            \"goal_selection_strategy\": config.her_strategy,\n",
        "        }\n",
        "        print(f\"HER config: strategy={config.her_strategy}, n_sampled_goal={config.her_n_sampled_goal}\")\n",
        "    else:\n",
        "        replay_buffer_class = DictReplayBuffer\n",
        "        replay_buffer_kwargs = {}\n",
        "        print(\"Using standard DictReplayBuffer (no HER)\")\n",
        "\n",
        "    model = SAC(\n",
        "        \"MultiInputPolicy\",\n",
        "        train_env,\n",
        "        learning_rate=config.high_level_lr,\n",
        "        buffer_size=config.buffer_size,\n",
        "        batch_size=config.batch_size,\n",
        "        learning_starts=config.learning_starts,\n",
        "        tau=config.tau,\n",
        "        gamma=config.gamma,\n",
        "        train_freq=1,\n",
        "        gradient_steps=1,\n",
        "        ent_coef='auto',  # Automatic entropy tuning (default, but explicit is good)\n",
        "        target_entropy='auto',  # Automatic target entropy\n",
        "        replay_buffer_class=replay_buffer_class,\n",
        "        replay_buffer_kwargs=replay_buffer_kwargs,\n",
        "        policy_kwargs=config.policy_kwargs,\n",
        "        tensorboard_log=log_dir,\n",
        "        verbose=0,\n",
        "        seed=seed,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    # Create callback for continuous action evaluation\n",
        "    live_callback = LiveRenderCallbackContinuous(\n",
        "        eval_env=eval_env,\n",
        "        eval_freq=config.eval_freq,\n",
        "        n_eval_episodes=config.n_eval_episodes,\n",
        "        plot_freq=plot_freq,\n",
        "        success_threshold=config.success_threshold,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.learn(\n",
        "        total_timesteps=config.total_timesteps,\n",
        "        callback=live_callback,\n",
        "        progress_bar=True\n",
        "    )\n",
        "\n",
        "    if config.save_models:\n",
        "        model_path = os.path.join(log_dir, \"final_model\")\n",
        "        model.save(model_path)\n",
        "        print(f\"✓ Model saved to {model_path}\")\n",
        "\n",
        "    eval_df = live_callback.get_eval_df()\n",
        "    eval_df['seed'] = seed\n",
        "    eval_df['algorithm'] = f'sac_{her_str}'\n",
        "    eval_df['use_her'] = use_her\n",
        "    eval_df['maze_size'] = config.maze_size\n",
        "\n",
        "    train_env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "    return model, eval_df\n",
        "\n",
        "\n",
        "print(\"✓ train_sac_live() defined\")"
      ],
      "metadata": {
        "id": "fE09oIzlNqNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4f97ea-5686-4920-f49e-ffe197d114e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ train_sac_live() defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TQC (Truncated Quantile Critics) WITH/WITHOUT HER\n",
        "# ============================================================================\n",
        "\n",
        "def train_tqc_live(\n",
        "    config: ExperimentConfig,\n",
        "    seed: int,\n",
        "    use_her: bool = True,\n",
        "    experiment_name: str = \"tqc_live\",\n",
        "    plot_freq: int = 500\n",
        ") -> Tuple[Any, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Train TQC with or without HER.\n",
        "    Uses CONTINUOUS actions (native action space).\n",
        "    TQC extends SAC with distributional critics and truncation.\n",
        "    \"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    her_str = \"with_her\" if use_her else \"no_her\"\n",
        "    log_dir = os.path.join(config.log_dir, f\"{experiment_name}_{config.maze_size}_tqc_{her_str}_seed{seed}\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # TQC uses CONTINUOUS actions (no discrete wrapper)\n",
        "    train_env = make_env(config, seed=seed, use_discrete=False, use_dense_reward=False)\n",
        "    eval_env = make_env(config, seed=seed + 1000, use_discrete=False, use_dense_reward=False)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"🎯 Training TQC {'WITH' if use_her else 'WITHOUT'} HER - {MAZE_CONFIGS[config.maze_size]['name']} Maze\")\n",
        "    print(f\"Seed: {seed}, Total Steps: {config.total_timesteps:,}\")\n",
        "    print(f\"Action Space: Continuous\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    if use_her:\n",
        "        replay_buffer_class = HerReplayBuffer\n",
        "        replay_buffer_kwargs = {\n",
        "            \"n_sampled_goal\": config.her_n_sampled_goal,\n",
        "            \"goal_selection_strategy\": config.her_strategy,\n",
        "        }\n",
        "        print(f\"HER config: strategy={config.her_strategy}, n_sampled_goal={config.her_n_sampled_goal}\")\n",
        "    else:\n",
        "        replay_buffer_class = DictReplayBuffer\n",
        "        replay_buffer_kwargs = {}\n",
        "        print(\"Using standard DictReplayBuffer (no HER)\")\n",
        "\n",
        "    # TQC-specific policy kwargs\n",
        "    tqc_policy_kwargs = {\n",
        "        \"net_arch\": [256, 256],\n",
        "        \"n_quantiles\": 25,  # Number of quantiles for distributional critic\n",
        "    }\n",
        "\n",
        "    model = TQC(\n",
        "        \"MultiInputPolicy\",\n",
        "        train_env,\n",
        "        learning_rate=config.high_level_lr,\n",
        "        buffer_size=config.buffer_size,\n",
        "        batch_size=config.batch_size,\n",
        "        learning_starts=config.learning_starts,\n",
        "        tau=config.tau,\n",
        "        gamma=config.gamma,\n",
        "        train_freq=1,\n",
        "        gradient_steps=1,\n",
        "        top_quantiles_to_drop_per_net=2,  # TQC truncation parameter\n",
        "        replay_buffer_class=replay_buffer_class,\n",
        "        replay_buffer_kwargs=replay_buffer_kwargs,\n",
        "        policy_kwargs=tqc_policy_kwargs,\n",
        "        tensorboard_log=log_dir,\n",
        "        verbose=0,\n",
        "        seed=seed,\n",
        "        device=DEVICE,\n",
        "    )\n",
        "\n",
        "    live_callback = LiveRenderCallbackContinuous(\n",
        "        eval_env=eval_env,\n",
        "        eval_freq=config.eval_freq,\n",
        "        n_eval_episodes=config.n_eval_episodes,\n",
        "        plot_freq=plot_freq,\n",
        "        success_threshold=config.success_threshold,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.learn(\n",
        "        total_timesteps=config.total_timesteps,\n",
        "        callback=live_callback,\n",
        "        progress_bar=True\n",
        "    )\n",
        "\n",
        "    if config.save_models:\n",
        "        model_path = os.path.join(log_dir, \"final_model\")\n",
        "        model.save(model_path)\n",
        "        print(f\"✓ Model saved to {model_path}\")\n",
        "\n",
        "    eval_df = live_callback.get_eval_df()\n",
        "    eval_df['seed'] = seed\n",
        "    eval_df['algorithm'] = f'tqc_{her_str}'\n",
        "    eval_df['use_her'] = use_her\n",
        "    eval_df['maze_size'] = config.maze_size\n",
        "\n",
        "    train_env.close()\n",
        "    eval_env.close()\n",
        "\n",
        "    return model, eval_df\n",
        "\n",
        "\n",
        "print(\"✓ train_tqc_live() defined\")"
      ],
      "metadata": {
        "id": "j31SHJk-Nr5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32ee48b-8461-4465-f90d-1b8d5cb21f76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ train_tqc_live() defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# TIER 3: HAC WITH CONTINUOUS LOW-LEVEL POLICY\n",
        "# ============================================================================\n",
        "\n",
        "class HACReplayBuffer:\n",
        "    \"\"\"\n",
        "    Hierarchical replay buffer for HAC with CONTINUOUS actions.\n",
        "    Supports HER for both high-level and low-level transitions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        buffer_size: int,\n",
        "        obs_dim: int,\n",
        "        goal_dim: int,\n",
        "        subgoal_dim: int,\n",
        "        action_dim: int,  # Continuous action dimension\n",
        "        device: str = \"cpu\"\n",
        "    ):\n",
        "        self.buffer_size = buffer_size\n",
        "        self.device = device\n",
        "\n",
        "        # High-level buffer (continuous subgoals)\n",
        "        self.high_buffer = {\n",
        "            'obs': np.zeros((buffer_size, obs_dim), dtype=np.float32),\n",
        "            'goal': np.zeros((buffer_size, goal_dim), dtype=np.float32),\n",
        "            'subgoal': np.zeros((buffer_size, subgoal_dim), dtype=np.float32),\n",
        "            'reward': np.zeros((buffer_size, 1), dtype=np.float32),\n",
        "            'next_obs': np.zeros((buffer_size, obs_dim), dtype=np.float32),\n",
        "            'done': np.zeros((buffer_size, 1), dtype=np.float32),\n",
        "            'segment_length': np.zeros((buffer_size, 1), dtype=np.float32),\n",
        "        }\n",
        "        self.high_ptr = 0\n",
        "        self.high_size = 0\n",
        "\n",
        "        # Low-level buffer (CONTINUOUS actions)\n",
        "        self.low_buffer = {\n",
        "            'obs': np.zeros((buffer_size, obs_dim), dtype=np.float32),\n",
        "            'subgoal': np.zeros((buffer_size, subgoal_dim), dtype=np.float32),\n",
        "            'action': np.zeros((buffer_size, action_dim), dtype=np.float32),  # Continuous!\n",
        "            'reward': np.zeros((buffer_size, 1), dtype=np.float32),\n",
        "            'next_obs': np.zeros((buffer_size, obs_dim), dtype=np.float32),\n",
        "            'done': np.zeros((buffer_size, 1), dtype=np.float32),\n",
        "            'achieved_goal': np.zeros((buffer_size, subgoal_dim), dtype=np.float32),  # For HER\n",
        "        }\n",
        "        self.low_ptr = 0\n",
        "        self.low_size = 0\n",
        "\n",
        "    def add_high_transition(self, obs, goal, subgoal, reward, next_obs, done, segment_length=None):\n",
        "        idx = self.high_ptr\n",
        "        self.high_buffer['obs'][idx] = obs\n",
        "        self.high_buffer['goal'][idx] = goal\n",
        "        self.high_buffer['subgoal'][idx] = subgoal\n",
        "        self.high_buffer['reward'][idx] = reward\n",
        "        self.high_buffer['next_obs'][idx] = next_obs\n",
        "        self.high_buffer['done'][idx] = done\n",
        "        self.high_buffer['segment_length'][idx] = segment_length if segment_length is not None else 1\n",
        "        self.high_ptr = (self.high_ptr + 1) % self.buffer_size\n",
        "        self.high_size = min(self.high_size + 1, self.buffer_size)\n",
        "\n",
        "    def add_low_transition(self, obs, subgoal, action, reward, next_obs, done, achieved_goal=None):\n",
        "        idx = self.low_ptr\n",
        "        self.low_buffer['obs'][idx] = obs\n",
        "        self.low_buffer['subgoal'][idx] = subgoal\n",
        "        self.low_buffer['action'][idx] = action\n",
        "        self.low_buffer['reward'][idx] = reward\n",
        "        self.low_buffer['next_obs'][idx] = next_obs\n",
        "        self.low_buffer['done'][idx] = done\n",
        "        if achieved_goal is not None:\n",
        "            self.low_buffer['achieved_goal'][idx] = achieved_goal\n",
        "        self.low_ptr = (self.low_ptr + 1) % self.buffer_size\n",
        "        self.low_size = min(self.low_size + 1, self.buffer_size)\n",
        "\n",
        "    def can_sample_high(self, batch_size: int) -> bool:\n",
        "        return self.high_size >= batch_size\n",
        "\n",
        "    def can_sample_low(self, batch_size: int) -> bool:\n",
        "        return self.low_size >= batch_size\n",
        "\n",
        "    def sample_high(self, batch_size: int) -> Optional[Dict[str, torch.Tensor]]:\n",
        "        if not self.can_sample_high(batch_size):\n",
        "            return None\n",
        "        indices = np.random.randint(0, self.high_size, size=batch_size)\n",
        "        return {k: torch.FloatTensor(v[indices]).to(self.device)\n",
        "                for k, v in self.high_buffer.items()}\n",
        "\n",
        "    def sample_low(self, batch_size: int) -> Optional[Dict[str, torch.Tensor]]:\n",
        "        if not self.can_sample_low(batch_size):\n",
        "            return None\n",
        "        indices = np.random.randint(0, self.low_size, size=batch_size)\n",
        "        return {k: torch.FloatTensor(v[indices]).to(self.device)\n",
        "                for k, v in self.low_buffer.items()}\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Return total transitions stored.\"\"\"\n",
        "        return self.high_size + self.low_size\n",
        "\n",
        "\n",
        "print(\"✓ HACReplayBuffer (continuous) defined\")"
      ],
      "metadata": {
        "id": "QJCnMc9WNtTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a8d38c-d1d7-45dd-8932-40a7bd1dc520"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ HACReplayBuffer (continuous) defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# HIGH-LEVEL POLICY (SAC-style for subgoal selection)\n",
        "# ============================================================================\n",
        "\n",
        "class HighLevelPolicy(nn.Module):\n",
        "    \"\"\"\n",
        "    High-level policy that outputs continuous subgoal positions.\n",
        "    Uses SAC-style actor-critic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        goal_dim: int,\n",
        "        subgoal_dim: int,\n",
        "        hidden_dims: List[int] = [256, 256],\n",
        "        subgoal_range_x: Tuple[float, float] = (0.0, 8.0),\n",
        "        subgoal_range_y: Tuple[float, float] = (0.0, 8.0),\n",
        "        target_entropy: float = None,\n",
        "        device: str = \"cpu\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.subgoal_dim = subgoal_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.register_buffer(\n",
        "            'subgoal_low',\n",
        "            torch.FloatTensor([subgoal_range_x[0], subgoal_range_y[0]])\n",
        "        )\n",
        "        self.register_buffer(\n",
        "            'subgoal_high',\n",
        "            torch.FloatTensor([subgoal_range_x[1], subgoal_range_y[1]])\n",
        "        )\n",
        "\n",
        "        input_dim = obs_dim + goal_dim\n",
        "\n",
        "        # Actor network\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.extend([nn.Linear(prev_dim, h), nn.ReLU()])\n",
        "            prev_dim = h\n",
        "        self.actor_net = nn.Sequential(*layers)\n",
        "        self.mean_head = nn.Linear(prev_dim, subgoal_dim)\n",
        "        self.log_std_head = nn.Linear(prev_dim, subgoal_dim)\n",
        "\n",
        "        # Critic networks\n",
        "        critic_input = input_dim + subgoal_dim\n",
        "\n",
        "        def make_critic():\n",
        "            layers = []\n",
        "            prev = critic_input\n",
        "            for h in hidden_dims:\n",
        "                layers.extend([nn.Linear(prev, h), nn.ReLU()])\n",
        "                prev = h\n",
        "            layers.append(nn.Linear(prev, 1))\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        self.q1 = make_critic()\n",
        "        self.q2 = make_critic()\n",
        "        self.q1_target = deepcopy(self.q1)\n",
        "        self.q2_target = deepcopy(self.q2)\n",
        "\n",
        "        for p in self.q1_target.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in self.q2_target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.log_alpha = nn.Parameter(torch.zeros(1))\n",
        "        self.target_entropy = target_entropy if target_entropy is not None else -subgoal_dim\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    @property\n",
        "    def alpha(self) -> torch.Tensor:\n",
        "        return self.log_alpha.exp()\n",
        "\n",
        "    def _scale_subgoal(self, subgoal: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Scale sigmoid output to subgoal range.\"\"\"\n",
        "        return subgoal * (self.subgoal_high - self.subgoal_low) + self.subgoal_low\n",
        "\n",
        "    def get_subgoal(self, obs: np.ndarray, goal: np.ndarray, deterministic: bool = False) -> np.ndarray:\n",
        "        with torch.no_grad():\n",
        "            obs_t = torch.FloatTensor(obs).unsqueeze(0).to(self.device)\n",
        "            goal_t = torch.FloatTensor(goal).unsqueeze(0).to(self.device)\n",
        "            x = torch.cat([obs_t, goal_t], dim=-1)\n",
        "\n",
        "            features = self.actor_net(x)\n",
        "            mean = self.mean_head(features)\n",
        "\n",
        "            if deterministic:\n",
        "                subgoal = torch.sigmoid(mean)\n",
        "            else:\n",
        "                log_std = torch.clamp(self.log_std_head(features), -20, 2)\n",
        "                std = log_std.exp()\n",
        "                dist = torch.distributions.Normal(mean, std)\n",
        "                subgoal = torch.sigmoid(dist.rsample())\n",
        "\n",
        "            subgoal = self._scale_subgoal(subgoal)\n",
        "            return subgoal.cpu().numpy().flatten()\n",
        "\n",
        "    def forward_actor(self, obs: torch.Tensor, goal: torch.Tensor):\n",
        "        x = torch.cat([obs, goal], dim=-1)\n",
        "        features = self.actor_net(x)\n",
        "        mean = self.mean_head(features)\n",
        "        log_std = torch.clamp(self.log_std_head(features), -20, 2)\n",
        "        std = log_std.exp()\n",
        "\n",
        "        dist = torch.distributions.Normal(mean, std)\n",
        "        z = dist.rsample()\n",
        "        subgoal_normalized = torch.sigmoid(z)\n",
        "\n",
        "        # Log prob with sigmoid Jacobian correction\n",
        "        log_prob = dist.log_prob(z) - torch.log(subgoal_normalized * (1 - subgoal_normalized) + 1e-6)\n",
        "        log_prob = log_prob.sum(dim=-1, keepdim=True)\n",
        "\n",
        "\n",
        "        subgoal = self._scale_subgoal(subgoal_normalized)\n",
        "        return subgoal, log_prob\n",
        "\n",
        "    def forward_critic(self, obs, goal, subgoal):\n",
        "        x = torch.cat([obs, goal, subgoal], dim=-1)\n",
        "        return self.q1(x), self.q2(x)\n",
        "\n",
        "    def forward_critic_target(self, obs, goal, subgoal):\n",
        "        x = torch.cat([obs, goal, subgoal], dim=-1)\n",
        "        return self.q1_target(x), self.q2_target(x)\n",
        "\n",
        "    def soft_update(self, tau: float = 0.005):\n",
        "        for tp, p in zip(self.q1_target.parameters(), self.q1.parameters()):\n",
        "            tp.data.copy_(tau * p.data + (1 - tau) * tp.data)\n",
        "        for tp, p in zip(self.q2_target.parameters(), self.q2.parameters()):\n",
        "            tp.data.copy_(tau * p.data + (1 - tau) * tp.data)\n",
        "\n",
        "\n",
        "print(\"✓ HighLevelPolicy defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoH7QTe-Numr",
        "outputId": "8c0164d2-857d-4c81-b06a-0810f03e18c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ HighLevelPolicy defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# LOW-LEVEL POLICY (TD3-style for CONTINUOUS actions)\n",
        "# ============================================================================\n",
        "\n",
        "class LowLevelPolicyContinuous(nn.Module):\n",
        "    \"\"\"\n",
        "    Low-level TD3-style policy that outputs CONTINUOUS actions to reach subgoals.\n",
        "    This is the key change from the original discrete DQN low-level policy.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        subgoal_dim: int,\n",
        "        action_dim: int,\n",
        "        hidden_dims: List[int] = [256, 256],\n",
        "        action_scale: float = 1.0,\n",
        "        device: str = \"cpu\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.action_dim = action_dim\n",
        "        self.action_scale = action_scale\n",
        "        self.device = device\n",
        "\n",
        "        input_dim = obs_dim + subgoal_dim\n",
        "\n",
        "        # Actor network (deterministic policy)\n",
        "        actor_layers = []\n",
        "        prev_dim = input_dim\n",
        "        for h in hidden_dims:\n",
        "            actor_layers.extend([nn.Linear(prev_dim, h), nn.ReLU()])\n",
        "            prev_dim = h\n",
        "        actor_layers.append(nn.Linear(prev_dim, action_dim))\n",
        "        actor_layers.append(nn.Tanh())  # Bound actions to [-1, 1]\n",
        "        self.actor = nn.Sequential(*actor_layers)\n",
        "\n",
        "        # Target actor\n",
        "        self.actor_target = deepcopy(self.actor)\n",
        "        for p in self.actor_target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Twin Q-networks\n",
        "        critic_input = input_dim + action_dim\n",
        "\n",
        "        def make_critic():\n",
        "            layers = []\n",
        "            prev = critic_input\n",
        "            for h in hidden_dims:\n",
        "                layers.extend([nn.Linear(prev, h), nn.ReLU()])\n",
        "                prev = h\n",
        "            layers.append(nn.Linear(prev, 1))\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        self.q1 = make_critic()\n",
        "        self.q2 = make_critic()\n",
        "        self.q1_target = deepcopy(self.q1)\n",
        "        self.q2_target = deepcopy(self.q2)\n",
        "\n",
        "        for p in self.q1_target.parameters():\n",
        "            p.requires_grad = False\n",
        "        for p in self.q2_target.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def get_action(self, obs: np.ndarray, subgoal: np.ndarray,\n",
        "                   noise: float = 0.0, deterministic: bool = False) -> np.ndarray:\n",
        "        \"\"\"Get continuous action.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            obs_t = torch.FloatTensor(obs).unsqueeze(0).to(self.device)\n",
        "            subgoal_t = torch.FloatTensor(subgoal).unsqueeze(0).to(self.device)\n",
        "            x = torch.cat([obs_t, subgoal_t], dim=-1)\n",
        "            action = self.actor(x).cpu().numpy().flatten()\n",
        "\n",
        "        if not deterministic and noise > 0:\n",
        "            action = action + np.random.normal(0, noise, size=action.shape)\n",
        "            action = np.clip(action, -1.0, 1.0)\n",
        "\n",
        "        return action * self.action_scale\n",
        "\n",
        "    def forward_actor(self, obs: torch.Tensor, subgoal: torch.Tensor) -> torch.Tensor:\n",
        "        x = torch.cat([obs, subgoal], dim=-1)\n",
        "        return self.actor(x) * self.action_scale\n",
        "\n",
        "    def forward_actor_target_smoothed(\n",
        "          self,\n",
        "          obs: torch.Tensor,\n",
        "          subgoal: torch.Tensor,\n",
        "          noise_clip: float = 0.5,\n",
        "          policy_noise: float = 0.2\n",
        "      ) -> torch.Tensor:\n",
        "          \"\"\"Target action with smoothing noise (TD3 feature).\"\"\"\n",
        "          x = torch.cat([obs, subgoal], dim=-1)\n",
        "          action = self.actor_target(x)\n",
        "\n",
        "          # Add clipped noise for target policy smoothing\n",
        "          noise = torch.randn_like(action) * policy_noise\n",
        "          noise = noise.clamp(-noise_clip, noise_clip)\n",
        "\n",
        "          # Clip action to valid range before scaling\n",
        "          action = (action + noise).clamp(-1.0, 1.0)\n",
        "\n",
        "          return action * self.action_scale\n",
        "\n",
        "    def forward_critic(self, obs, subgoal, action):\n",
        "        x = torch.cat([obs, subgoal, action], dim=-1)\n",
        "        return self.q1(x), self.q2(x)\n",
        "\n",
        "    def forward_critic_target(self, obs, subgoal, action):\n",
        "        x = torch.cat([obs, subgoal, action], dim=-1)\n",
        "        return self.q1_target(x), self.q2_target(x)\n",
        "\n",
        "    def soft_update(self, tau: float = 0.005):\n",
        "        for tp, p in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
        "            tp.data.copy_(tau * p.data + (1 - tau) * tp.data)\n",
        "        for tp, p in zip(self.q1_target.parameters(), self.q1.parameters()):\n",
        "            tp.data.copy_(tau * p.data + (1 - tau) * tp.data)\n",
        "        for tp, p in zip(self.q2_target.parameters(), self.q2.parameters()):\n",
        "            tp.data.copy_(tau * p.data + (1 - tau) * tp.data)\n",
        "\n",
        "\n",
        "print(\"✓ LowLevelPolicyContinuous (TD3-style) defined\")"
      ],
      "metadata": {
        "id": "watch_tier2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ea84b1-52f9-40a2-c7d4-e3a9d028c30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ LowLevelPolicyContinuous (TD3-style) defined\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# HAC AGENT WITHOUT HER (Baseline)\n",
        "# ============================================================================\n",
        "\n",
        "class HACAgentNoHER:\n",
        "    \"\"\"\n",
        "    HAC Agent with Hindsight Action Transitions (HAT) but WITHOUT Hindsight Goal Transitions (HGT).\n",
        "\n",
        "    Key mechanisms implemented:\n",
        "    1. HAT (Hindsight Action Transitions): Always relabel high-level \"action\" (subgoal)\n",
        "       with what was actually achieved. This ensures valid transitions despite non-stationary\n",
        "       low-level policy.\n",
        "    2. Subgoal Testing: With probability ~30%, test if low-level can reach commanded subgoal\n",
        "       deterministically. If it fails, penalize high-level to prevent \"impossible\" subgoals.\n",
        "\n",
        "    \"No HER\" means: NO Hindsight Goal Transitions (no relabeling of final goal).\n",
        "    HAT is ALWAYS enabled as it's essential for hierarchical learning.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        goal_dim: int,\n",
        "        action_dim: int,\n",
        "        subgoal_dim: int,\n",
        "        config: ExperimentConfig,\n",
        "        device: str = \"cpu\"\n",
        "    ):\n",
        "        self.obs_dim = obs_dim\n",
        "        self.goal_dim = goal_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.subgoal_dim = subgoal_dim\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        # HAC-specific parameters\n",
        "        self.subgoal_period = config.subgoal_period_k\n",
        "        self.subgoal_test_prob = 0.3  # Probability of testing subgoal reachability\n",
        "        self.subgoal_test_penalty = -config.subgoal_test_penalty_scale  # Penalty for unreachable subgoals\n",
        "\n",
        "        # High-level policy (SAC-style, outputs continuous subgoals)\n",
        "        self.high_policy = HighLevelPolicy(\n",
        "            obs_dim=obs_dim,\n",
        "            goal_dim=goal_dim,\n",
        "            subgoal_dim=subgoal_dim,\n",
        "            subgoal_range_x=config.subgoal_range_x,\n",
        "            subgoal_range_y=config.subgoal_range_y,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Low-level policy (TD3-style, outputs continuous primitive actions)\n",
        "        self.low_policy = LowLevelPolicyContinuous(\n",
        "            obs_dim=obs_dim,\n",
        "            subgoal_dim=subgoal_dim,\n",
        "            action_dim=action_dim,\n",
        "            action_scale=config.action_scale,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Optimizers for high-level policy\n",
        "        self.high_actor_optim = Adam(\n",
        "            list(self.high_policy.actor_net.parameters()) +\n",
        "            list(self.high_policy.mean_head.parameters()) +\n",
        "            list(self.high_policy.log_std_head.parameters()),\n",
        "            lr=config.high_level_lr\n",
        "        )\n",
        "        self.high_critic_optim = Adam(\n",
        "            list(self.high_policy.q1.parameters()) +\n",
        "            list(self.high_policy.q2.parameters()),\n",
        "            lr=config.high_level_lr\n",
        "        )\n",
        "        self.high_alpha_optim = Adam([self.high_policy.log_alpha], lr=config.high_level_lr)\n",
        "\n",
        "        # Optimizers for low-level policy\n",
        "        self.low_actor_optim = Adam(self.low_policy.actor.parameters(), lr=config.low_level_lr)\n",
        "        self.low_critic_optim = Adam(\n",
        "            list(self.low_policy.q1.parameters()) +\n",
        "            list(self.low_policy.q2.parameters()),\n",
        "            lr=config.low_level_lr\n",
        "        )\n",
        "\n",
        "        # Replay buffer\n",
        "        self.buffer = HACReplayBuffer(\n",
        "            buffer_size=config.buffer_size,\n",
        "            obs_dim=obs_dim,\n",
        "            goal_dim=goal_dim,\n",
        "            subgoal_dim=subgoal_dim,\n",
        "            action_dim=action_dim,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Counters\n",
        "        self.total_steps = 0\n",
        "        self.update_count = 0\n",
        "\n",
        "        # Episode state (will be set in reset())\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset agent state at episode start.\"\"\"\n",
        "        self.current_subgoal = None\n",
        "        self.steps_since_subgoal = 0\n",
        "        self.high_start_state = None\n",
        "        self.high_start_goal = None\n",
        "        self.is_testing_subgoal = False  # Track if currently testing subgoal reachability\n",
        "\n",
        "    def act(self, obs: Dict[str, np.ndarray], deterministic: bool = False) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Select action using hierarchical policy.\n",
        "\n",
        "        Args:\n",
        "            obs: Dictionary with 'observation', 'achieved_goal', 'desired_goal'\n",
        "            deterministic: If True, use deterministic policies (for evaluation)\n",
        "\n",
        "        Returns:\n",
        "            action: Continuous primitive action\n",
        "            subgoal: Current subgoal being pursued\n",
        "        \"\"\"\n",
        "        state = obs['observation']\n",
        "        final_goal = obs['desired_goal']\n",
        "\n",
        "        # Check if we need a new subgoal\n",
        "        if self.current_subgoal is None or self.steps_since_subgoal >= self.subgoal_period:\n",
        "            # Store state at subgoal selection time (for high-level transition)\n",
        "            self.high_start_state = state.copy()\n",
        "            self.high_start_goal = final_goal.copy()\n",
        "\n",
        "            # Decide if this will be a \"Subgoal Test\" transition\n",
        "            # During testing, we check if low-level can actually reach the commanded subgoal\n",
        "            if deterministic:\n",
        "                self.is_testing_subgoal = False  # No testing during evaluation\n",
        "            else:\n",
        "                self.is_testing_subgoal = (np.random.random() < self.subgoal_test_prob)\n",
        "\n",
        "            # Get new subgoal from high-level policy\n",
        "            # Use deterministic high-level during testing to get a \"real\" subgoal command\n",
        "            use_deterministic_high = deterministic or self.is_testing_subgoal\n",
        "            self.current_subgoal = self.high_policy.get_subgoal(\n",
        "                state, final_goal, deterministic=use_deterministic_high\n",
        "            )\n",
        "            self.steps_since_subgoal = 0\n",
        "\n",
        "        # Get primitive action from low-level policy\n",
        "        # During subgoal testing, low-level must also be deterministic\n",
        "        # to fairly assess if the subgoal is reachable\n",
        "        use_deterministic_low = deterministic or self.is_testing_subgoal\n",
        "        noise = 0.0 if use_deterministic_low else self.config.exploration_noise\n",
        "\n",
        "        action = self.low_policy.get_action(\n",
        "            state, self.current_subgoal, noise=noise, deterministic=use_deterministic_low\n",
        "        )\n",
        "        self.steps_since_subgoal += 1\n",
        "\n",
        "        return action, self.current_subgoal.copy()\n",
        "\n",
        "    def compute_low_reward(self, achieved: np.ndarray, subgoal: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Compute reward for low-level policy.\n",
        "        Sparse reward: 0 if reached subgoal, -1 otherwise.\n",
        "        \"\"\"\n",
        "        distance = np.linalg.norm(achieved[:self.subgoal_dim] - subgoal)\n",
        "        return 0.0 if distance < self.config.subgoal_threshold else -1.0\n",
        "\n",
        "    def compute_high_reward(self, achieved: np.ndarray, final_goal: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Compute reward for high-level policy.\n",
        "        Sparse reward: 0 if reached final goal, -1 otherwise.\n",
        "        \"\"\"\n",
        "        distance = np.linalg.norm(achieved[:self.goal_dim] - final_goal)\n",
        "        return 0.0 if distance < self.config.success_threshold else -1.0\n",
        "\n",
        "    def store_transition(self, obs, action, subgoal, next_obs, done, info):\n",
        "        \"\"\"\n",
        "        Store transitions for both levels with HAT (Hindsight Action Transitions).\n",
        "\n",
        "        Key insight: HAT is applied to ALL high-level transitions, not just some.\n",
        "        This ensures the high-level always sees valid (state, action, next_state) tuples\n",
        "        where \"action\" is what was actually achieved, not what was commanded.\n",
        "        \"\"\"\n",
        "        state = obs['observation']\n",
        "        achieved = obs['achieved_goal']\n",
        "        final_goal = obs['desired_goal']\n",
        "        next_state = next_obs['observation']\n",
        "        next_achieved = next_obs['achieved_goal']\n",
        "\n",
        "        # =====================================================================\n",
        "        # LOW-LEVEL TRANSITION (Standard - no HAT needed)\n",
        "        # =====================================================================\n",
        "        low_reward = self.compute_low_reward(next_achieved, subgoal)\n",
        "\n",
        "        # Low-level has its own \"done\" condition: either episode ends OR subgoal is reached\n",
        "        # This is important because the low-level policy should learn that reaching\n",
        "        # the subgoal is a terminal state for its own MDP\n",
        "        subgoal_reached = low_reward == 0.0  # Reward is 0 when subgoal is reached\n",
        "        low_done = done or subgoal_reached\n",
        "\n",
        "        self.buffer.add_low_transition(\n",
        "            obs=state,\n",
        "            subgoal=subgoal,\n",
        "            action=action,\n",
        "            reward=low_reward,\n",
        "            next_obs=next_state,\n",
        "            done=low_done,  # Use low-level specific done signal\n",
        "            achieved_goal=next_achieved\n",
        "        )\n",
        "\n",
        "        # =====================================================================\n",
        "        # HIGH-LEVEL TRANSITION (with HAT)\n",
        "        # =====================================================================\n",
        "        # Only store at subgoal boundaries (every K steps or episode end)\n",
        "        if self.steps_since_subgoal >= self.subgoal_period or done:\n",
        "            if self.high_start_state is not None:\n",
        "\n",
        "                # --- HINDSIGHT ACTION TRANSITION (HAT) ---\n",
        "                # Always relabel the \"action\" (subgoal) with what was actually achieved.\n",
        "                # This makes the transition valid: \"If I 'command' position X, I end up at X\"\n",
        "                # Without HAT, high-level sees: \"I commanded A, ended at B\" -> invalid transition\n",
        "                hat_action = next_achieved[:self.subgoal_dim].copy()\n",
        "\n",
        "                # Compute base reward (relative to final goal)\n",
        "                high_reward = self.compute_high_reward(next_achieved, final_goal)\n",
        "\n",
        "                # --- SUBGOAL TESTING PENALTY ---\n",
        "                # If we were testing and the low-level failed to reach the subgoal,\n",
        "                # add a penalty to discourage commanding unreachable subgoals\n",
        "                if self.is_testing_subgoal:\n",
        "                    dist_to_commanded_subgoal = np.linalg.norm(\n",
        "                        next_achieved[:self.subgoal_dim] - subgoal\n",
        "                    )\n",
        "                    if dist_to_commanded_subgoal > self.config.subgoal_threshold:\n",
        "                        # Low-level failed to reach the commanded subgoal\n",
        "                        # Penalize the high-level for commanding an unreachable subgoal\n",
        "                        high_reward += self.subgoal_test_penalty\n",
        "\n",
        "                # Store the HAT-relabeled transition\n",
        "                self.buffer.add_high_transition(\n",
        "                    obs=self.high_start_state,\n",
        "                    goal=self.high_start_goal,\n",
        "                    subgoal=hat_action,\n",
        "                    reward=high_reward,\n",
        "                    next_obs=next_state,\n",
        "                    done=done,\n",
        "                    segment_length=self.steps_since_subgoal  # NEW: actual segment length\n",
        "                )\n",
        "\n",
        "        self.total_steps += 1\n",
        "\n",
        "    def train_step(self) -> Dict[str, float]:\n",
        "        \"\"\"Perform one training step for both levels.\"\"\"\n",
        "        losses = {}\n",
        "        batch_size = self.config.batch_size\n",
        "\n",
        "        # Train high-level (SAC-style)\n",
        "        if self.buffer.can_sample_high(batch_size):  # Cleaner with helper method\n",
        "            batch = self.buffer.sample_high(batch_size)\n",
        "            if batch is not None:\n",
        "                high_loss = self._update_high_level(batch)\n",
        "                losses.update({f'high_{k}': v for k, v in high_loss.items()})\n",
        "\n",
        "        # Train low-level (TD3-style)\n",
        "        if self.buffer.can_sample_low(batch_size):\n",
        "            batch = self.buffer.sample_low(batch_size)\n",
        "            if batch is not None:\n",
        "                low_loss = self._update_low_level(batch)\n",
        "                losses.update({f'low_{k}': v for k, v in low_loss.items()})\n",
        "\n",
        "        self.update_count += 1\n",
        "        return losses\n",
        "\n",
        "    def _update_high_level(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:\n",
        "        \"\"\"Update high-level SAC policy.\"\"\"\n",
        "        obs = batch['obs']\n",
        "        goal = batch['goal']\n",
        "        subgoal = batch['subgoal']\n",
        "        reward = batch['reward']\n",
        "        next_obs = batch['next_obs']\n",
        "        done = batch['done']\n",
        "        segment_length = batch['segment_length'].clamp(1, 50)\n",
        "        # ✅ Add this debug check:\n",
        "        if reward.abs().max() > 10:\n",
        "            print(f\"WARNING: Large reward detected: {reward.abs().max():.2f}\")\n",
        "\n",
        "        # Discounted over K steps\n",
        "        segment_length = segment_length.clamp(1, 100)  # Prevent extreme values\n",
        "        gamma = self.config.gamma ** segment_length\n",
        "\n",
        "        # Update critics\n",
        "        with torch.no_grad():\n",
        "            next_subgoal, next_log_prob = self.high_policy.forward_actor(next_obs, goal)\n",
        "            q1_target, q2_target = self.high_policy.forward_critic_target(next_obs, goal, next_subgoal)\n",
        "            q_target = torch.min(q1_target, q2_target).clamp(-100, 100)\n",
        "            alpha = self.high_policy.log_alpha.exp().clamp(0.01, 1.0)\n",
        "            target = reward + gamma * (1 - done) * (q_target - alpha * next_log_prob)\n",
        "            target = target.clamp(-100, 100)\n",
        "\n",
        "        q1, q2 = self.high_policy.forward_critic(obs, goal, subgoal)\n",
        "        q1 = q1.clamp(-100, 100)\n",
        "        q2 = q2.clamp(-100, 100)\n",
        "        critic_loss = F.mse_loss(q1, target) + F.mse_loss(q2, target)\n",
        "\n",
        "        self.high_critic_optim.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(  # ✅ Gradient clipping\n",
        "            list(self.high_policy.q1.parameters()) + list(self.high_policy.q2.parameters()),\n",
        "            self.config.max_grad_norm\n",
        "        )\n",
        "        self.high_critic_optim.step()\n",
        "\n",
        "        # Update actor\n",
        "        new_subgoal, log_prob = self.high_policy.forward_actor(obs, goal)\n",
        "        q1_new, q2_new = self.high_policy.forward_critic(obs, goal, new_subgoal)\n",
        "        q_new = torch.min(q1_new, q2_new)\n",
        "\n",
        "        alpha = self.high_policy.log_alpha.exp().detach()\n",
        "        actor_loss = (alpha * log_prob - q_new).mean()\n",
        "\n",
        "        self.high_actor_optim.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(self.high_policy.actor_net.parameters()) +\n",
        "            list(self.high_policy.mean_head.parameters()) +\n",
        "            list(self.high_policy.log_std_head.parameters()),\n",
        "            self.config.max_grad_norm\n",
        "        )\n",
        "        self.high_actor_optim.step()\n",
        "\n",
        "        # Update alpha (entropy coefficient)\n",
        "        alpha_loss = -(self.high_policy.log_alpha *\n",
        "                      (log_prob.detach() + self.high_policy.target_entropy)).mean()\n",
        "\n",
        "        self.high_alpha_optim.zero_grad()\n",
        "        alpha_loss.backward()\n",
        "        self.high_alpha_optim.step()\n",
        "\n",
        "        # Soft update target networks\n",
        "        self.high_policy.soft_update(self.config.tau)\n",
        "\n",
        "        return {'critic_loss': critic_loss.item(), 'actor_loss': actor_loss.item()}\n",
        "\n",
        "    def _update_low_level(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:\n",
        "        \"\"\"Update low-level TD3 policy.\"\"\"\n",
        "        obs = batch['obs']\n",
        "        subgoal = batch['subgoal']\n",
        "        action = batch['action']\n",
        "        reward = batch['reward']\n",
        "        next_obs = batch['next_obs']\n",
        "        done = batch['done']\n",
        "\n",
        "        if reward.abs().max() > 10:\n",
        "            print(f\"WARNING: Large reward detected: {reward.abs().max():.2f}\")\n",
        "\n",
        "        # Update critics\n",
        "        with torch.no_grad():\n",
        "            # Target policy smoothing\n",
        "            next_action = self.low_policy.forward_actor_target_smoothed(\n",
        "                next_obs, subgoal,\n",
        "                noise_clip=self.config.noise_clip,\n",
        "                policy_noise=self.config.policy_noise\n",
        "            )\n",
        "            # Clamp to action scale (already done in method, but safe to keep)\n",
        "            next_action = next_action.clamp(-self.config.action_scale, self.config.action_scale)\n",
        "\n",
        "            q1_target, q2_target = self.low_policy.forward_critic_target(next_obs, subgoal, next_action)\n",
        "            q_target = torch.min(q1_target, q2_target).clamp(-100, 100)\n",
        "            target = reward + self.config.gamma * (1 - done) * q_target\n",
        "            target = target.clamp(-100, 100)\n",
        "\n",
        "        q1, q2 = self.low_policy.forward_critic(obs, subgoal, action)\n",
        "        critic_loss = F.mse_loss(q1, target) + F.mse_loss(q2, target)\n",
        "\n",
        "        self.low_critic_optim.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            list(self.low_policy.q1.parameters()) + list(self.low_policy.q2.parameters()),\n",
        "            self.config.max_grad_norm\n",
        "        )\n",
        "        self.low_critic_optim.step()\n",
        "\n",
        "        actor_loss_val = 0.0\n",
        "\n",
        "        # Delayed policy update (TD3 style)\n",
        "        if self.update_count % self.config.policy_delay == 0:\n",
        "            new_action = self.low_policy.forward_actor(obs, subgoal)\n",
        "            q1_new, _ = self.low_policy.forward_critic(obs, subgoal, new_action)\n",
        "            actor_loss = -q1_new.mean()\n",
        "\n",
        "            self.low_actor_optim.zero_grad()\n",
        "            actor_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                self.low_policy.actor.parameters(),\n",
        "                self.config.max_grad_norm\n",
        "            )\n",
        "            self.low_actor_optim.step()\n",
        "\n",
        "            actor_loss_val = actor_loss.item()\n",
        "\n",
        "            # Soft update target networks\n",
        "            self.low_policy.soft_update(self.config.tau)\n",
        "\n",
        "        return {'critic_loss': critic_loss.item(), 'actor_loss': actor_loss_val}\n",
        "\n",
        "print(\"✓ HACAgentNoHER defined\")"
      ],
      "metadata": {
        "id": "Pwa1SQbXNwKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc7138c-10a0-4631-e072-e90c08a62683"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ HACAgentNoHER defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# HAC AGENT WITH HER (Full Implementation)\n",
        "# ============================================================================\n",
        "\n",
        "class HACAgentWithHER(HACAgentNoHER):\n",
        "    \"\"\"\n",
        "    HAC Agent WITH Hindsight Goal Transitions (HGT/HER).\n",
        "\n",
        "    Extends HACAgentNoHER with:\n",
        "    - HGT for high-level: Relabel final goal with achieved positions\n",
        "    - HER for low-level: Relabel subgoals with future achieved positions\n",
        "\n",
        "    This class has ALL three HAC mechanisms:\n",
        "    1. HAT (inherited from parent)\n",
        "    2. Subgoal Testing (inherited from parent)\n",
        "    3. HGT/HER (added here)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        obs_dim: int,\n",
        "        goal_dim: int,\n",
        "        action_dim: int,\n",
        "        subgoal_dim: int,\n",
        "        config: ExperimentConfig,\n",
        "        device: str = \"cpu\"\n",
        "    ):\n",
        "        # Episode buffer for HER relabeling\n",
        "        self.episode_buffer = []\n",
        "        self.her_k = config.her_n_sampled_goal  # Number of HER samples per transition\n",
        "        super().__init__(obs_dim, goal_dim, action_dim, subgoal_dim, config, device)\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset agent state and process episode buffer for HER.\"\"\"\n",
        "        # Process completed episode with HER before clearing\n",
        "        if hasattr(self, 'episode_buffer') and len(self.episode_buffer) > 0:\n",
        "            self._apply_her_to_episode()\n",
        "        self.episode_buffer = []\n",
        "\n",
        "        # Call parent reset\n",
        "        super().reset()\n",
        "\n",
        "    def store_transition(self, obs, action, subgoal, next_obs, done, info):\n",
        "        \"\"\"\n",
        "        Store transition with HAT (from parent) and prepare for HER.\n",
        "        \"\"\"\n",
        "        state = obs['observation']\n",
        "        achieved = obs['achieved_goal']\n",
        "        final_goal = obs['desired_goal']\n",
        "        next_state = next_obs['observation']\n",
        "        next_achieved = next_obs['achieved_goal']\n",
        "\n",
        "        # Store in episode buffer for later HER processing\n",
        "        self.episode_buffer.append({\n",
        "            'state': state.copy(),\n",
        "            'action': action.copy(),\n",
        "            'subgoal': subgoal.copy(),\n",
        "            'next_state': next_state.copy(),\n",
        "            'achieved': achieved.copy(),\n",
        "            'next_achieved': next_achieved.copy(),\n",
        "            'final_goal': final_goal.copy(),\n",
        "            'done': done,\n",
        "            'high_start_state': self.high_start_state.copy() if self.high_start_state is not None else None,\n",
        "            'high_start_goal': self.high_start_goal.copy() if self.high_start_goal is not None else None,\n",
        "            'is_subgoal_boundary': self.steps_since_subgoal >= self.subgoal_period or done,\n",
        "            'is_testing_subgoal': self.is_testing_subgoal,\n",
        "        })\n",
        "\n",
        "        # =====================================================================\n",
        "        # LOW-LEVEL TRANSITION (Standard)\n",
        "        # =====================================================================\n",
        "        low_reward = self.compute_low_reward(next_achieved, subgoal)\n",
        "\n",
        "        # Low-level done: episode ends OR subgoal reached\n",
        "        subgoal_reached = low_reward == 0.0\n",
        "        low_done = done or subgoal_reached\n",
        "\n",
        "        self.buffer.add_low_transition(\n",
        "            obs=state,\n",
        "            subgoal=subgoal,\n",
        "            action=action,\n",
        "            reward=low_reward,\n",
        "            next_obs=next_state,\n",
        "            done=low_done,  # Low-level specific done\n",
        "            achieved_goal=next_achieved\n",
        "        )\n",
        "\n",
        "        # =====================================================================\n",
        "        # HIGH-LEVEL TRANSITION (with HAT + HGT)\n",
        "        # =====================================================================\n",
        "        if self.steps_since_subgoal >= self.subgoal_period or done:\n",
        "            if self.high_start_state is not None:\n",
        "\n",
        "                # --- HAT: Hindsight Action Transition ---\n",
        "                hat_action = next_achieved[:self.subgoal_dim].copy()\n",
        "                high_reward = self.compute_high_reward(next_achieved, final_goal)\n",
        "\n",
        "                # --- Subgoal Testing Penalty ---\n",
        "                if self.is_testing_subgoal:\n",
        "                    dist_to_commanded = np.linalg.norm(next_achieved[:self.subgoal_dim] - subgoal)\n",
        "                    if dist_to_commanded > self.config.subgoal_threshold:\n",
        "                        high_reward += self.subgoal_test_penalty\n",
        "\n",
        "                # Store original HAT transition\n",
        "                self.buffer.add_high_transition(\n",
        "                    obs=self.high_start_state,\n",
        "                    goal=self.high_start_goal,\n",
        "                    subgoal=hat_action,\n",
        "                    reward=high_reward,\n",
        "                    next_obs=next_state,\n",
        "                    done=done,\n",
        "                    segment_length=self.steps_since_subgoal\n",
        "                )\n",
        "\n",
        "                # --- HGT: Hindsight Goal Transition ---\n",
        "                # Relabel the GOAL with the achieved position\n",
        "                # This creates a \"successful\" transition where we pretend\n",
        "                # the final goal was where we actually ended up\n",
        "                hindsight_goal = next_achieved[:self.goal_dim].copy()\n",
        "                hindsight_reward = 0.0  # Success by definition (we reached \"the goal\")\n",
        "\n",
        "                self.buffer.add_high_transition(\n",
        "                    obs=self.high_start_state,\n",
        "                    goal=hindsight_goal,  # HGT: Relabeled goal\n",
        "                    subgoal=hat_action,   # Still use HAT\n",
        "                    reward=hindsight_reward,\n",
        "                    next_obs=next_state,\n",
        "                    done=done,\n",
        "                    segment_length=self.steps_since_subgoal\n",
        "                )\n",
        "\n",
        "        self.total_steps += 1\n",
        "\n",
        "    def _apply_her_to_episode(self):\n",
        "        \"\"\"\n",
        "        Apply HER to low-level transitions using 'future' strategy.\n",
        "\n",
        "        IMPORTANT: HER is applied WITHIN each K-step subgoal segment, not across\n",
        "        the entire episode. This maintains consistency because each segment has\n",
        "        a single subgoal, and relabeling should only use futures from that segment.\n",
        "        \"\"\"\n",
        "        if len(self.episode_buffer) < 2:\n",
        "            return\n",
        "\n",
        "        # First, identify segment boundaries\n",
        "        # A segment ends when is_subgoal_boundary is True\n",
        "        segments = []\n",
        "        current_segment_start = 0\n",
        "\n",
        "        for t, trans in enumerate(self.episode_buffer):\n",
        "            if trans['is_subgoal_boundary']:\n",
        "                # End of current segment (inclusive)\n",
        "                segments.append((current_segment_start, t + 1))\n",
        "                current_segment_start = t + 1\n",
        "\n",
        "        # Handle any remaining transitions (shouldn't happen if boundaries are correct)\n",
        "        if current_segment_start < len(self.episode_buffer):\n",
        "            segments.append((current_segment_start, len(self.episode_buffer)))\n",
        "\n",
        "        # Apply HER within each segment\n",
        "        for seg_start, seg_end in segments:\n",
        "            self._apply_her_to_segment(seg_start, seg_end)\n",
        "\n",
        "    def _apply_her_to_segment(self, seg_start: int, seg_end: int):\n",
        "        \"\"\"\n",
        "        Apply HER within a single K-step segment.\n",
        "\n",
        "        For each transition in the segment, sample future achieved positions\n",
        "        (within the same segment) as hindsight subgoals.\n",
        "        \"\"\"\n",
        "        segment_length = seg_end - seg_start\n",
        "        if segment_length < 2:\n",
        "            return\n",
        "\n",
        "        for t in range(seg_start, seg_end):\n",
        "            trans = self.episode_buffer[t]\n",
        "\n",
        "            # Future indices within this segment only\n",
        "            future_indices = list(range(t + 1, seg_end))\n",
        "            if len(future_indices) == 0:\n",
        "                continue\n",
        "\n",
        "            # Sample k future states from within this segment\n",
        "            n_samples = min(self.her_k, len(future_indices))\n",
        "            sampled_indices = np.random.choice(future_indices, size=n_samples, replace=False)\n",
        "\n",
        "            for idx in sampled_indices:\n",
        "                future_trans = self.episode_buffer[idx]\n",
        "\n",
        "                # Use future achieved position as the hindsight subgoal\n",
        "                hindsight_subgoal = future_trans['next_achieved'][:self.subgoal_dim].copy()\n",
        "\n",
        "                # Recompute reward with hindsight subgoal\n",
        "                hindsight_reward = self.compute_low_reward(\n",
        "                    trans['next_achieved'], hindsight_subgoal\n",
        "                )\n",
        "\n",
        "                # Compute proper done signal for HER transition\n",
        "                # Done if this transition reaches the hindsight subgoal\n",
        "                hindsight_subgoal_reached = hindsight_reward == 0.0\n",
        "                hindsight_done = trans['done'] or hindsight_subgoal_reached\n",
        "\n",
        "                # Add HER-relabeled low-level transition\n",
        "                self.buffer.add_low_transition(\n",
        "                    obs=trans['state'],\n",
        "                    subgoal=hindsight_subgoal,  # Relabeled subgoal\n",
        "                    action=trans['action'],\n",
        "                    reward=hindsight_reward,\n",
        "                    next_obs=trans['next_state'],\n",
        "                    done=hindsight_done,  # Proper done signal\n",
        "                    achieved_goal=trans['next_achieved']\n",
        "                )\n",
        "\n",
        "print(\"✓ HACAgentWithHER defined\")"
      ],
      "metadata": {
        "id": "kGTwI5goSkGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb03b0f-0fc7-4f79-f636-6e2c877bad4f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ HACAgentWithHER defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# HAC TRAINING AND EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_hac(agent, env: gym.Env, n_episodes: int, verbose: bool = False) -> Dict[str, float]:\n",
        "    \"\"\"Evaluate HAC agent (works for both with and without HER).\"\"\"\n",
        "    successes = []\n",
        "    steps_list = []\n",
        "    path_lengths = []\n",
        "    goal_distances = []\n",
        "    rewards_list = []\n",
        "    final_distances = []\n",
        "\n",
        "    for ep in range(n_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        agent.current_subgoal = None\n",
        "        agent.steps_since_subgoal = 0\n",
        "        agent.high_start_state = None\n",
        "        agent.high_start_goal = None\n",
        "        agent.is_testing_subgoal = False\n",
        "\n",
        "        start_pos = obs['achieved_goal'].copy()\n",
        "        goal_pos = obs['desired_goal'].copy()\n",
        "        goal_distance = np.linalg.norm(goal_pos - start_pos)\n",
        "\n",
        "        path_length = 0.0\n",
        "        prev_pos = start_pos.copy()\n",
        "        steps = 0\n",
        "        done = False\n",
        "        success = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            action, _ = agent.act(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            current_pos = obs['achieved_goal']\n",
        "            path_length += np.linalg.norm(current_pos - prev_pos)\n",
        "            prev_pos = current_pos.copy()\n",
        "            steps += 1\n",
        "            total_reward += reward\n",
        "\n",
        "            if info.get('is_success', False):\n",
        "                success = True\n",
        "\n",
        "        final_dist = np.linalg.norm(obs['achieved_goal'] - obs['desired_goal'])\n",
        "        final_distances.append(final_dist)\n",
        "\n",
        "        successes.append(float(success))\n",
        "        steps_list.append(steps)\n",
        "        path_lengths.append(path_length)\n",
        "        goal_distances.append(goal_distance)\n",
        "        rewards_list.append(total_reward)\n",
        "\n",
        "        if verbose and ep < 3:\n",
        "            print(f\"  Ep {ep}: success={success}, final_dist={final_dist:.3f}, steps={steps}\")\n",
        "\n",
        "    efficiencies = [gd / pl if pl > 0 else 0 for gd, pl in zip(goal_distances, path_lengths)]\n",
        "    successful_steps = [s for s, succ in zip(steps_list, successes) if succ]\n",
        "\n",
        "    return {\n",
        "        'success_rate': np.mean(successes),\n",
        "        'success_rate_std': np.std(successes),\n",
        "        'mean_steps': np.mean(steps_list),\n",
        "        'std_steps': np.std(steps_list),\n",
        "        'mean_steps_successful': np.mean(successful_steps) if successful_steps else float('inf'),\n",
        "        'mean_path_efficiency': np.mean(efficiencies),\n",
        "        'std_path_efficiency': np.std(efficiencies),\n",
        "        'mean_reward': np.mean(rewards_list),\n",
        "        'mean_final_distance': np.mean(final_distances),\n",
        "        'min_final_distance': np.min(final_distances),\n",
        "    }\n",
        "\n",
        "\n",
        "def train_hac_live(\n",
        "    config: ExperimentConfig,\n",
        "    seed: int,\n",
        "    use_her: bool = False,\n",
        "    experiment_name: str = \"tier3_live\",\n",
        "    plot_freq: int = 1000\n",
        "):\n",
        "    \"\"\"\n",
        "    Train HAC agent with LIVE loss visualization.\n",
        "\n",
        "    Args:\n",
        "        config: Experiment configuration\n",
        "        seed: Random seed\n",
        "        use_her: If True, use HACAgentWithHER, else use HACAgentNoHER\n",
        "        experiment_name: Name for logging\n",
        "        plot_freq: How often to update plots\n",
        "    \"\"\"\n",
        "    set_seeds(seed)\n",
        "\n",
        "    her_str = \"with_her\" if use_her else \"no_her\"\n",
        "    log_dir = os.path.join(config.log_dir, f\"{experiment_name}_{config.maze_size}_hac_{her_str}_seed{seed}\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "    # HAC uses CONTINUOUS actions (no discrete wrapper)\n",
        "    train_env = make_env(config, seed=seed, use_discrete=False, use_dense_reward=False)\n",
        "    eval_env = make_env(config, seed=seed + 1000, use_discrete=False, use_dense_reward=False)\n",
        "\n",
        "    # Get dimensions\n",
        "    obs, _ = train_env.reset()\n",
        "    obs_dim = obs['observation'].shape[0]\n",
        "    goal_dim = obs['desired_goal'].shape[0]\n",
        "    action_dim = train_env.action_space.shape[0]\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"🎯 Training HAC {'WITH' if use_her else 'WITHOUT'} HER - {MAZE_CONFIGS[config.maze_size]['name']} Maze\")\n",
        "    print(f\"Seed: {seed}, Total Steps: {config.total_timesteps:,}\")\n",
        "    print(f\"Action Space: Continuous ({action_dim}D)\")\n",
        "    print(f\"Subgoal Period K: {config.subgoal_period_k}\")\n",
        "    print(f\"{'=' * 60}\\n\")\n",
        "\n",
        "    # Create agent\n",
        "    AgentClass = HACAgentWithHER if use_her else HACAgentNoHER\n",
        "    agent = AgentClass(\n",
        "        obs_dim=obs_dim,\n",
        "        goal_dim=goal_dim,\n",
        "        action_dim=action_dim,\n",
        "        subgoal_dim=config.subgoal_dim,\n",
        "        config=config,\n",
        "        device=str(DEVICE)\n",
        "    )\n",
        "\n",
        "    # Initialize live loss plotter\n",
        "    loss_plotter = LiveLossPlotter(update_freq=plot_freq)\n",
        "\n",
        "    eval_history = []\n",
        "    total_steps = 0\n",
        "    best_success_rate = 0.0\n",
        "    episode_count = 0\n",
        "\n",
        "    pbar = tqdm(total=config.total_timesteps, desc=f\"Training HAC ({her_str})\")\n",
        "\n",
        "    while total_steps < config.total_timesteps:\n",
        "        obs, _ = train_env.reset()\n",
        "        agent.reset()\n",
        "        done = False\n",
        "        episode_count += 1\n",
        "\n",
        "        while not done and total_steps < config.total_timesteps:\n",
        "            action, subgoal = agent.act(obs)\n",
        "            next_obs, reward, terminated, truncated, info = train_env.step(action)\n",
        "            done = terminated or truncated\n",
        "\n",
        "            agent.store_transition(obs, action, subgoal, next_obs, done, info)\n",
        "            obs = next_obs\n",
        "            total_steps += 1\n",
        "\n",
        "            # Train and collect losses\n",
        "            if total_steps > config.learning_starts:\n",
        "                losses = agent.train_step()\n",
        "                if losses:\n",
        "                    loss_plotter.add_loss(total_steps, losses)\n",
        "\n",
        "                    if total_steps % plot_freq == 0:\n",
        "                        loss_plotter.update_plot()\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "            # Evaluate\n",
        "            if total_steps % config.eval_freq == 0:\n",
        "                metrics = evaluate_hac(agent, eval_env, config.n_eval_episodes)\n",
        "                metrics['timestep'] = total_steps\n",
        "                eval_history.append(metrics)\n",
        "\n",
        "                if metrics['success_rate'] > best_success_rate:\n",
        "                    best_success_rate = metrics['success_rate']\n",
        "\n",
        "                loss_plotter.add_eval_metrics(\n",
        "                    total_steps,\n",
        "                    metrics['success_rate'],\n",
        "                    metrics.get('mean_reward', 0)\n",
        "                )\n",
        "                loss_plotter.update_plot(force=True)\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'success': f\"{metrics['success_rate']:.1%}\",\n",
        "                    'best': f\"{best_success_rate:.1%}\"\n",
        "                })\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    # Final reset to process last episode's HER\n",
        "    if use_her:\n",
        "        agent.reset()\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    loss_plotter.update_plot(force=True)\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"✓ HAC ({her_str}) Training completed!\")\n",
        "    print(f\"Best success rate: {best_success_rate:.1%}\")\n",
        "    print(f\"Total episodes: {episode_count}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "\n",
        "    eval_df = pd.DataFrame(eval_history)\n",
        "    eval_df['seed'] = seed\n",
        "    eval_df['algorithm'] = f'hac_{her_str}'\n",
        "    eval_df['use_her'] = use_her\n",
        "    eval_df['maze_size'] = config.maze_size\n",
        "\n",
        "    train_env.close()\n",
        "    eval_env.close()\n",
        "    loss_plotter.close()\n",
        "\n",
        "\n",
        "    if config.save_models:\n",
        "        model_path = os.path.join(log_dir, \"hac_agent.pt\")\n",
        "        torch.save({\n",
        "            'high_policy_state_dict': agent.high_policy.state_dict(),\n",
        "            'low_policy_state_dict': agent.low_policy.state_dict(),\n",
        "            'config': config.to_dict(),\n",
        "        }, model_path)\n",
        "        print(f\"✓ Model saved to {model_path}\")\n",
        "\n",
        "\n",
        "\n",
        "    return agent, eval_df\n",
        "\n",
        "\n",
        "print(\"✓ evaluate_hac() and train_hac_live() defined\")"
      ],
      "metadata": {
        "id": "RL6qQI5M89ER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0009fbcf-927f-4036-fd8d-3f4c5ab9f089"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ evaluate_hac() and train_hac_live() defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# RUN ALL EXPERIMENTS (Both Mazes, All Methods)\n",
        "# ============================================================================\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "print(\"# RUNNING ALL EXPERIMENTS\")\n",
        "print(\"# - Maze sizes: Small (UMaze), Large\")\n",
        "print(\"# - Methods: DQN (Dense), DQN +/- HER, SAC +/- HER, TQC +/- HER, HAC +/- HER\")\n",
        "\n",
        "# Storage for all results\n",
        "all_results = {\n",
        "    'tier1': [], 'tier2': [], 'sac': [], 'tqc': [], 'tier3': [],\n",
        "}\n",
        "experiment_times = {}\n",
        "failed_experiments = []\n",
        "\n",
        "# Iterate over maze sizes\n",
        "for maze_size in ['small', 'large']:\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"MAZE: {MAZE_CONFIGS[maze_size]['name']} ({MAZE_CONFIGS[maze_size]['env_id']})\")\n",
        "    print(f\"{'=' * 80}\")\n",
        "\n",
        "    config = ExperimentConfig().update_for_maze(maze_size)\n",
        "\n",
        "    # Define all experiments\n",
        "    experiments = [\n",
        "        ('tier1', 'DQN Dense', lambda s: train_dqn_live(config, seed=s), {}),\n",
        "        ('tier2', 'DQN no HER', lambda s: train_dqn_her_live(config, seed=s, use_her=False), {}),\n",
        "        ('tier2', 'DQN with HER', lambda s: train_dqn_her_live(config, seed=s, use_her=True), {}),\n",
        "        ('sac', 'SAC no HER', lambda s: train_sac_live(config, seed=s, use_her=False), {}),\n",
        "        ('sac', 'SAC with HER', lambda s: train_sac_live(config, seed=s, use_her=True), {}),\n",
        "        ('tqc', 'TQC no HER', lambda s: train_tqc_live(config, seed=s, use_her=False), {}),\n",
        "        ('tqc', 'TQC with HER', lambda s: train_tqc_live(config, seed=s, use_her=True), {}),\n",
        "        ('tier3', 'HAC no HER', lambda s: train_hac_live(config, seed=s, use_her=False), {}),\n",
        "        ('tier3', 'HAC with HER', lambda s: train_hac_live(config, seed=s, use_her=True), {}),\n",
        "    ]\n",
        "\n",
        "    for tier, name, train_fn, _ in experiments:\n",
        "        print(f\"\\n>>> {name} - {maze_size} maze\")\n",
        "        for seed in config.seeds:\n",
        "            exp_key = f'{name}_{maze_size}_{seed}'\n",
        "            try:\n",
        "                start_time = time.time()\n",
        "                model, eval_df = train_fn(seed)\n",
        "                experiment_times[exp_key] = time.time() - start_time\n",
        "                all_results[tier].append(eval_df)\n",
        "                print(f\"  ✓ Seed {seed} complete ({experiment_times[exp_key]:.1f}s)\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ Seed {seed} FAILED: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()  # Print full traceback for debugging\n",
        "                failed_experiments.append(exp_key)\n",
        "                break\n",
        "\n",
        "    # Checkpoint after each maze\n",
        "    checkpoint_path = os.path.join(config.log_dir, f'checkpoint_{maze_size}.pkl')\n",
        "    with open(checkpoint_path, 'wb') as f:\n",
        "        pickle.dump(all_results, f)\n",
        "    print(f\"✓ Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "# Combine and save results\n",
        "tier1_df = pd.concat(all_results['tier1'], ignore_index=True) if all_results['tier1'] else pd.DataFrame()\n",
        "tier2_df = pd.concat(all_results['tier2'], ignore_index=True) if all_results['tier2'] else pd.DataFrame()\n",
        "sac_df = pd.concat(all_results['sac'], ignore_index=True) if all_results['sac'] else pd.DataFrame()\n",
        "tqc_df = pd.concat(all_results['tqc'], ignore_index=True) if all_results['tqc'] else pd.DataFrame()\n",
        "tier3_df = pd.concat(all_results['tier3'], ignore_index=True) if all_results['tier3'] else pd.DataFrame()\n",
        "\n",
        "# Save all results\n",
        "all_df = pd.concat([tier1_df, tier2_df, sac_df, tqc_df, tier3_df], ignore_index=True)\n",
        "all_df.to_csv(os.path.join(config.log_dir, 'all_results.csv'), index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"✓ ALL EXPERIMENTS COMPLETE!\")\n",
        "print(f\"Total time: {sum(experiment_times.values()) / 60:.1f} minutes\")\n",
        "if failed_experiments:\n",
        "    print(f\"⚠️ Failed experiments: {failed_experiments}\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "L23wKrHX8-xh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "1e4be09ca3cc42afa0076edb237af35e",
            "ba62082f070143c282656b6479ada387",
            "eb1355937c6444a796c366f03ac5454d",
            "99dbbc36751040e6b193f87875433516",
            "f4aba92ae7004c789765fa8476a45db2",
            "5b2254932b8344a4b05096574fa9db61",
            "118f1666805b4808a4b6ed8bed7cee2d",
            "fee621e3a4af4b8fa66e971402d58b46",
            "249fa69b69084c29a5393aff168209a4",
            "93f4c5ca18eb4d06a06965bab604121c",
            "b050b1abb84d47669f437f4a868af0d7",
            "7415cc88832d4e84a2ef894453a15dc8",
            "a68d7d2e36bc41ada3b5d9b9d671a4db",
            "35d7658e1b314d88b4ff3f5026e21d18",
            "7a39ec12f4364d129b1af30b2df450e8",
            "47b4eb8c436d4ef4a56cd231a5fde9c5",
            "e237cfdde8864b0091b0338a6fbb7897",
            "ac0fa7b246b94a30a15b811dc57b5f69",
            "6b363522e6144e81835fe33b21b0f7ff",
            "6eaff2fb330247308753a097399edb77",
            "c8264842c9e240ff9bd92bbb97ae3533",
            "8ce268efe714439384f9d753e70c7a08",
            "f0dfc7d422e24f94995b905a39180766",
            "eb01a6677a1947c2b1ba7128ccff0f9d",
            "ab09c87826784732b53f565d14e7902d",
            "ed17eaa1d9ff45d28009653339beadea",
            "6e21f6a0ec7b4864921690fce0373b23",
            "3b7c4d7fd95848ad85175037996fe5c2",
            "db58788c6a4244b5a85c30df31940e85",
            "945693fd95f941aaa4d385fcc9f2d2da",
            "f95a40b64f1d42ee8fdc21b8cdff729d",
            "53d8f912b5dd46a3a84a83cfc3de6c5a",
            "cef8180d9c7c4e00ab48e845e56e223a",
            "d600a384997e407ea7624c22a9cb0070",
            "8575ecedced4490e8c5a56f5ce032d52",
            "c3c940075ef74b118471b40295d4b0ff",
            "da0fc6c246c24d9f957447f715db8daa",
            "a1e2e2e4f1e042eaa7f7283beb910bc2",
            "1006c9a3dffd4244acbfe4ba7f49c46b",
            "02e5de24fc314cbaaf65b301335bedcc",
            "fcef836c5a46416fbdc65f616f7cde95",
            "cb83f85c67634eddb67fc9a4d2208e4b",
            "0837e93eec144e4ca599f6916e46107f",
            "57fd1910e56e47deab1d44b46a276777",
            "6e4a563835554606b89111bc165a5033",
            "0c9b2797044342669203413825346663",
            "276a25043691493caf6ac094fe4127c0",
            "11f74208b1be4c789cfd5a1b420ae472"
          ]
        },
        "outputId": "f2691ce6-cbc2-4f40-b33a-83e47dc0fae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAHqCAYAAAB/bWzAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd8FGX+B/DPzGxN7wkhdJCOKCBFED2RakHB9tMT9E7xFBXxLHgnRVTUs2A5wUNFzwPrIWcFQUGRJogUAektQHqy2WT7zvP7Y/LMzmxJNiGQ9n3fy9cluzOzzz47IdnPfuf7CIwxBkIIIYQQQgghhBBCCCGNgtjQAyCEEEIIIYQQQgghhBASQKEtIYQQQgghhBBCCCGENCIU2hJCCCGEEEIIIYQQQkgjQqEtIYQQQgghhBBCCCGENCIU2hJCCCGEEEIIIYQQQkgjQqEtIYQQQgghhBBCCCGENCIU2hJCCCGEEEIIIYQQQkgjQqEtIYQQQgghhBBCCCGENCIU2hJCCCGEEEIIIYQQQkgjQqEtIU3I5MmT0b59+zrtO3v2bAiCUL8DIoQQQgghhBBCCAB6303qF4W2hNQDQRCi+m/t2rUNPdQGMXnyZMTFxTX0MAghhDRyu3btwsSJE9GuXTtYLBa0bt0aV1xxBV577bWGHlqDO3r0qO5vClEUkZKSgjFjxmDjxo11Pu4bb7yBd999t/4GSgghpF69++676r/9P/30U8j9jDG0adMGgiDgyiuvbIARRq99+/a632WxsbG46KKL8O9//7uhh0ZIo2Ro6AEQ0hy8//77uu///e9/Y9WqVSG3d+/e/YweZ9GiRZBluU77/v3vf8djjz12Ro9PCCGEnC0bNmzAZZddhrZt2+LOO+9EVlYWTpw4gU2bNuGVV17Bfffd19BDbBRuvvlmjB07Fn6/H/v378cbb7yByy67DFu2bEHv3r1rfbw33ngDaWlpmDx5cv0PlhBCSL2xWCxYunQphg4dqrv9hx9+QG5uLsxmcwONrHb69u2Lhx56CABw+vRpvPXWW5g0aRLcbjfuvPPOBh4dIY0LhbaE1INbb71V9/2mTZuwatWqkNuDORwOxMTERP04RqOxTuMDAIPBAIOBfuQJIYQ0Tk8//TQSExOxZcsWJCUl6e4rKChomEE1QhdeeKHu74thw4ZhzJgxWLBgAd54440GHBkhhJCzaezYsfjkk0/w6quv6t7XLV26FP369UNRUVEDji56rVu31v0emzx5Mjp27IiXX365SYS2Pp8PsizDZDI19FBIC0DtEQg5Ry699FL06tULv/zyCy655BLExMTg8ccfBwD873//w7hx45CdnQ2z2YxOnTph7ty58Pv9umME97Tll0q+8MIL+Ne//oVOnTrBbDZjwIAB2LJli27fcL11BEHA1KlTsXz5cvTq1Qtmsxk9e/bEihUrQsa/du1a9O/fHxaLBZ06dcKbb75Z7/16PvnkE/Tr1w9WqxVpaWm49dZbcfLkSd02eXl5uP3225GTkwOz2YxWrVrhmmuuwdGjR9Vttm7dilGjRiEtLQ1WqxUdOnTAHXfcoTuOLMuYP38+evbsCYvFgszMTEyZMgWlpaW67aI5FiGEkDN36NAh9OzZMySwBYCMjAz1a/67L9wl/YIgYPbs2brbTp48iT/96U/q79gOHTrgL3/5Czwej7pNWVkZHnzwQbRv3x5msxk5OTm47bbbdG+A3W43Zs2ahc6dO8NsNqNNmzZ45JFH4Ha7dY+3atUqDB06FElJSYiLi0PXrl3V3/fca6+9hp49eyImJgbJycno378/li5dWovZChg2bBgAZf60Fi9ejD/84Q/IyMiA2WxGjx49sGDBAt027du3x+7du/HDDz+ol6peeumlunmZNm0a2rRpA7PZjM6dO+O5556r81U/hBBC6u7mm29GcXExVq1apd7m8Xjw6aef4v/+7//C7hPte55o34/y97R79uzBZZddhpiYGLRu3RrPP/98nZ9Xeno6unXrFvJ7LJqxT58+HampqWCMqbfdd999EAQBr776qnpbfn4+BEFQfw96PB7MnDkT/fr1Q2JiImJjYzFs2DCsWbNGNwbt++358+er77f37NkDAPjpp58wYMAA3XtkQuoTld0Rcg4VFxdjzJgxuOmmm3DrrbciMzMTgNKnKC4uDtOnT0dcXBy+//57zJw5E+Xl5fjHP/5R43GXLl0Ku92OKVOmQBAEPP/887juuutw+PDhGqtzf/rpJyxbtgz33HMP4uPj8eqrr2LChAk4fvw4UlNTAQC//vorRo8ejVatWmHOnDnw+/148sknkZ6efuaTUuXdd9/F7bffjgEDBmDevHnIz8/HK6+8gvXr1+PXX39V38RPmDABu3fvxn333Yf27dujoKAAq1atwvHjx9XvR44cifT0dDz22GNISkrC0aNHsWzZMt3jTZkyRX3M+++/H0eOHMHrr7+OX3/9FevXr4fRaIz6WIQQQs5cu3btsHHjRvz222/o1atXvRzz1KlTuOiii1BWVoa77roL3bp1w8mTJ/Hpp5/C4XDAZDKhoqICw4YNw969e3HHHXfgwgsvRFFRET7//HPk5uYiLS0Nsizj6quvxk8//YS77roL3bt3x65du/Dyyy9j//79WL58OQBg9+7duPLKK9GnTx88+eSTMJvNOHjwINavX6+OadGiRbj//vsxceJEPPDAA3C5XNi5cyc2b94c8U13dfiHlsnJybrbFyxYgJ49e+Lqq6+GwWDAF198gXvuuQeyLOPee+8FAMyfPx/33Xcf4uLi8Le//Q0A1L9NHA4Hhg8fjpMnT2LKlClo27YtNmzYgBkzZuD06dOYP39+rcdKCCGk7tq3b4/Bgwfjgw8+wJgxYwAA33zzDWw2G2666SZdSMlF854HqN370dLSUowePRrXXXcdbrjhBnz66ad49NFH0bt3b3VcteHz+ZCbmxvyeyyasQ8bNgwvv/wydu/erf7tsG7dOoiiiHXr1uH+++9XbwOASy65BABQXl6Ot956CzfffDPuvPNO2O12vP322xg1ahR+/vln9O3bVzeWxYsXw+Vy4a677oLZbEZKSgp27dqlvlecPXs2fD4fZs2apf4eJaReMEJIvbv33ntZ8I/X8OHDGQC2cOHCkO0dDkfIbVOmTGExMTHM5XKpt02aNIm1a9dO/f7IkSMMAEtNTWUlJSXq7f/73/8YAPbFF1+ot82aNStkTACYyWRiBw8eVG/bsWMHA8Bee+019barrrqKxcTEsJMnT6q3HThwgBkMhpBjhjNp0iQWGxsb8X6Px8MyMjJYr169mNPpVG//8ssvGQA2c+ZMxhhjpaWlDAD7xz/+EfFYn332GQPAtmzZEnGbdevWMQBsyZIluttXrFihuz2aYxFCCKkf3377LZMkiUmSxAYPHsweeeQRtnLlSubxeHTb8d99ixcvDjkGADZr1iz1+9tuu42Johj233FZlhljjM2cOZMBYMuWLYu4zfvvv89EUWTr1q3T3b9w4UIGgK1fv54xxtjLL7/MALDCwsKIz/Oaa65hPXv2jHh/JPx5z5kzhxUWFrK8vDy2bt06NmDAAAaAffLJJ7rtw/1tMWrUKNaxY0fdbT179mTDhw8P2Xbu3LksNjaW7d+/X3f7Y489xiRJYsePH6/1cyCEEFJ7ixcvVt+TvP766yw+Pl79N/76669nl112GWOMsXbt2rFx48ap+0X7noex6N+P8ve0//73v9Xb3G43y8rKYhMmTKjxubRr146NHDmSFRYWssLCQrZr1y72xz/+kQFg9957b63HXlBQwACwN954gzHGWFlZGRNFkV1//fUsMzNT3e/+++9nKSkp6u91n8/H3G637tilpaUsMzOT3XHHHept/HdvQkICKygo0G0/fvx4ZrFY2LFjx9Tb9uzZwyRJiuo9MiHRoPYIhJxDZrMZt99+e8jtVqtV/dput6OoqAjDhg2Dw+HA77//XuNxb7zxRt0nk/xSycOHD9e474gRI9CpUyf1+z59+iAhIUHd1+/3Y/Xq1Rg/fjyys7PV7Tp37lynT1LD2bp1KwoKCnDPPffAYrGot48bNw7dunXDV199BUCZJ5PJhLVr14Zc0sPxitwvv/wSXq837DaffPIJEhMTccUVV6CoqEj9r1+/foiLi1Mvi4nmWIQQQurHFVdcgY0bN+Lqq6/Gjh078Pzzz2PUqFFo3bo1Pv/881ofT5ZlLF++HFdddRX69+8fcj9v7/Pf//4X559/Pq699tqI23zyySfo3r07unXrpvu98Yc//AEAQn5v/O9//4vYQiApKQm5ubkhbYyiNWvWLKSnpyMrK0utEH7xxRcxceJE3Xbavy1sNhuKioowfPhwHD58GDabrcbH+eSTTzBs2DAkJyfrnvOIESPg9/vx448/1mn8hBBC6u6GG26A0+nEl19+Cbvdji+//DLiVRrRvucBavd+NC4uTteT1mQy4aKLLorqvScAfPvtt0hPT0d6ejp69+6N999/H7fffruuojfasfPWCvx30vr16yFJEh5++GHk5+fjwIEDAJRK26FDh6q/1yVJUnvSyrKMkpIS+Hw+9O/fH9u2bQsZ84QJE3RXmfr9fqxcuRLjx49H27Zt1du7d++OUaNGRTUPhESDQltCzqHWrVuHbVi+e/duXHvttUhMTERCQgLS09PVX4TRvLHS/qIAApdIRgo2q9uX78/3LSgogNPpROfOnUO2C3dbXRw7dgwA0LVr15D7unXrpt5vNpvx3HPP4ZtvvkFmZiYuueQSPP/888jLy1O3Hz58OCZMmIA5c+YgLS0N11xzDRYvXqzrOXjgwAHYbDZkZGSofzDw/yoqKtQFb6I5FiGEkPozYMAALFu2DKWlpfj5558xY8YM2O12TJw4Ue0fF63CwkKUl5fX2Grh0KFDNW5z4MAB7N69O+R3xnnnnQcgsFDajTfeiIsvvhh//vOfkZmZiZtuugkff/yxLsB99NFHERcXh4suughdunTBvffeq2ufUJO77roLq1atwhdffIEHH3wQTqczpOcgoLxxHTFiBGJjY5GUlIT09HS1t240f1scOHAAK1asCHnOI0aM0D1nQggh5w7/d3jp0qVYtmwZ/H5/yId2XLTveYDavR/NyckJWddE+/6xJgMHDsSqVauwYsUKvPDCC0hKSkJpaanufXJtxj5s2DC1/cG6devQv39/9O/fHykpKVi3bh3Ky8uxY8cOtbCJe++999CnTx9YLBakpqYiPT0dX331VdjfkR06dNB9X1hYCKfTiS5duoRsG+49LSF1RT1tCTmHtJ9gcmVlZRg+fDgSEhLw5JNPolOnTrBYLNi2bRseffTRqBb7kCQp7O1M05D9bOzbEKZNm4arrroKy5cvx8qVK/HEE09g3rx5+P7773HBBRdAEAR8+umn2LRpE7744gusXLkSd9xxB1588UVs2rQJcXFxkGUZGRkZWLJkSdjH4J+iRnMsQggh9c9kMmHAgAEYMGAAzjvvPNx+++345JNPMGvWrIgLYIYLLuuLLMvo3bs3XnrppbD3t2nTBoDye/7HH3/EmjVr8NVXX2HFihX46KOP8Ic//AHffvstJElC9+7dsW/fPnz55ZdYsWIF/vvf/+KNN97AzJkzMWfOnBrH0qVLFzU4vfLKKyFJEh577DFcdtllakXxoUOHcPnll6Nbt2546aWX0KZNG5hMJnz99dd4+eWXo/rbQpZlXHHFFXjkkUfC3s8Da0IIIefW//3f/+HOO+9EXl4exowZE3YBTwBRv+ep7fvRM33/mJaWpv4eGzVqFLp164Yrr7wSr7zyCqZPn16rsQPA0KFDsWjRIhw+fBjr1q3DsGHDIAgChg4dinXr1iE7OxuyLOtC2//85z+YPHkyxo8fj4cffhgZGRmQJAnz5s0LWRANCP8+npBzgUJbQhrY2rVrUVxcjGXLlqmN0QHgyJEjDTiqgIyMDFgsFhw8eDDkvnC31UW7du0AAPv27VMvNeX27dun3s916tQJDz30EB566CEcOHAAffv2xYsvvoj//Oc/6jaDBg3CoEGD8PTTT2Pp0qW45ZZb8OGHH+LPf/4zOnXqhNWrV+Piiy+O6hdwdccihBBydvEg8vTp0wACV5OUlZXptuNXZXDp6elISEjAb7/9Vu3xO3XqFNU2O3bswOWXXx4xNOZEUcTll1+Oyy+/HC+99BKeeeYZ/O1vf8OaNWvUN6mxsbG48cYbceONN8Lj8eC6667D008/jRkzZujaBEXjb3/7GxYtWoS///3vWLFiBQDgiy++gNvtxueff667oiZ4VWwAEZ9Pp06dUFFRoY6ZEEJI43DttddiypQp2LRpEz766KOI20X7nqeh34+OGzcOw4cPxzPPPIMpU6YgNja2Vu/XeBi7atUqbNmyBY899hgAZdGxBQsWIDs7G7GxsejXr5+6z6effoqOHTti2bJlut+Ds2bNimrM6enpsFqtavsFrX379kV1DEKiQe0RCGlg/JNK7SeTHo8Hb7zxRkMNSUeSJIwYMQLLly/HqVOn1NsPHjyIb775pl4eo3///sjIyMDChQt1rQe++eYb7N27F+PGjQOgrGTtcrl0+3bq1Anx8fHqfqWlpSGf8vLVP/k2N9xwA/x+P+bOnRsyFp/PpwYB0RyLEEJI/VizZk3YKp2vv/4aQOByw4SEBKSlpYX0VA3+vSmKIsaPH48vvvgCW7duDTkuf6wJEyZgx44d+OyzzyJuc8MNN+DkyZNYtGhRyDZOpxOVlZUAgJKSkpD7g39vFBcX6+43mUzo0aMHGGN16p+elJSEKVOmYOXKldi+fTuA8H9b2Gw2LF68OGT/2NjYkAAcUJ7zxo0bsXLlypD7ysrK4PP5aj1WQgghZy4uLg4LFizA7NmzcdVVV0XcLtr3PI3h/eijjz6K4uJi9fdstGMHlNYFrVu3xssvvwyv14uLL74YgBLmHjp0CJ9++ikGDRoEgyFQsxjuOW/evBkbN26MarySJGHUqFFYvnw5jh8/rt6+d+/esL83CakrqrQlpIENGTIEycnJmDRpEu6//34IgoD333+/UbUnmD17Nr799ltcfPHF+Mtf/gK/34/XX38dvXr1Ut8g1sTr9eKpp54KuT0lJQX33HMPnnvuOdx+++0YPnw4br75ZuTn5+OVV15B+/bt8eCDDwIA9u/fj8svvxw33HADevToAYPBgM8++wz5+fm46aabACi9id544w1ce+216NSpE+x2OxYtWoSEhASMHTsWgNKrdsqUKZg3bx62b9+OkSNHwmg04sCBA/jkk0/wyiuvYOLEiVEdixBCSP2477774HA4cO2116Jbt27weDzYsGEDPvroI7Rv3163kOef//xnPPvss/jzn/+M/v3748cff8T+/ftDjvnMM8/g22+/xfDhw3HXXXehe/fuOH36ND755BP89NNPSEpKwsMPP4xPP/0U119/Pe644w7069cPJSUl+Pzzz7Fw4UKcf/75+OMf/4iPP/4Yd999N9asWYOLL74Yfr8fv//+Oz7++GOsXLkS/fv3x5NPPokff/wR48aNQ7t27VBQUIA33ngDOTk5GDp0KABg5MiRyMrKwsUXX4zMzEzs3bsXr7/+OsaNG4f4+Pg6zd0DDzyA+fPn49lnn8WHH36IkSNHwmQy4aqrrsKUKVNQUVGBRYsWISMjQ61Y5vr164cFCxbgqaeeQufOnZGRkYE//OEPePjhh/H555/jyiuvxOTJk9GvXz9UVlZi165d+PTTT3H06FGkpaXVabyEEELOzKRJk2rcJtr3PI3h/eiYMWPQq1cvvPTSS7j33nujHjs3bNgwfPjhh+jdu7d6Rc6FF16I2NhY7N+/P2SxtiuvvBLLli3Dtddei3HjxuHIkSNYuHAhevTogYqKiqjGPGfOHKxYsQLDhg3DPffcA5/Ph9deew09e/bEzp07629ySMvGCCH17t5772XBP17Dhw9nPXv2DLv9+vXr2aBBg5jVamXZ2dnskUceYStXrmQA2Jo1a9TtJk2axNq1a6d+f+TIEQaA/eMf/wg5JgA2a9Ys9ftZs2aFjAkAu/fee0P2bdeuHZs0aZLutu+++45dcMEFzGQysU6dOrG33nqLPfTQQ8xisUSYhYBJkyYxAGH/69Spk7rdRx99xC644AJmNptZSkoKu+WWW1hubq56f1FREbv33ntZt27dWGxsLEtMTGQDBw5kH3/8sbrNtm3b2M0338zatm3LzGYzy8jIYFdeeSXbunVryLj+9a9/sX79+jGr1cri4+NZ79692SOPPMJOnTpV62MRQgg5M9988w274447WLdu3VhcXBwzmUysc+fO7L777mP5+fm6bR0OB/vTn/7EEhMTWXx8PLvhhhtYQUFByO8+xhg7duwYu+2221h6ejozm82sY8eO7N5772Vut1vdpri4mE2dOpW1bt2amUwmlpOTwyZNmsSKiorUbTweD3vuuedYz549mdlsZsnJyaxfv35szpw5zGazMcaU35XXXHMNy87OZiaTiWVnZ7Obb76Z7d+/Xz3Om2++yS655BKWmprKzGYz69SpE3v44YfVY0RS3e98xhibPHkykySJHTx4kDHG2Oeff8769OnDLBYLa9++PXvuuefYO++8wwCwI0eOqPvl5eWxcePGsfj4eAaADR8+XL3PbrezGTNmsM6dOzOTycTS0tLYkCFD2AsvvMA8Hk+14yWEEFI/Fi9ezACwLVu2VLtdu3bt2Lhx40Jur+k9D2PRvx+N9J42+H1qbcfIGGPvvvsuA8AWL15cq7Ezxtg///lPBoD95S9/0d0+YsQIBoB99913uttlWWbPPPMMa9euHTObzeyCCy5gX375Za3ebzPG2A8//MD69evHTCYT69ixI1u4cGHY992E1JXAWCMq5yOENCnjx4/H7t27w/byIYQQQgghhBBCCCF1Qz1tCSFRcTqduu8PHDiAr7/+GpdeemnDDIgQQgghhBBCCCGkmaJKW0JIVFq1aoXJkyejY8eOOHbsGBYsWAC3241ff/0VXbp0aejhEUIIIYQQQgghhDQbtBAZISQqo0ePxgcffIC8vDyYzWYMHjwYzzzzDAW2hBBCCCGEEEIIIfWM2iMQQqKyePFiHD16FC6XCzabDStWrMCFF17Y0MMihFTjxx9/xFVXXYXs7GwIgoDly5fr7meMYebMmWjVqhWsVitGjBgR0qO6pKQEt9xyCxISEpCUlIQ//elPUa+qSwghhBBCCCGkbii0JYQQQpqpyspKnH/++fjnP/8Z9v7nn38er776KhYuXIjNmzcjNjYWo0aNgsvlUre55ZZbsHv3bqxatQpffvklfvzxR9x1113n6ikQQgghhBBCSItEPW0JIYSQFkAQBHz22WcYP348AKXKNjs7Gw899BD++te/AgBsNhsyMzPx7rvv4qabbsLevXvRo0cPbNmyBf379wcArFixAmPHjkVubi6ys7Mb6ukQQgghhBBCSLNGPW3rgSzLOHXqFOLj4yEIQkMPhxBCyFnGGIPdbkd2djZEsWletHLkyBHk5eVhxIgR6m2JiYkYOHAgNm7ciJtuugkbN25EUlKSGtgCwIgRIyCKIjZv3oxrr7025Lhutxtut1v9XpZllJSUIDU1lX5HEkJIC9Ecfk+eK/RekhBCWp5of09SaFsPTp06hTZt2jT0MAghhJxjJ06cQE5OTkMPo07y8vIAAJmZmbrbMzMz1fvy8vKQkZGhu99gMCAlJUXdJti8efMwZ86cszBiQgghTU1T/j15rtB7SUIIablq+j1JoW09iI+PB6BMdkJCQgOPpu5kWUZhYSHS09PpE3ENmpfwaF7Co3kJr7nNS3l5Odq0aaP++08CZsyYgenTp6vf22w2tG3bFr/88gvat2/fLF7/MyHLMoqKipCWltai54LmQUHzoKB5CGguc1FeXo527drR78ko8Dnatm0bOnTo0KRf9zPV3P5ePBM0FwqaBwXNg6I5zUO07ycptK0H/DKWhISEJh/aulwuJCQkNPkfgPpE8xIezUt4NC/hNdd5acqXMWZlZQEA8vPz0apVK/X2/Px89O3bV92moKBAt5/P50NJSYm6fzCz2Qyz2Rxye3x8PJKSkprV618XsizD4/G0+LmgeVDQPChoHgKay1zwsTfl35PnCp+juLi4Zvd3Um01178X64LmQkHzoKB5UDTHeajp92TzeJaEEEIIqZUOHTogKysL3333nXpbeXk5Nm/ejMGDBwMABg8ejLKyMvzyyy/qNt9//z1kWcbAgQPP+ZgJIYQQQgghpKWgSltCCCGkmaqoqMDBgwfV748cOYLt27cjJSUFbdu2xbRp0/DUU0+hS5cu6NChA5544glkZ2dj/PjxAIDu3btj9OjRuPPOO7Fw4UJ4vV5MnToVN910E7KzsxvoWRFCCCGEEEJI80ehLSGEnEV+vx9er7ehh9HgZFmG1+uFy+VqcpeyGI1GSJLU0MOok61bt+Kyyy5Tv+e9ZidNmoR3330XjzzyCCorK3HXXXehrKwMQ4cOxYoVK2CxWNR9lixZgqlTp+Lyyy+HKIqYMGECXn311XP+XAghhBBCCCGkJaHQlhBCzpKKigrk5uaCMdbQQ2lwjDHIsgy73d7k+tsJgoCcnBzExcU19FBq7dJLL632/BMEAU8++SSefPLJiNukpKRg6dKlZ2N4hBBCCCGEEEIioNCWEELOAr/fj9zcXMTExCA9Pb3JBZX1jTEGn88Hg8HQpOaCMYbCwkLk5uaiS5cuTbbilhBCCCGEEEJI00KhLSGEnAVerxeMMaSnp8NqtTb0cBpcUw1tASA9PR1Hjx6F1+ul0JYQQgghhBBCyDnRtBoLEkJIE9PUAkoSil5DQgghhBBCCCHnGoW2hBBCCCGEEEIIIYQQ0ohQaEsIISSi2bNnw+Vy1esxJ0+ejPnz59frMQkhhBBCCCGEkOaEetoSQsg5wBiD2yef1ccwG8R6v5R/zpw5mDZtGiwWS6324/1rCSGEEEIIIYQQUnv0jpoQQs4Bt0/G9Qs3ntXH+OTuwbAYq18o65ZbbsG+ffvg8XjQpk0bvP3228jKysJXX32F2bNnw+PxQBAEvPnmm1i8eDEAYNiwYZAkCd9++y0A4O6778aBAwfAGMN9992HKVOmAADat2+PG2+8EWvWrEGXLl2wZMmSGsdcUVGB+++/Hz///DMA4Prrr8esWbMAAE899RSWLFkCs9kMAPjf//6HjIwMTJ48Gbt27YLRaERmZqY6LkIIIYQQQgghpLmg9giEENKCzJ8/H1u3bsXOnTsxbNgwzJ49G/v378ftt9+O999/Hzt27MCWLVvQrVs3LFy4EACwbt06bN++HRkZGbjvvvvQtWtX7Nq1C99//z2eeuopbNq0ST1+cXExNm/eHFVgCwBz586F2+3Gzp07sXnzZixfvhwfffQRSktL8cILL2Dbtm3Yvn07NmzYgMzMTKxYsQJlZWXYs2cPduzYgQ8//PCszBMhhBBCmqd//vOfaN++PSwWCwYOHKh+cBzOokWLMGzYMCQnJyM5ORkjRowI2X7y5MkQBEH33+jRo8/20yCEENICUKUtIYScA2aDiE/uHnzWH6MmS5cuxfvvvw+XywWXy4W0tDSsWrUKo0ePRrdu3QAARqMRiYmJYfdfvXo1fvnlFwBARkYGrrvuOqxevRqDBg0CEHjjEq3Vq1fjxRdfhCiKiI2NxW233YZVq1Zh4sSJ6NKlC2699VaMHDkS48aNQ05ODs4//3zs3bsX99xzD4YPH46xY8dG/ViEEEIIadk++ugjTJ8+HQsXLsTAgQMxf/58jBo1Cvv27UNGRkbI9mvXrsXNN9+MIUOGwGKx4LnnnsPIkSOxe/dutG7dWt1u9OjR6hVKANSrhAghhJAzQZW2hBByDgiCAItROqv/1RSW/vTTT3j11Vfx9ddf47fffsNLL710xouMBT9mXFxcvRxPkiRs2rQJ06ZNQ0FBAQYNGoR169ahY8eO2LNnD0aPHo3169ejV69eKC0tPaPHJIQQQkjL8NJLL+HOO+/E7bffjh49emDhwoWIiYnBO++8E3b7JUuW4J577kHfvn3RrVs3vPXWW5BlGd99951uO7PZjKysLPW/5OTkc/F0mpVle5fhgjcvQPu32uOCNy/Asr3LGnpIhBDS4Ci0JYSQFqK0tBTx8fFITU2Fw+XAgoULAACjRo3CypUr8fvvvwMAvF4vbDYbACA+Pl79GgBGjBiBRYsWAQAKCwuxbNkyXHHFFXUe04gRI/D222+DMYbKykq8//77GDlyJOx2O/Lz8zFs2DA88cQTGDp0KH799Vfk5uZCEARcffXVeOGFF8AYw4kTJ+r8+IQQQghpGTweD3755ReMGDFCvU0URYwYMQIbN0a37oDD4YDX60VKSoru9rVr1yIjIwNdu3bFX/7yFxQXF9fr2Ju7ZXuXYcLHE7CrYBfcfjd2FezChI8nUHBLCGnxqD0CIYS0EKNHj8Z//vMfdO3aFfFJ8Rh86WCcPnUanTt3xuLFi3HrrbfC6/VCkiQsXLgQF110ER566CFcccUViImJwbfffotXX30Vf/nLX9C7d28wxvC3v/0NAwcOrPOYnnjiCdx///3o3bs3AGUhshtuuAG5ubmYOHEiKisrIQgCunTpgkmTJmHDhg2YMWMGGGPw+Xz44x//iD59+tTXFBFCCCGkmSoqKoLf70dmZqbu9szMTPWD65o8+uijyM7O1gW/o0ePxnXXXYcOHTrg0KFDePzxxzFmzBhs3LgRkhS6QKzb7Ybb7Va/Ly8vBwAwxiDLcl2eWpM3Z+0cCBDAwAAADAwCBMz5YQ7Gdx3fsINrILIst+hzgqN5UNA8KJrTPET7HCi0JYSQFsJoNOKjjz4CYwyHbYcBAK889woAYOzYsWH7w86aNQuzZs3S3bZsWfiqh6NHj0Y1jnfffVf9Oi4uLuwliTk5OboFzrgxY8ZgzJgxUT0OIYQQQkh9efbZZ/Hhhx9i7dq1sFgs6u033XST+nXv3r3Rp08fdOrUCWvXrsXll18ecpx58+Zhzpw5IbfbbDYUFBRAFFvexbD7ivepgS3HwLCvaB8KCgoaaFQNS5Zl2Gw2MMZa5DnB0TwoaB4UzWke7HZ7VNtRaEsIIS2M9o/i4D+QCSGEEEKao7S0NEiShPz8fN3t+fn5yMrKqnbfF154Ac8++yxWr15d4xU+HTt2RFpaGg4ePBg2tJ0xYwamT5+ufl9eXo42bdogMTERGRkZTT6IqIuuqV2xq2CX7u9SAQK6pXULu0BcSyDLMgRBQHp6eos8JziaBwXNg6I5zYP2w7/qUGhLCGkwdo8dS/YuwWVtLkPXlK4NPZwW6WyFtl9//TUef/xx/WMxhhkzZugqUgghhBBCzgWTyYR+/frhu+++w/jx4wFAXVRs6tSpEfd7/vnn8fTTT2PlypXo379/jY+Tm5uL4uJitGrVKuz9ZrMZZrM55HZBECCKYpMPIupi1qWzMOHjCbrbGBhmDZ/VIueDa8nnhBbNg4LmQdFc5iHa8VNoSwhpMFvytmDNiTVweB0U2p5DjLGwX9en4HYLvAetwUC/dgghhBDSMKZPn45Jkyahf//+uOiiizB//nxUVlbi9ttvBwDcdtttaN26NebNmwcAeO655zBz5kwsXboU7du3R15eHgClvVNcXBwqKiowZ84cTJgwAVlZWTh06BAeeeQRdO7cGaNGjWqw59nUXNf9Orwx9g3c8/U9AIBEcyIWX7MY13a/toFHRgghDYvePRNCGozL5wIAuP3uGrYk9YnaIxBCCCGkJbrxxhtRWFiImTNnIi8vD3379sWKFSvUxcmOHz+uq35asGABPB4PJk6cqDvOrFmzMHv2bEiShJ07d+K9995DWVkZsrOzMXLkSMydOzdsNS2JrEd6D/XrC7IuoMCWEEJAoS0hpAH5mA8A4Gf+Bh5Jy6KrrqXMlhBCCCEtyNSpUyO2Q1i7dq3u+5oWWbVarVi5cmU9jaxlO1F+Qv26yFHUgCMhhJDGo2k3gSCENGlevxcA4JN9DTySloUqbQkhhBBCSGNywhYIbYudxQ04EkIIaTwotCWENBiv7NX9Pzk3KLQlhBBCCCGNibbStthZfNbWXSCEkKaEQltCSIPhFbZUaXtunYuFyAghhBBCCImWNrT1+D2o9FY24GgIIaRxoNCWENJgPLIHAIW2DSlcpe3WrVtx4403AgDKysrw7LPP6u7/85//jDVr1tTp8Tp06IDt27fXaV9CCCGEENI8adsjANTXlhBCAFqIjBDSgHhY2yIWImMM8LnO2uEdXgcMpjiYDDWvVFxdpa3P50P//v3x0UcfAQiEto899pi6zVtvvVVPoyaEEEIIIQTILc/VfV/sKEb7pPYNMxhCCGkkKLQlhDQY3svWL9c9tPXKXhhFY30N6ezxuYB3Rp+VQ8uQIfq9yL3hbXRM61ntths3bsRDf30IpbZSMMYwc85MPP7Xx3HjjTdizZo16NKlC+68805MmzYN27dvx9133w273Y6+ffvCYDBg69atuPTSSzFt2jSMHz8eNpsNDz30EDZt2gRJktCvXz+88847UY374MGDuPvuu1FQUABRFDF79myMHz8eTqcTkydPxq5du2A0GpGZmYlvv/0WBw4cwOTJk1FRUQFZlnHNNdfgqaeeqo8pJIQQQgghDcThdaiLj2XHZeNUxSlajIwQQkChLSGkAfFKWy+r20JkXx3+Ch/8/gGeGPQEuqZ0rc+hNSl+Jke1XUlJCcaPH4/3P3wfnS7oBFmWYXArvwaKi4uxefNmCIKAtWvXqvssXLgQffv2jdjSYNq0abBardi5cydEUURhYWHU477llltwxx13YMqUKdi/fz8GDR6E7r27Y8/OPSgrK8OePXvUcQPA66+/jiuvvBIzZszQ3U4IIYQQQpouXmUba4xF+4T2SmjroNCWEEIotCWENBivXwlr69rTdl/JPnhlLw6WHWz8oa3BAtyx4qwcurgyHw5fJZhUfWuEjRs3omvXrhhy8RDkO/IhiiKSk5MBAJMnT4YgCLV+7C+//BKbN2+GKCot0tPT06Paz263Y9u2bVi/fj0AoG3Htrhw4IVY+f1KXHn5ldi7dy/uueceDB8+HGPHjgUAXHLJJXj44YdRUVGB4cOHY8SIEbUeLyGEEEIIaVx4P9s2CW2QYkkBAKq0JYQQ0EJkhJAGxNsj1DW05fvz/2/UBAEwWs/Kf15JAjNYlMeIgnbxMRlKlW5cXNxZedrRkpkMQRAgQ0bHjh2xZ88ejB49GuvXr0evXr1QWlqKCRMmYP369ejatatadUsIIYQQQpq2E+VKaJuTmINks1JQQAuREUIIhbaEkAZ0pj1tm1RoexZFG3oPGTIEBw4cwPp1SnWrLMsoLS6tdp+EhAQ4nU54PJ6w91999dV44YUXIMtK+Btte4T4+HhceOGFWLx4MQClv+0vm37BRUMuQm5uLgRBUI/NGMOJEydw4MABZGZm4rbbbsPzzz+PTZs2RfVYhBBCCCGk8dJW2iZblNCW2iMQQgi1RyCENKB6q7T1t9zQljEGOcqetsnJyfjss88w7cFpKCsvgyiK+Nusv1W7T0pKCm677Tb06dMHcXFx2Lp1q+7+l19+GQ8++CB69+4No9GIAQMGYNGiRVGNZ8mSJbj77rvx+uuvg4HhmVefQXZONnZt2IUZM2aAMQafz4c//vGP6NOnD+bNm4f//Oc/MJlMkGUZCxcujOpxCCGEEEJI48UrbdsktIHoVerKqD0CIYRQaEsIaUA8rJUhQ2YyRKF2xf88rG3JlbbBz50xVm1v2kGDBmHF2hXqH8KJ5kTcMvEW3TaXXnqpbuGx4BBWu1BZQkIC3n777ajHe+TIEXV8nTt3xurVqwEAFZ4K5DvywcAwZswYjBkzJmTfGTNmqIuQEUIIIYSQ5oEvRJaTkANnpRMAhbaEEAI0s/YI8+bNw4ABAxAfH4+MjAyMHz8e+/btq3afd999F4Ig6P6zWCznaMSENH5+2Y+//fQ3vP7r6/V+bG3gWJcWCTz0pdA2QNuvNiLNJoxFsf05wMcd1fgJIYQQQkizofa0TchBillZiIx62hJCSDMLbX/44Qfce++92LRpE1atWgWv14uRI0eisrKy2v0SEhJw+vRp9b9jx46doxET0vgVOYtwsOwgNp2u//6h2rYIdQlePbKnzvs2F8GtIaIJYbXB6NkISZ988kn07dtX998FF1yAQ4cO1Tw2xhpNkEwIIYQQQs4+6mlLCCHhNav2CCtWrNB9/+677yIjIwO//PILLrnkkoj7CYKArKyssz08Qpok3i/VK3trvPS+tjz+wOJWPlb7vrY89K1rT9zmgAfXXKQQ1if7UOYuQ4IpQReKno2AdObMmZg5c6Z+XFX9aSPRjQkMAurvPCOEEEIIIY2T3W2HzW0DoIS29jI7AGqPQAghQDMLbYPZbMo//ikpKdVuV1FRgXbt2kGWZVx44YV45pln0LNnz4jbu91uuN1u9fvy8nIAykrsfAX1pkiWZWVRoyb8HM6Glj4vXr9XvZze4/fAKBoB1M+8eOXAsb0+L2RD7Y7l8XsABnh8nkbz+mjnhVeNns3K0XCVtuEer8JTAZvbBsaYrncww7mrbOWPE+7xdNW/jDWqNgl8TrX/xjeW840QQgghpCnjrRESzYmIN8erlbYVngq4fW6YDeaGHB4hhDSoZhvayrKMadOm4eKLL0avXr0ibte1a1e888476NOnD2w2G1544QUMGTIEu3fvRk5OTth95s2bhzlz5oTcXlhYCJfLVW/P4VyTZRk2W1WoIzarzhlnpKXPS2FlIbw+JRg8nX8aFknp+Vwf8+JwOdTQMa8wD15z7docON1OeH1elFeWo6CgoE5jqG98XrxeL2RZhs/nq7bC9Ey5/W5dCOrz+cI2vvH4PEq1q98HURDVffyy/6yOj2OMwe9X+haHq9b2+X3qmLw+LyRBOutjipbP54MsyyguLobRqHxoYbfbG3hUhBBCCCFNn9oaIbENACDBlABRECEzGcXOYmTHZzfk8AghpEE129D23nvvxW+//Yaffvqp2u0GDx6MwYMHq98PGTIE3bt3x5tvvom5c+eG3WfGjBmYPn26+n15eTnatGmD9PR0JCQk1M8TaACyLEMQBKSnp7fIcDKSlj4vDpsDRoMSVCWlJiHBpJzj9TEvgkGAUag6dkoSMmIzancACTDCCIPZgIyMWu57lvB5iY+PR0VFBQwGAwyGs/dPLYO+ZYVkkGAQQx+Peaq2EwFRENV9BEE4q+MLxkPPYJJfUsckSeGfQ0MxGAwQRRGpqanqQpW0YCUhhBBCyJnLLc8FoLRGAJS/U1OsKShyFKHYQaEtIaRlazzviuvR1KlT8eWXX+LHH3+MWC0bidFoxAUXXICDBw9G3MZsNsNsDr1MQxTFJh/qCYLQLJ5HfWvJ88IEBt5e1M/8ujk4k3lhjCm9aKuOLUOu9XH4/sHjamh8XgRBUP87G3i/Yf6YvK1AuMfj2zLGlNc0aLxnm7YfcrjHC26HcC7GFC3+GmrP9cZ0vhFCCCGENFW8PQIPbQEg1ZqqhLbU15YQ0sI1q3edjDFMnToVn332Gb7//nt06NCh1sfw+/3YtWsXWrVqdRZGSEjT42d+9ev6XPDLx3y6oK62x/bLfsgILJLWEmnbIohV/5xH6k/LX8fgHrbV9ZnlZs+efdZbv+h62lZ9PWvWLHTr1g0DBw6MuN/kyZMxf/78szo2QgghhBBydvD2CDkJgWKrtJg0AECxg0JbQkjL1qwqbe+9914sXboU//vf/xAfH4+8vDwAQGJiIqxWKwDgtttuQ+vWrTFv3jwAwJNPPolBgwahc+fOKCsrwz/+8Q8cO3YMf/7znxvseRDSmGirOeszHA0Oaf2yP8KW4WnHErwYV2PEGIPb7655w1rwyT71mEbRCAGRq1MjVdoyMDh9TuRX5iPVmop4U3zIvnPmzMG0adPObksATWbMA+Tnn38ehw8fpg/RCCGEEEKaKbXSNjFQaZtiVRYSp0pbQkhL16xC2wULFgAALr30Ut3tixcvxuTJkwEAx48f113WWlpaijvvvBN5eXlITk5Gv379sGHDBvTo0eNcDZuQevHTyZ+wt3gv7uh1BySx/hZx0oa29VlpGxwA+1jtjq0LbZtApa3b78akFZPq9ZiMMXj8HrWVwNNDn66x0nb71u14dvazsJXb4Pf7cd9f78PggYNxyUWX4K5778KalWtgs9nw6quvYuzYsbj77rsBAMOGDYMkSfj2228j9g/euHEjHn74YdjtdjDGMHfuXFxzzTXYunUr7r//ftjtdlitVrz88su4+OKLAQArV67E3LlzYa+0AyLw8OyHMXHMRAwZMgQulwsjR47EZZddhldffbXG+aioqMD999+Pn3/+GQBw/fXXY9asWQCAp556CkuWLFFb2/zvf/9DRkYGJk+ejF27dsFoNCIzMxPffvtttNNPCCGEEELOUKT2CABQ5ChqkDERQkhj0axC2+ou7+XWrl2r+/7ll1/Gyy+/fJZGRMi588m+T5DnyMOlbS5Fl+Quuvt8sg8unwtxprhaH1dbAVuf4WhwdWxtA2HtWOozTG6qeJVtcG9YQAneZSaj3FaORx94FEuWLUF8WjxKiksw/tLxWPTeItjL7ejeqzteeOYFrFixAg888ADGjh2LhQsX4s0338S6deuQlJQU8fFLSkowfvx4fPrppxg2bBhkWUZZWRk8Hg+uu+46/Otf/8Lll1+OTZs2YcKECTh48CAKCgowe/ZsrFy5Eh6jBzv27sDNY2/GlYeuxIYNGyAIQo2PqzV37ly43W7s3LkTTqcTQ4cORbdu3TBy5Ei88MILOH36NKxWKxwOB0RRxDfffIOysjLs2bNHfQ6EEEIIIeTcYIyp7RG0lbapMUpoS+0RCCEtXbMKbQlpyZw+JwDAI3tC7ntx64vYVbQLr//hdSRZkmp1XG1P27PZHqG2wat2+3DPubExS2a8N/q9ej2my+fCqcpTMIgGGAQDZCZHDG0BYNvmbThx7ARuue4W3YdcB/YdgNlixrirxwEABg8ejEOHDtVqLBs3bkTXrl0xbNgwAMpCXSkpKdi1axdEUcSoUaPg8/kwdOhQZGZmYvv27di5cycOHjyISy65BD7ZB5kpi9EdP3YcST2Saj0fq1evxosvvghRFBEbG4vbbrsNq1atwsSJE9GlSxfceuutGDlyJMaNG4ecnBycf/752Lt3L+655x4MHz4cY8eOrfVjEkIIIYSQuilzlaHSWwkgqKettaqnLbVHIIS0cBTaEtJM8OAyXPh53H4cXtmLPEderUPbM1ksrDrBQWtzr7QVBAEWQ/32hGVgMEtmGEUjJFGCy+cKe8WBuggZY+jcrTO++O4LuHzKwmKSIKHoVBFMJhN4S1xJkuD3167HcG3wdg6MMVxxxRVYunQpCh2FKPeUAwCyYrPq9XEkScKmTZuwYcMGrF27FoMGDcIHH3yAYcOGYc+ePfj++++xevVqPPLII9i+fTuSk5Pr5fEJIYQQQkhkueW5AJR2CDHGGMiyUmiQEkM9bQkhBADEmjchhDQFvN1AuAW9eKhZl3DzbLVHCKm0rW1PW3/T6ml7NvCAVhTEqBYhu3Dghcg9losfv/9RvW/Pzj1wu5XFzMJV6QJAfHw8bDZbtWMZMmQIDhw4gHXr1imPKcsoKSlB165dIcsyVq1aBQDYsGED8vLy0LdvX4waNQqrV6/Gzp071cfe8cuOqFrdhDNixAi8/fbbYIyhsrIS77//PkaOHAm73Y78/HwMGzYMTzzxBIYOHYpff/0Vubm5EAQBV199NV544QXlEr0TJ+r02IQQQgghpHbCLUIGUE9bQgjhqNKWkGZAZrIaemrbGXA8eK1TaKs53tlciCxc2Bzt/sH9cVsKHnQKVf/T3qbF5zYxKRGLPlqE5554DqWPl8Lr86J1TmvMfW6usm+EsPShhx7CFVdcgZiYmIgLkSUnJ+Ozzz7DQw89BLvdDlEUMXfuXFx11VVYtmwZ7r//fjz00EOwWq349NNPERcXh86dO2Pp0qWYMmUKyivK4fa40aN3D1wx7Io6zccTTzyB+++/H7179wagLER2ww03IDc3FxMnTkRlZSUEQUCXLl0wadIkbNiwATNmzABjDD6fD3/84x/Rp0+fOj02IYQQQgipHd7PVtsaAQiEttTTlhDS0lFoS0gz4Pa71a/DBas84KxL6MqrNLXHqQ9n2tNWOxYZMvyyH5Io1cvYmgoesgqCoGs5EEz7GvY6vxeWfrFUDeMFCDAbzPj12K/qNnFxcbrjzJo1C7NmzapxPIMGDcL69etDbu/fvz/Wr18Pn88Hg8GgjhVQqmNHjBiB/Mp8VHgrdM8hmorbd999Vzfud955J2SbnJwcbNq0KeT2MWPGYMyYMTU+BiGEEEIIqX9qpW2CvtI2LYZ62hJCCEDtEQiJyCf7cKD0QK0rQBuCxx/oDxu20rbqttq2IACCQtt6rGgNDoDPJLQN972W9jk0J/x5CUINlbZB54R2PhhYICSN0B7hXNA+dkOOgxBCCCGEnBuRQlteaVvqLG0S78UIIeRsoUpbQiL44tAX+HDfh/hTzz+hj7VxXzJd06Jc9dYeoQ6hbyTBAbCX1S4QDtlf9sKC0IW+5v8yH4fKDuEfw/9R7wuBNTRtewTe0jaa0DZ4G+1CZTW5++67w1atbty4EVarNapx1yR4fF9//TUef/zxkO1mzJiBG2+8sV4ekxBCCCGEnFu8PUJwT9sUq7IQGQNDqatUrbwlhJCWhkJbQiIodBYCAPId+UD9ZFFnja7SVg6tqpShVFaecXuEs1hpW9tP0YMD5EiVtr8W/AqX34XTlafRIbFD7QbZyGkXIgu+TaumSmN+fzQVrgsXLqzNEKOmHXfwcxg7dizGjh1bq+Px86mltcwghBBCCGkqcstzAYRW2holIxLMCSh3l6PYUUyhLSGkxaL2CIREwIPQ+lx862zRhrbBYaY2DG1UlbbBoW2Ytg7V7u+vub2CT/bB5XcBAFw+Vy1HWLNdhbtwquJUtdtEU71aV7VdiCwSNdRtwK4E9dkegTGG3IpcnLCfqJfWGGfzNSSEEEIIaYkYY4H2CEGVtoBmMTLqa0sIacEotCUkAo+sBKH1ufjW2aJdiCw4oNO1TqhD6KoNrOqz0rY+FyID9ME1V+mtVL/WzlF9KHAU4KnNT+HFrS+GvV+SlApPjyd0XPVF19NWUPsjhIg2EG8svWTPNCSVmQyf7IOf+esltOWvIX9NCSGEEELImSl2FqtFFa3jW4fcry5G5qDQlhDSclF7BEIi4AFlUwhtqwtmdZWydai01R6vPquO63shsnD7O7wO9WtecVtfChwFAIAiZ1HY+w0GA2JiYlBYWAij0QhRrP/PyDxuD/weP7xQ5sLv8cMNN1yCK3S7aNpPiIDLVf8VyYASxPp8PhgMhkDArOF1e+H3K2P0wBPyHGrD41fmBQAcTgdMkqnOx5JlGYWFhYiJiYHBQL8yCSGEEELqA+9nmxGbAbPBHHJ/agxV2hJCCL0DJSQCHgo2hdC2up622jCzTj1t5UCloo/5cNh2GCuPrsTEzhPrMNKA4Hmt7TwHP5dw++sqbX31W2lr99iV4/rdYIyFBJGCIKBVq1Y4cuQIjh07Vq+PrR2Dy+9CuaEcAODwOWCTbCgzlem2K3IWgYFBFERd5akAQVddK0KEx3p2KoMZY5BlGaIohg1tS12l6gcE4Z5DbXhlL8rcyv4uswtG0VjnYwGAKIpo27Zt2HETQgghhJDaU1sjJIS2RgAC7RGKHOELJAghpCWg0JaQCHgQ2iRCW7manrZnWGnLFzEDlOrjFUdW4IfcH9A6tjUuirso7D7v7X4PR2xH8LeBf4NRCh+YRdOTtjrRhL6VvkBo6/Q7a3X8mvDQloHB5XfBaghdrc5kMqFLly5nrUXCkr1LsDV/K67qdBU8fg9WnlyJIa2H4PoO16vbeGUvXv3hVQBAu4R2OFYeCJBjjbG6YDvGGIOnhz59VsYqyzKKi4uRmpoatur40y2fqv2BB7UahBs73Fjnx/qt8Dd88NsHAIA7+9yJ81LPAwDsLd6LTXmbkGHNQJu4Njgv5TxYDJYaj2cymc5KpTQhhBBCSEvFK23D9bMFND1tqT0CIaQFo9CWkAjUnrb12Mf1bDmrlbaaykyv7FVbDmhbD2j9XvI7vj7yNQDgWPkxdE7uHHa76sLlaEQV2noCgWS4nrdngoe2gLLIWbjQFlCqNC2WyMHg5tOb8c2RbzD1gqlIs9ZuZVybbEOJvwSiSQTzMpT4S1DBKnSP53Q5lW0goou5C0r8Jep9kknSfe+Ao9qxnglZlmE0GmGxWMIGoGX+MnUsdmY/o3HYmV09lvY5fXDoA11o/cblb5y150sIIYQQQiKrqdJW7WlL7REIIS0YlQ4REgEPa7VVrI2VLrRlkUPb2gajgD4E9sk+dUGvcJWrjDF8+PuHUT1ecBgeVc/VavYPF647fJqetr767dUaHNrW1ZoTa7C3ZC92FO6o9b78OZtEEwyi8hlc8DzyccaaYnX9wiRBCmkbUJ89i2vrTCvCtSq8FerX/MMFxhjyK/MBAANbDUSP1B5IsaSc0eMQQgghhJC6yS3PBVBNewTqaUsIIVRpS0gkTao9gia0DQ686rvSVg1tfaGh7c6indhbsjeqx+PzyvuqnpX2CJpL/+s9tPUGQttwcxGtMznP+L4myaR+uBA8j+tPrQcAtIptBZMYWJDLKBpDQ1vmC9uf91zQhs1n+jNX7ilXv+bnQKm7FC6/CyJE3HfBfWfc55YQQgghhNSdWmlbQ3sE6mlLCGnJqNKWkAh4cOTzN1z1YbS01cDB1a3a7+sShgVXQPLQNlwIuuHkBt331T0ev88smes0tmgWItNWXPJx1xdtpe2Z9Mvl465tpTEQeN1NogkGwaA7HgDY3DasOLICAHB1p6thkgKhrUE0qNW5WnWpxq4P2nYZZ1xp69FU2lZVW+dV5gFQLrWjwJYQQgghpGHxnrY5CTlh71crbamnLSGkBaPQlpAIePjVUJW2NrctYt/YYOeyp211oW1wxWk0lbZWo9ILNrjHbU2C21aEeyzt/Ln8Z689gtN75pW20YSlTp9T93rw18IkBdojaOfhy8NfwuV3oUNiB/TP7K8G5EDk0LahWiTUZ6VtuPYIPLRtFdvqjI5NCCGEEELOjMzkGtsjUE9bQgih0JY0Mw6vA0dtR+vlWDwQa4ietm6/G9PXTsfjPz0e1fbakKu6Bb6qC+Q2n96MPcV7Qm4PrtRVQ9swIWhwNWt1QSQfS4whpsaxVbc/F+510rZHcPvOXqXtmQTCakV31fNZcWQFlh9crlswC1BC/LtX3Y1/bPlHYF/e01YT2vI5Z4xh9bHVAIDrz7segiDoQttw7RG0+59rZ1oRrqV9bXil7enK0wCArNisMzo2IYQQQgg5MwWVBfDKXggQkB2fHXYb3h6h2FEMxti5HB4hhDQaFNqSZuW1X1/Do+seVXsk1RVjLCRMO5dKnCWo8FbgdOXpqC6b14aldelpa3Pb8PIvL+OlrS+F3Ket7PTJPrUyNFylbXBoG02lrUWyAKjDQmRBwV64x9L1tD2LlbZn0i+XB68+2YcT9hNYvHsxPvj9Azzy4yP44tAX6nZHbEfg8rtw2HZYvU3XHiGo0tbpc6qBZe+03sp2UbRHaKhKW+3j1mtoW1Vpyxchy4qh0JYQQgghpCHx1git4lvBKIVvW8XbI3hlr671FSGEtCQU2pJmpcBRAAAodBYCAE5VnNK1DoiWNkCqy/5nqra9WKtrjxBNpW2ltxIMDHavXQ0RueD2CDz8DBdUBs9VdeEbH4vFYAkZJ6BcCjV7w2xsydtS7f7qY/lDH4uHlkD99rT1+r26EPhMFiLTtuEIboexu3i3+nWxS7k0TDvv2oXIgnvalrpLASiVzDysbdTtEbSVtmFey9oIV2mrtkeIo/YIhBBCCCENqabWCAAQY4xR3yfQYmSEkJaKQlvSrPDgxyf7cMR2BA+ufRALdiyo9XG0l9o3RE9b3WX9tQ1tWTU9bSP0jdXurw06g4/n9rsDlZxhFt/iY7UarCGPHekx+R9jwdtuOr0Je0v2YvFvi3XBccj+VZW64V4nXaXtGVTDBiv3lOu+r4/Q1if7QuaAfwgBACWuEgDKHPNLxHShbVClbZm7DACQZE5Sj9GYK221HzZEO4YvDn2BT/Z/oruNMab70KPSWwnGGPIcSmhLlbaEEEIIIQ2LXxXZJjFyaAtoWiRQX1tCSAtFoS1pVnjY45N9yHcol0PzCrva0Fb61UdoW+QswvS107Hi6IqottdWXEYT2up62tahPYJ2f23QCegrbWsKQXmIGGuMVR6vmsXF+Fh4wBs8zzwYLXYVY2fhzoj7xxhjwu4fMt56bI+greQE6ie09TN/YHG2qjkpdBSqAW2JUwltGQKtO7ShLe9Py+fF5rIBABLNiepjNbaetruLduPtXW8rC6xBX9FdE6/fiyV7l+DT/Z/qQnSnz6l7Dg6fAyWuErj9bogQkR6TXr9PghBCCCGE1Apvj5ATn1PtdupiZA4KbQkhLROFtqRZUUNb5lOD17q0N9BW2jLGzjjI2lO8BycrTmLTqU1RbV/pq3ul7dkMbbX9pDx+T8i88HmLNcRW+3jax4xUlWtz29Sv+YJa4faPtJAZYyxkITKb24a3dr2FQ2WHIo4rGtpKTqDuVbyMMV1PW/4csmKzIECAR/aogSSvtAWUYNIn+9SgM1xPW94eIdmSrO7X2Cpt/3vgv/j22LfYlr+t1mOweWxgUAJt7XkZHKg7vA71A5z0mPSwz5kQQgghhJw7UVfaxlClLSGkZaPQljQr2kpb/nVdKmVr05s1GjyYi/Y4tb2sXxvsBgep0fS01T7f4NBWu782zA7eTzsOtfq1mt6kwaFt8Li11ZO/5P+CUldp2P0jVdq6/e6Q1g4bT2/EqmOrsPzg8ojjCsfuseO93e/hWPmxkLEBda/i9TO/Grz6ZJ9amWyRLGrYylsk8J62/Llo594smQOhLYuyPYJQfWjr8Xvw5MYnQ9oP1Cd+rtm9+qA1mp8T7WugDdH517xthtvvRq5d6ZvWKpb62RJCCCGENDQ1tK2mpy0QaI9APW0JIS0VhbakWeGBlVf2qoFdNAHQUdtRrD62Wr0UPXifM60+5GFmXULbaCqFtcetS09b7TbBi2EFL2ymFRxW8rHyIDWa9gg8XAue43K3EspJggQZMrbmbw27f6T2CsHhs8vvUoNfXnkZrR9zf8TXR75Ww976ao8Q3NaCh9wG0YDMmEwASosEQF9pqw1tBQgwiAZIgqQeB4D6XLWVtmZR0x5BCt8egb9m+0r2YXfxbny6/1MctR2t0/OrCf9AwunVz180Pye6xcY05yy/PSMmQ73tkE2prM6Mzaz7YAkhhBBCSL3g7RGi7mlL7REIIS0UhbakWalrpe1bu97Col2LsLdkL4D6r7TlFarhwl+v7MWKIytwsuKkeltte9pW2x5BE5xGrLTVVNBqWzMACLsIGKcNbX2yTw2MecuC6gJfHlDyhciCt7V5lPYIbeKVP+Z4T9fg/fljBVf18jnU9nHlAWiRs3af1vOQl1ev8mAwzhgHoO7tEYJfN/76GEUj0qxKD68CZwFcPldI9TV/zYyiEYIgRLUQmXYuamqPoD3vPtr3UZ2eX034+RO8+J1P9qkfoETCQ31AX2nLK3ATzYnqBwJHyo4AoEpbQgghhJCG5pf9OGU/BaDmSlu1py21RyCEtFAU2pJmhQd/2kWdqrtEn+NBz+mK08o+wZW21VSMRoOHc+HC3x0FO7B492L8Z89/1Nu0IdSZhrbaMDRSaKu9vbqetiGPqwl7tWPgYWa1PW2Zvj0C/57joRwPbXmIG7y/WtUb9Fg8fE42BypNC51KaFvprQypKK4OD3n5mHgPVb6oVXDoGC1dpS0LtEcwiAa1UrTQURjSGsLtd6vnBW95EE1oa5QClbUGwRB+IbKq80VbPbytYBv2l+6v/ROsgVppG1SpzFBzH+mI7RGqXpt4U7x6bpywK9UcFNoSQgghhDSsvIo8+JkfBtGArLisarelnraEkJaOQlvSbMhM1vcHrUWlLQ8feagXXGl7pu0R+PHCHSe4ehPQB6dRhbaa8LS69giRKl+r62kbbaWt9nJ9Xj1b3bz5/FXtEcJs6/a71WO3TWgLQL8wGRCm0jbodebhXZwpTq245K8vEFpt6/A68PG+j3UVz8Hb8teIB4YZViVYrWulrfYDBb/sV+fAIBqQbk1Xx6ztZ8sfj+/LQ1sewFbX01ZbaRupPQI/f4JbX6zLXVe7J1cDmcnquR2uvURNP7c1tUeIM8ap5wb/dyErtvo3BoQQQggh5Ozi/Wyz47MhiVK121JPW0JIS0ehLWk2dL1bNYs6+Zm/2sv0gUB4xhd9Cg6Mghfgqi2+f7ggigdW2nD2TNojBD9XbYgbXM3KVdvTtpqKR11oW/UctYtiVRe8qQuJGUIrZXlFq1E0qr1dg0Pbmnra8urXGEOMGlZqK1a1AS4A/JD7A/574L/47MBnIWPVhrYyk9VgkFfa1jm0Deppqw1teaVtgaNA188WqOppWzXfJjG00tYre9UxJpoT1f107REEQ9g/lPmYgoPUuvbtjcTtd4OB6Y7Nw3Wg5g9KtKEtD+iBwKJm2kpbABAhqi0nSIDf78cTTzyBDh06wGq1olOnTpg7d66uPQVjDDNnzkSrVq1gtVoxYsQIHDhwoAFHTQghhJCmivezzUnIqXFbtdKWetoSQlooCm1Js6ENebyyN+T76vBgNFKlbU2XatdEXYgsTKsGHnxqw9ng/qU10bVHCGrlEBxmh91fE0oHX+ofbaWt9nJ9NUCMZiGyMD1teSVrgilBrRQNaY8g69sjRFqILNYYC7PBjGDBoW2uPReA/lJ7QAmx+bFkyHB4HWowyEPbelmIjGlCW8GgHrvIWRRSFezyu9TXnAex2v60vP+vJEiIN8Wrt/OqXEAJxLWVtvw4fAz8vBMgAIhuQbzacPtCP6QwikaIVb+WalNpW+mrRIGjAK9sewW/Ff0GQAltY42x6jYZMRlhe/i2dM899xwWLFiA119/HXv37sVzzz2H559/Hq+99pq6zfPPP49XX30VCxcuxObNmxEbG4tRo0bB5arbhxWEEEIIabl4pW1N/WwB6mlLCCH0DpY0G8ELbvGwCVACIAss4XaDzGQ1IOILVQVX1p7xQmRVgVe48JeHY5FaFNQUljHG9O0R5MjtESKFttowWVu1CNTQ09Yf2tNWF9pGeDyZyerrxasrtdvyqtpEc6JaKapdeEpmcsiiZ8GBuDa0tUrWkDEEX2Z1ulLpZxwckgf/kWj32NU54lXAHtkDv+yv8RKvYMGVtvx7o2REqiUVIkR4ZS8Olx3W7ef2udX55n1qtYFkkUt5bonmRIhC4LM5g2iACBEyZBglo26fWGMs3H63Oq88iE4wJcDmsUVV8V0b2sCfP5YkSjCIBnhkT42VttqetpWeSqw6tgobTm1Qb4s3xavnBkCtESLZsGEDrrnmGowbNw4A0L59e3zwwQf4+eefASj/vsyfPx9///vfcc011wAA/v3vfyMzMxPLly/HTTfd1GBjJ4QQQkjTwyttowlteXsEqrQlhLRUFNqSZkPXuzUoHK0u+NTeV+ouhdfvDQlp6yu09cpeMMYgCIFAmYeEPMRijOkrbf3VV7MFh1vVfR8xtNU8v+BK22jbI/BQT9seIZqFz3h7AxkyZCZDFEQ1tE0wJSDBlKA+lsvngsVg0Y03UnsEPocxxpioKm15aBt8rgRvV+4pV/vF8tCWjy9WjEVtaINmbXW4JEiQRAmp1lQUOgvxe+nvAKAGrm6/WxeSA0p1LscDae0ibJxJMsHld0ESJN0+scZYlLhK1DHwIDXRnAibx3bGLUKCacNxNbQVJJgkEzyyp8afueCFyHi4Hm+Kh0EwoEtSF/xe8ru6DYW24Q0ZMgT/+te/sH//fpx33nnYsWMHfvrpJ7z00ksAgCNHjiAvLw8jRoxQ90lMTMTAgQOxcePGsKGt2+2G2x0I+cvLldeKMQZZjvwhUEshyzLNBWgeOJoHBc1DQHOZi6Y+fnL2qJW2iVGEtlXtESq9ler7AEIIaUkotCXNRnA4GVxpG0lwGFXkLAqp2jzT0FZbpehjPhiFwGXpPLDiIZzL71IXTtLeHs2xgdCQVft9pN6+2ucXvBBZtaGtHLoQmUkyqc8vmpBY+8eXX/ZDlMRAewRzAqwGK4yiEV7Zi3JPuRLa+msObfkl97HGWF0vV07bcsDlc6l9Y4PnM7g1QW5FLryyFwIEpMekwyAY4GM+OH1O3eX40QiukObPgYfeGTEZKHQWqq0AMmIykOfIU9ojBPW0FQURAgQwMHXM2n62nFkyw+V3Ke0RpMB5GGeMAxDaHiHRnAjY6789QsRKW1bVDzlMKxEtbWjr8DrUiuLJPSdjaOuhAKCrtG0V26p+Bt7MPPbYYygvL0e3bt0gSRL8fj+efvpp3HLLLQCAvLw8AEBmZqZuv8zMTPW+YPPmzcOcOXNCbrfZbCgoKIAotuzOTLIsw2azgTHWoueC5kFB86CgeQhoLnNht9tr3oi0SLnlSkuyaCptE82JkAQJfuZHsaMYrRNan+3hEUJIo0KhLWk2tIFkrULboDCqwFkQclt1vVmjEXwZvLaXKA+v/MwPn+wLCU1ruiw9OHSurtJWW80aaXzBC5FpFyQKph2b2tNWrLk9gvZ2bWjrlb0wSsZAewRTIgRBQKI5EUXOItjcNmTEZKj7CxDU0Db4sbTtEbQLXPFgk7fCAIC8ykD4FDzfwZW2R2xHAABJliQYRSMsBgsqvBV16msbfF7wgJyfH+M6jsP+0v3qdtlx2chz5OnaI/BAWhAEGEQDvLJXHXOyJbTSlm8f3B6B9wbm57q2PQJQc4haW+EqbQ2CAUxUzrfq2iPITNa18ajwVqhzpH3O2hCdKm3D+/jjj7FkyRIsXboUPXv2xPbt2zFt2jRkZ2dj0qRJdTrmjBkzMH36dPX78vJytGnTBomJicjIyGjSIUR9kGUZgiAgPT29Rc8FzYOC5kFB8xDQXObCYqGKSBJebSptBUFAijUFhY5CFDsptCWEtDwU2pJmo7o2ANUFTiGXwzsKo26PIDNlYao4U1y1Y9M+hlf2wopAj1Vt2Ofxe2of2tawaFq4hcm0C1IFH6PSV6lr4RCu0tYgGuDz+8KHtlH0tFV7twYthsUfS1tpCyjhLQ9ttfsbRIP6WMHzwNs8xBhidMFw67jWyK3IVS7593tgkkzIcwRC2+B2FME9bXl/2TSLsjCC1WBFhbciqgXjggUvIMfPUz4n/TL74Zmhz2DhjoVw+93okNgB2wq2wel3qvOtrZbloS2vtOWLuGnx117bHkGEqAbb/MMPPg+8Wre+e9pqz3vt68nAdLeFY/fY1e0AJaDnr3eKOUW9nQfRAIW2kTz88MN47LHH1DYHvXv3xrFjxzBv3jxMmjQJWVnKvOXn56NVq0C1cn5+Pvr27Rv2mGazGWZzaHW7IAgQRbFJhxD1heZCQfOgoHlQ0DwENIe5aMpjJ2eP1+/FabvSkiwnISeqfdJi0pTQlvraEkJaIPptSpoNL9NXLWoDw+oCoHCVlcG3RQof5/8yH1NWT0GBo6DasenaIwQdy+0L3Ofyu6oNbf2yP+T+4EA6uAVCdQuTqccIqvjUVu+GW4iMh4HagJOPQ9fTNkKFMg8rDaIBoiBCrPqniI9NW2kLBIJDm0cf2hpFoxpCBj+WGtoaY3TtEVrFtlIDSh5unq44rd6vfT2AQKVthjUDAHDcfhwAkGZVQlseCNcltA2ed/4ctAuatU1oi2eGPYMXhr+AeFM8AGX++L68PQIQaKtQXWirVtqKgUpbsyG0D3Fwpe3Z7GnLSaKkBtbVVdrydhH8vHH5Xep4kyxJ6naxBqXSVhIkpFvT62XczY3D4Qh5Yy1JktqLsEOHDsjKysJ3332n3l9eXo7Nmzdj8ODB53SshBBCCGnaTtlPgYHBKBqREZsR1T68r21wIQUhhLQEzTK0/ec//4n27dvDYrFg4MCB6irYkXzyySfo1q0bLBYLevfuja+//vocjZTUJ117BObThXjRLkQGhK+0jRQg7S/bD5/sw6GyQ9WOTRusBh8ruNI2uD2BNrR9YesLuHvV3Wr/VQAhvU15CwQuuFI2XIAdaRGvcPsDgTA13EJk0VTa8tCNh5A8pFRD26pwloe1vOK23F2uG682eAwOr51eZV6DK20TzAlIj1ECPB7IatsjeGSPbv54ANohsYPusfkxeHuG+miPwJ+/tvqYEwRBDVxdPlfIQmRAdKGtunCZaFCrdC2SJWJoy1+D+u5pG65yVxICoW11ITGvxObBOWeRLOrrAUCtgM+IydAF4STgqquuwtNPP42vvvoKR48exWeffYaXXnoJ1157LQDlvJs2bRqeeuopfP7559i1axduu+02ZGdnY/z48Q07eEIIIYQ0Kbw1Qk5CTki7tkhSrUpoyxfaJYSQlqTZhbYfffQRpk+fjlmzZmHbtm04//zzMWrUKBQUhK+E3LBhA26++Wb86U9/wq+//orx48dj/Pjx+O23387xyMmZCm6PoA3xgkNJl8+FBTsWYHvB9tDQ1hmmPQILDTplJsPmUsLFYlf1n/xqA6rgYzv9Tt12PDBVqwirKhKdPqcyXtmDUxWnQo6tDauC+/tq8e/LPeX4MfdHuP3ukMBTG9qGW/1XDfI0wVq40NYre3G64jQeWvsQ1hxfo27LQzce/gYHhmp7BFOCbjt+uxpuSoH2Cl7Zq+u/q22PoK20TTAlqFWXP538CYwxnKoMzCcQCCh9sg+lrlIAgdCW439A8qrd4LYK0QgO8/nz0vaa1dI+lna+Ob4AHD/Hwi1ExsedYklRQ90US4r6mDyk1y1EhtqFtl6/t9peyED4kFvb7iKaStskS5KuX3FwD9/uKd0xou0I3NL9lqjH3tK89tprmDhxIu655x50794df/3rXzFlyhTMnTtX3eaRRx7Bfffdh7vuugsDBgxARUUFVqxYQf0KCSGEEFIrJ2zR97Pl+N+u1B6BENISNbvQ9qWXXsKdd96J22+/HT169MDChQsRExODd955J+z2r7zyCkaPHo2HH34Y3bt3x9y5c3HhhRfi9ddfP8cjJ2cqOLTVVtoGB6XbC7dj7Ym1WHZgmRp+8bCo0FEYuhBZmADJ7rFDhhJo1nS5ji609YcGyNqveWCaaNGHZQdLD6qPp92H36/t36l97pFC22X7l+Gf2/+JH3N/DJkfbbVvuErbsO0R5DDtEWQffiv+DbkVuVh1bJW6LW9/wCtoeW9VH/OBMaZW1Ko9bauCwzJ3me6xtD1xGZhurDy0tRqtukrbeFM8RrUfBREifsz9EYt3L9a1RwACr1eJq0S9hKtNvP6PS21PW+3j1Yb2teEL0WnnI5jZoITPbp870B5BE9oGV5OGW4hscs/JeHzg4+iT3get41rj0QGP4r4L7oMkKPvy46rtBqpea4/sqTGIBYAyVxnuWnUX3tjxRrXbhQu5tZW2NfW0BZQAXrvYWHBlsVEy4s4+d2JA1oAax91SxcfHY/78+Th27BicTicOHTqEp556CiZT4LwSBAFPPvkk8vLy4HK5sHr1apx33nkNOGpCCCGENEXqImQJ0Ye2aTHK39zUHoEQ0hI1q4XIPB4PfvnlF8yYMUO9TRRFjBgxAhs3bgy7z8aNG3WrXAPAqFGjsHz58rM51FC7PgUEEZBMgGQEREPgv6oFoVQ+N1B0AHCWAGnnAUltAdkPFO0HSg4BSe2AjB6AVMuXV2YwlJYAvtTQx6yJ1wGUKb0+kdQOMMVWv73sA+x5yn5xGYA5HkAtHjPM+PxlBwCPEpz5KvKVhYo8DgACPIW/AyxQbWnL3wF4nKi0n4SncC/gcaKVNQ0nXCUodZXDKVoBjxNmyQi33wN/+XHg9A7d49oc+YBHCbaKi/YCp7ZHHK7XVQZUBV6+/N+AyjIAAGMMbmepep8n/zdU2o8BHidSTMko9TjhQgFwajv25a5RH89dsAeQq6pZS5TxW00u9X7/qe1AVZjoq8hTbwcAX95OwJqOgsLdgMeJ0ryd8Nr12zjydgAu5XvZWaK7DwASXXbA64DHX6jOi7vksDJnFYUwFB0CPE74HMVwF+0HPE4cK94LX+4vMIgSbPm/AR4nEt0O4NR2GLwOwOOEP+83VJpz4XdXKI9TfBQQc5FYUQx4nCgvPQyc2g6vTTm+wVABY/4edXzek7/AIJnhlX3wuZRgL6bwICzlgecXby9EX0tr3JVzBRYeXo6V+5erz0sSBPgZg/vkNsCSjKLyo8prYbEgwXY6MA8CkFZRBJzeAavLBnidcBUdAMytAj9H/jxArP6c9pQeBqraOPjghNd+GvA6YSg7ARh3hGxvsR0HvE64K/PhgQHwOmG25yuvAQCDu0I9HgAkl54AbPpAOh7A+QCQtwsAcCEkwF4Agz0f8DrhKzsO/6lf4eXBedkJ9ZjeU7/AFKZ1g9bRsgNwOIux9+RmIHNo4I6geXGVHNaNFQAkZxlEQQC8TniL9gNifNjHKC/YDXidSPA4EOf3orjqOCk+rzoXUcnsBVDbBEIIIaRF+ec//4l//OMfyMvLw/nnn4/XXnsNF110UdhtFy1ahH//+9/qVZj9+vXDM888o9ueMYZZs2Zh0aJFKCsrw8UXX4wFCxagS5cu5+T5NCW55bkAahfaUk9bQkhL1qxC26KiIvj9fmRmZupuz8zMxO+//x52n7y8vLDb5+Xlhd0eANxuN9zuQOVkebkSbsiyHPZS8hoxBmHj62pwVyv7vqn9PhEIYEjw+iAYDWC1CVAbCa/gBYxKaOstq7rcXVAqL72bF4LJgcqxcskFSG64ynLhPrEHMDiRWnoKJ0UfZABF5QWA4EcME+EWZBgKT0M4uEY3L6WCDzAqVbHFZSfBfg//wYAPDH5Tufq9Z+08MKb86LnAIGvuc617EZWiD5A8SC49DYheuJkA9sUD+N1QCYhKJaZr8wL1+bhFD2Bwwlp6Sr3f980jYFWF9H7NfgDg/W4OGJNQYagARD+cJR/BI/rVuQIA+/qX1eP7jXZAkGGCAA+UczSx+FPA4IJPBoQvHwCDALfkBCQPTCX5kGQjYKyArywX7lP7AMkFH4ATXz+A9kxCWdW2CSX5YLvXQKp6DO+ap3AQAIyViGUCDF89BAYgoWquy8pOgh3cDk/Va20sOwnDsb8CVXPo+fqvsEBEJWTAZIcAwPzNIzCLXsBQtbDW5n+BMSMuBWASvfhIciFfkNGWSSiFDLvA4Fr9BBiTUFI1tymlpxB/4hBgqlDnKPW7Z8AgwFz1XJzF/wH75dNa/Rx5qs5DAGAA3CUnAdEPw+aFYHJoOGqqmgdXaS48bCcgemEs+g/Y1k8AAEZjhfo6xjIBhi+nI9p/VaSqsfiK8+DY+Y06p/ErZ6pfu7+cDmMNz6lS9AIGBypxAuzz+9Xbg+fFVTVvujGUnIIEARC98P68CEx+L+xjlFftG1+cjxjBr57fScX5YHt/ivIZA2zSF0BV39vaqtO/9YQQQghpULyV3sKFCzFw4EDMnz8fo0aNwr59+5CREbow1tq1a3HzzTdjyJAhsFgseO655zBy5Ejs3r0brVu3BgA8//zzePXVV/Hee++hQ4cOeOKJJzBq1Cjs2bPnnLUSWrZ3Geb8MAf7i/bjvLTzMGv4LFzX/bpz8ti1oVba1qE9AvW0jV5TOR+aAppL0tCaVWh7rsybNw9z5swJub2wsBAuV+37WoLJiMscCMheCMwPyD4Isrfq/3mQpo1eRPgS20K2JMNQehBiVc9Nf2wW/MkdIdmOQSrPDdon3OOG3u81eOE3Vl9JF5ZkhD9O+cNFqjgJoYb+lwwC5Jh0MGMMREchBG/tLy3XEsDgYJVgUC6p9sIEGQCDMo5KUyLcQoK6fRkrBoMMB0RUSolg8EEU4xAv+lDKvMhnDAwirDCiGF44jDFwSRkQNJW2RaxCPX4hJLikDGyDA51gRpLm8nYnk8EQqCh0mlPgFpQq2HLm191XaU6CDU4wMCSKCWAohwsCHFIG9uMYGJTXpsKUALegtAyoZPaq8VshwAkZgMOSDkvVGNzsFBgCHzI4zKlwC2bYmBcMXlSKcXDDDQYPYiDCARk2zXz5mAcMPhghwl3VniHGlAoZBXAAcFkyIQgCnKwQDAyimAiGGDC44YGESikODMp5vN8cj1ZCPEpZARgYYsQkuE2JEKvG4jCn4gOUgMGIQUiA26D8kWZlHjB4UAYJbkOm+loLMMNryILAlOddaUmHWTCgjHnB4IIZIrzWLIisEgxKX2uLOR1uQam67gfgAsZwEG6kwoCncBoMPtir5iiflYHBh0QxFmZDGhiOAQDMEGCwZMANAUaUgsGGCjEWbmMqGGOokNx43lCMboIVtyAl4nnrhHIeqq+NaASDF8yUDDdiQrZXYnMPHBDhhBkMgGBKghvxVff71dc6Hka4pehW5VWUgaEMHjEWNmMSGJwwQAAsmep5ZbekwljDrw0b7Mp5BcBpSYdYFfIyxuCVvPAbjBAEARVQzgEdMQYiBDBUwmlKgBsJoQ8AoBTKuWYVE2GBGwzKvx9xYiLcxtA+vhGfcWGx+kFPbdnt9jrtRwghhJCGo22lBwALFy7EV199hXfeeQePPfZYyPZLlizRff/WW2/hv//9L7777jvcdtttYIxh/vz5+Pvf/45rrrkGAPDvf/8bmZmZWL58OW666aaz/pyW7V2GCR9PgAABDAy78ndhwscT8N8b/tvowiXe0zYnISfqfdRKW+ppG5WmdD40djSXpDFoVqFtWloaJElCfn6+7vb8/HxkZWWF3ScrK6tW2wPAjBkzdC0VysvL0aZNG6SnpyMhIXzIUKOr5tVqc3PNm9SaLMsoKyxEeno6RLHptTsWT66HsF3pRSzHtYYMGUJVr1LW/RaYOl6pbuv49TUIpzbAJYjwd7sJwt6liGk9FMn2XNjKj8IDpVlDbHIXCKX74UjuD+Og6bp5qTj8BYS9SwEA5YKAnRc+iFd/eQkdEjvg6YufVgNep9sGYfXdgYEOeASmjAsAAP7KPAhrH1TvkvtMgSt/C4T8bUjreiOEfR/BD+DUxU/Bvf7vao2jr+sNMHVWVneXj66EsPtdWLMugrFQWVhNvOwVmGKUwI6t/zuEskOBeRoyB6bk8+BYNQWCpxze7CHw2w5DqMxDclw2nBWn4NEcn313LwRXCazWNFQ6lU+40wbNhLBpDpw+H6Qrl8AgGeDb9gqE05tg7TkJ1rQ+EH54CLIxFnLOJRCOKBXhue1HwtTzdlRsehJC8V6kXDAVpuyLYfrxYQj2XGxpdwWOHlsFi8GM6y99BaaqXrZpVXNYKQgwjPkPcHojhF9fhyWtJ0wD/w7Tyslw+9wQLpsPU0wmvGWHIKz/O+KsqTD94XXEFe6A8POzAIDUP7wOU9Un9lyvqv+3/vBXCBUnIQ/6O0ypPVG+5z0IR1YgreOVSOz2fzCs+CP8sh/pca1hHv4CACDu0P8g/P4hvDnDYTr/bsiyjH2HN+HYvldRZkrE7Ve8GXKuMsYgCALknf+CcCKwQJs7Jh2CoxCWAY/ClNE3ZL94RyGENffDKxlRkdAOQulBJF44DaZWAwEApo1PQijZCwBISe0B06AnQo4RibnqebCc4ZA7Xgnhx4cRY4qH6Yp/wbzydqWP8qUvwxQb+d9GAPAe+gLC78rPhTzybViqei0H//vi/flZCIX6VgamVgNhkkwQctcB3f4Ppk5XhX2Mys3PQCjaheTz/4KEkj0QTvwAAEjvOxWm1hdH/ZxrE2kHo0W4CCGEkKalLq30gjkcDni9XqSkKB/KHzlyBHl5eRgxYoS6TWJiIgYOHIiNGzeGDW0jXbXJGKvTlTxz1s5RQyVAWedBgIA5P8zB+K7ja328s4lX2raOax32ucqyHDIPKRZlroudxS3qSqdwcxGNpnQ+RKOu81AfGtNcNuQ8NCbNaR6ifQ7NKrQ1mUzo168fvvvuO4wfPx6AMhHfffcdpk6dGnafwYMH47vvvsO0adPU21atWoXBgwdHfByz2QyzOTQ2FUWxSYadWoIgNNnn4YdfbYvLF7Ti3/uZX/ec7F47IAAyZGXBJQGwGCxIsiQBmgK6OFMcBAjwMV/IvJR7ytXjMzBsytsECMCR8iP4vfR39EzrCQDwMq+uXa92LG7ZrbvPwzzqeNJi0tT7fiv+Tb+d7FGP4WM+QFAWqTKIBmXBKLCQ+7XzJAgCKrwVgKCMwSsrY0yyJOFU5Sk4fU51fxmyenx+nBRrCoSqbzyyByajCR7Zo86jyWACBOWx+bEB4IjtCERRVBaSEpSFo0RRVBbQEoBVx1cBAnBlxyuRbA0sopVoSYQgKL8wK32VyoJdgrIQmSiKMIpGuAW3+jq5/C5AUBZnE0VRWaRNCBwr0vltMVgAITC/pa5SQADSY9IhSRISTAkodZciLSZNPUaCKQEQlHOK31bpq4QAQfc6cZXeSjz242PokdpDWThN89q4/cr5YDKYwo7RarICgrJIV5GzCBCAjNgMdVuDZFCPl2xJrtXPsVEyAoJyfrhkZf6sBitEUYRZMsPld6nzWx2n36mOwSW7ECcG2g9o/30JPvcBZTFAkxQ4dyI9Fn+MOFMc4oxxgfMyJuWc/dvVFP+NJIQQQlqyurTSC/boo48iOztbDWl5S73atNuLdNWmzWZDQUFBrf/G2Fe8L+TqJQaGfUX7UFBQUKtjnU1uvxsFlVVXvnksYccmyzJsNhsYC7yX4RclFlUWNarnc7aFnYsoNJXzIVp1nYf60JjmsiHnoTFpTvMQ7ZWbzSq0BYDp06dj0qRJ6N+/Py666CLMnz8flZWV6iUwt912G1q3bo1585TK1gceeADDhw/Hiy++iHHjxuHDDz/E1q1b8a9//ashnwapA5/s032t/QfWE9Suga8+DwA2tw0AYJJMSDDrK6VjDDEhx+bK3GW677flb1O//vLwl2po6/a7ddtpj+Xy6dtpePweVHqVPrlJ5iT1k73fS5Q/JCVBgp/54fa5dfvw8UtViyppH8MvB3rV8vscPocSxlaNwSt71ccEoI4BAGSmbGeRApWFcaY4tZLY5XchDnHqMcySGZIQGIf2+R8rPwa/7IfNY9M9nlGzuJUIEWM7jNWNWRREJFmSUOoqxZa8LThZcVJ9LEAJZyu8FXBUtdlw+JT/568f384iWZRQMAJ+H5/fElcJgMAn/Gpoa01T90msqgbm5xEAJRCH8trwqlruQOkBFDgL4Mh3qOcI5/Q5Q+ZDS/sa8PMv1RKoGtbux+c2WgZR+XXgk33qeWmtWsxOnZegczkc7bnj8DoAa/jt+HMNHgMfBz+fwtGOL07TkzbZnBxpF0IIIYSQM/Lss8/iww8/xNq1a8/oiptIV20mJiYiIyOj1kFE19Su2FWwS/feR4CAbmndwvbpbSiHSpQr/ywGC7q17ab7+5iTZRmCIOiv/Kxa39rmtiElLUX9W7G5CzsXUWgq50O06joP9aExzWVDzkNj0pzmIdrfI83uX7wbb7wRhYWFmDlzJvLy8tC3b1+sWLFC/fTz+PHjuhd3yJAhWLp0Kf7+97/j8ccfR5cuXbB8+XL06tUr0kOQRsrH9KGtrOkVGhwA8VANgBogmiQTksQk3Xaxxtiw+wP6kA5QwktuW8E25NpzkROfA69fv6/2WNp9ACWM4mOLNcaqFY6nKpSF1bJis3Cy4qRuP49cFdqKJhiq+thq58LPQkPbCk/g+Ucb2mrDTotkgdVghcfrUQM0HuiZJJP6x5Sf+XVBn0f24IT9hPr4PCTX/vHVObmzLojjxnUYh//s/Q/e3f2uOt4hrYcoxzEloMBRoIbxPLzloWNOfA56pPZAp8ROIcfVshgsuudS7FJ6Z/HQNt6k9I7VhrbJFiUoLHWXqrdV+JTnJ0OGj/lgFAJhKg+cHV5HxHMj0h+jRtEIEaJ6bhsEg+6DBu1+SZakap9rMPXckX1qoMrng7/2/FyrDg/MAf15FEz7wQMnCZIaPIf7oITj57/FYFGqqKvw14IQQgghJFhdWulxL7zwAp599lmsXr0affr0UW/n++Xn56NVq1a6Y/bt2zfssSJdtVnXKx5nXToLEz6eEDhOVdHHrOGzGlWowd/PtEloA0mSIm4XPA9pscrf3QwMNrcN6bHpZ3+wjURdzommcj7URkNdDdzY5rIpXxVdn5rLPEQ7/qb9LCOYOnUqjh07Brfbjc2bN2PgwIHqfWvXrsW7776r2/7666/Hvn374Ha78dtvv2Hs2LEgTY+uupT5dd8Hh01hK21Fk3Kpu0Z1oW1p1QJw2opGg2hA3/S+AID1J9cDqL7S1unVVxtqK23jTfFqhWihsxAAkB2bHXJMXmlrlIxqpa22upZ/rQ3ltKG1yx8IbXnopb2fh758LAIEGESDGojykE4b2morPh1Bi8ztLNqp9gPiIahBs3Bb77TeCGdcx3HondZbHevo9qMxqNUgda6AwOuqVtpWBXoG0YBZg2fh1h63hj02x5+jW3ZDZjLKXGUAlHYQANApSQl9z0s+T92Hv/42t00NuLXzF1zlzf9glSErLTbC4JXKwQRB0IXnKZYUiELgn3FdaFvLSlttdTQPbYMrbYND5nC0r7c2wA0WrtJWEgOhbXUBMf+gwCyZlfYICHyQQAghhBASjraVHsdb6VXXGu/555/H3LlzsWLFCvTv3193X4cOHZCVlaU7Znl5OTZv3lztMevTdd2vw8ujXla/75PZB8tuWIZru197Th4/WryfbZvENrXazyAa1Cvbip20GFlNrut+HZZet1T9Pjs+u1GeD03Bdd2vw70D7lW/b5vYluaSnHPNMrQlLVNwewTt99qwye1360LPcrcSnJkkk/oHAcdDP23lKsfDXh7kAUC7+HboW7WA1DH7MQCh4ZOXRa60tXvt6th4pS0A9ZKM1vGtlf00bRV07RGqgjdtdS1/PF416Zf9utDa6XOqc8UrSrX38yDSbFDGYpbMEIRA4Mrnj4/DLJn1oW1VcMcvXd9RoCw+FW+KVwNHbfDYKy18lbsoiJjadyo6JHbAoFaDdAGsGtp6g0JbQ0zogaqhhrY+N8rcZZAhQ4SoBqA3d7sZ/7riX7ox8nPGzwLzyittgdDQ/lTlKfVrHvwHM0rh2yMAgdcRAFKDFlTThra1bRWgrY7m55daaStG3x4h6krbqmMJmsa2BsEQqHYOU4nLaStteWhLVbaEEEIIqcn06dOxaNEivPfee9i7dy/+8pe/hLTS0y5U9txzz+GJJ57AO++8g/bt2yMvLw95eXmoqFD+1hMEAdOmTcNTTz2Fzz//HLt27cJtt92G7OxsdY2Vc+HmXjcDUP5e3jZlW6MMlU7YqkLbhNqFtkDVWh8Aih0U2kbjsg6XqV/fM+CeRnk+NBWZsYF+1Y8NfYzmkpxzza49Amm5tNWlPtmnho2AvlJWG0gCgd6gJskUUp0Ya4hVj6fllb1qQNgpsRN+yf8FANAhsQPaxrcFEPg0ObjSUhsgB1cb8hBPhAirwRrSf7VVrHLZlTY8419bJIuuLynH58UkmQCvEkBr50DbKoGHttoKUB4A836qPNhMNFX1cq1qL6FW2oqB3rpAoOq0a0pXbDq9Se3Pq61q1gaZXZK7IJIkSxKeHfZsyO3xxqBKW6++0jZaamjrd6PEWaI+Jg+VBUEICfYNogHxpnjYPXbY3DbEG+OjqrQFQvsiq8cUIv/TrO1rGxLaCmdQaSuGVtqGtEfwR9EeIYpKW5nJavAaZ4pTXzdJlNSgne97uuI0fMyHNvFt1PHx89siWdAjtQcGtxqMCzMvrMWzJYQQQkhLVNtWegsWLIDH48HEiRN1x5k1axZmz54NAHjkkUdQWVmJu+66C2VlZRg6dChWrFhxRn1va4tfFcavFOPfNyb8vVFOQk6t902NScWh0kNUaRslXlQT/DWpPX7eAkCRo6gBR0JaKgptGwGXz4WfTv6E05WncWv3W8M2ZSc101XaBlXGaqtdg0Nbfp9ZMoe2RzCFb4/Af/lJgoR2Ce3U2zsmdlQ/PS5wFsDpc4YEXdUtRMb/EIk1xkIURF1VZYIpQa0q1Ia22qrScD1t+ePxS8e9slc3Ju3c8F6tdo9dXUBLlvU9bXmwyUNBHjxqK35FQVR7r/IQr1tKN2w6vUkdmzb8LHIGfgFGWoSrOmrVb1XYzEPH2lba8vl2+Vwhi5BVJ9mcDLvHjlJ3KXLicnSVth6/ByuOrMCn+z/Fg/0f1AW1wf2GueoWWOAVz4B+EbLg/Wrb01bbSzZ4/moT2mqra4Pbf3Da8zfBlBAIbQVJbUlS6a2EzGTM3DATHr8Hb17xJiwGi25fs0Gp6p7Wb1pUz9Hu8uK0zQWTJMJqkpAeZ4Yo0r+3hBBCSEsydepUTJ06Nex9a9eu1X1/9OjRGo8nCAKefPJJPPnkk/UwuroxSkYkmBNQ7i5HkaOoUYe2dam05YUKFJpFx+ayhf2a1J42tKVKb9IQKLRtBERBxNu73oYMGVd2vJIu862jcC0MOG11a3Boy5nEaiptg47NWyMkmhN1i1J1TOqIBFMCksxJKHOX4YT9RGilbZiFyGIMMXD4HOrCV3whLm2lbao1VRcqcuqiW0Zr2J62PLTlYWtwT1tO2wbAz/xw+pywGqzqoldqpW1VaMgXwOIBNg/T+OMYRAM8skcdX4fEDjCJJjUk1oa2A7MGYnPeZoztULd+0jxsD+5pazXWrsepdsEtHtoGB6PhJJoTAXvgvNDOr9vvxuLdiwEAT26M7o/5akNbSRPaRmiPYBAMasAfLV17BN5+IKi6urYLkUWqtOXnrwhRN06DaFCrox0+BxxehxrEl7nLkGXIUvc1CAZdwF/m8GBfnh378u0osruRFGOCzBjybC54/DIcHj8O5NshBxZ/xX/+PBCJ1tp/SEAIIYQQ0tikWlNR7i5XgqWa/3w959T2CLXsaQsolbYAhWbR0lXaRlhDg0SHn7cA9VQmDYNC20bAJJnQKq4VTlacxLHyYxTa1lF1q81X1x6BM0kmxJvi1VUhgcDl9cGVtrxaMsmchIyYDBhFI0ySCTnxyuU+beLbqKFt8L66hciqKhqTzElw+Bzq97zaUHcpvCVVd/k+p6201fa09cpeGEVjyEJiPtkXdg4MogEmyQSLZIHL70K5p1wXEEaqtLV5lAW4+PPk2xklIzyyRxf6tk9sj/2l+wHo2yPc1ecuDMoehIuyLgoZVzRCFiLz1q2nLZ9vl8+lBujBwWg4/GeWt7eo9FWCt2qNpjo1WHXVxsHnhBYPXhPNibWu2NcuVKcuRFYVevOetjU9F5nJupYfwYvQcepCYgaz7oMJSQi0R6j0VOK0vQw+P4NPlrFizxHEiT4UOU+juMIDgYmYvPhn2JxemA0iKt3hq5aDpcQqYa7T44fFSG3dCSGEENI8pMak4kjZkUYbLJ1JpS0vkmmsz62x4YUkAFXanildpS2df6QBUGjbSLSNb4uTFSdx3H5cXciK1M6ZhrZmyQxJlBBvike5pxwGwaAGStWFtjHGGMwePBsmyaSGbW3j22JX0S6cKD8RcnmSV/ai1FWKAkeBGl4lmhN1fV159WFwVaUaKmoWMOOXoFsNVjW0O1R2CK9uexVXdboq0JOWL0TG/Lo+thx/rgmmBLicSmirDQX5WIJ72pa5y3Tzw48T3JfVLJnRIbGDGtpqK23jTHEYkj0kZEzRCg5t69oeQdsGgFfaRvMhirZVhNfvhcvvgtGgnAtuvxs5cTnIrciN/LiaCmSghtBW0zJDW+UNBOa8tv1sAX1PW3UhsqrzjS+MVlOlbXCP5oiVtpqFxEyiCWAABEAQJOw87sTJUieOFuRh6u8bUWRV2i0sOb0fFr8fHvE0Sq0eSLIFFqcyHp/fD0EA2iTHoGtWPLKTrChzeCAIArISLLCaRIiCgO6tEpCZcO76yxFCCCGEnCuNebEuh9ehrhdBlbZnH/W0rR/l7nLd/NH5RxoChbaNRLuEdth4eiOOlx9v6KE0WdWGtpr2CJEuEeGBXaI5UQltRYNaYRh8bG17BADonNxZd3/bBGUxsuP242qrA+0452+bj99LfkeGNUN3HI7vow1t06xpamsCty9Mpa0xRg1tfy/5HR7Zg52FO9XteAAXqdKWB4XxpngUOAtQ7i7X9Vzl4SX/f217BF2f0aoxaxcjA5T57ZDQQf0+uH/wmYhYaVvLhci0oTg/T6Jpj6ANbYPPL7ffHRL6G0SD7pyyGqzweAKBaPDcaVXXHoGHq7XtZwtArdL2sTALkUVZaRtcWVvprYTHJyPP5kJxhQsFxRXIcJvww7GjOFnqxEm/Bb95CuA0KB8iLDh1GEaPCc4YPwAXGJTzShIFdMqU0C0xA2X+SvxYYkSKKRF/H9UL2UkWuDwyUuNMiDXTrzRCCCGEtEyNue9rbrlSvBBnigt53xMN9bk5G99za4x0PW3dVGlbV/y85RrjzxZp/ugdbiPBV0Y/Vn6sgUfSdEVa1AkIvxAZXyiLU0NbUyJO4ATMklkNQYN72pa6lcvgI1U0to0PhLadkjrp7vPKXhQ4CgAoi5UBYUJbXmkbtOiUtreozGQIEHStAHjwxp+jzRP4Jc2PFamnrTa05ceQWWB+BmQNwAMXPIBuqd10z73MXaaGeUbRCFFQLjkP7stqkkzomNRR/b4uf7BFwsdc4a2AX/brWkbUhhqK+90oc5UBiK7SNtkcaI9g9+oDca/s1YXaANA+oT0Olh1Uv48xxqivlQhRncOwY6w6B0yiKaRvbbo1HQDQLr5dyH41CbcQGV+8jv9sBD8PzuOTcbS4EuuPHUFppQeiIMDjl/F9yQls3rIBMgMYGHxeHwzG03BLx+G0+GH0G2DQ/Bry+QWkWWLhi1UC2PsuaI03dynP8ZqeqRjT4Txsy6/A3i1mdEpMQd82SbV+noQQQgghzREPNhvjJdy8L2hOQk6dFt2mStvaoUrb+sHPW7NkhtvvbpQ/W6T5o9C2kWif2B4AcLLipNqLlNROtJW2PNBMsaboPq1VL/uvChONklENq/zMD7/shygqYZraHiFCRWNOfA5EiLB77Opj8OpKbSjGBYe/4SptUywpukvj3X43RCEQPMcYY9QKTR7Kan9J8ypSr+wN2x6BV2mqoa1XH9qaJTOGtA60MODtESq9lWqLBm1/0uBz2CyZ0TquNYyiEV7ZW6+VtnHGOLUXcYW3ItAeoa6VttqettFU2ladB2XuspA/jNx+t27hOINgQI/UHrrQloejQOB1iDjGqnMg1Zoa8kfv0NZDkROfo/ZWrg3tInZ8vHxcZskMxoDiSgdKKj0oc3hwsKACBwoqcKigAoeLKuGXGdzicRRbAx+QGORKWBkQY5KQGmuC3+eBIBkhxZpx2G9G95QsdEhqgx9OHgZjwMROXXBt14tx+8qFkCGj2B34+eTntLYfLiGEEEIIUTTmYPNM+tkCmtYPFJpFhULb+sHP296ZvbH11FaUucrgk33VLhpNSH2js62RSLWkIsYQA4fPgVMVp9AuofaVci1ddaFtuErbdGu6LrTVtkcAlNBRGzx6ZS+MUL5X2yOYwleLmiQTMmMzcbryNA6VHQIAxBpiYfPY4JE9uvYG4Y4Ta4jVjQlQQjqTaFLDSbfPrS6YJkKERbKoPU15KKvtfcuP5ZN9ajVorDEWlV6lZyj/5cPDVLvHrqteFqAPCONMcRChhNiFzsKQ8Qb/MjOKRgiCgKs7XY39pfvRMbEj6oskSog1xqLCW4FSV6laEVrXnrZFziJ4ZS8ECCE9icPhoXu4SluXz6WOZ9bgWZAECfmOfN022jC+pj8CeJAf3M8WAARBQIfEDiG3R8MgGuCXGUocLhTZfbB5PVi+rRBf+PZiZ9lpHHZV4NTpY/jq1xfhFyqQ6BkFAYGK4ASrAUnJJnjdRjAmQhRlZMQa8MblFyE5xgjGGAoKCpCRkYEfcu1YuNOIzPgEJFiskETl3MpMiIHFaECMMQYV3gq1Ih0I/Nyq/XAl6k1LCCGEEMI15mCTVyzWNbRVq4gbYSDdGAUvRMYYq1OFc0vHz9vzM8/H1lNbAQClzlKkx6Y35LBIC0OhbSMhCALaJbTD3pK9OFZ+jELbOghuYaAVbiGyjJgM7C3Zq94eHNpqFxYDgINlB5FsTUab+DbqpfPVLfiUGaOEtjx4ijUqoa3D69C1ZQAC/WE5XmnLgykBAlIsKRAEAWbJDJffBZffpYaqVqMVgiAEFpMKmguDYFCfi9vvVitR0yxpamjL+5bySttyT7laaStCDPlFLwoi4oxxcDKn2ubBLAaqH7ULkZlEk7r/DV1viDhnZyLeFB8S9GkrWKPBA1Fe1ZlkSYqq6p2fBy6/K6TXlt1jV8P1jokdYTFY1DkPN87gBdyC8XYNrWJb1Tiu6vhlhlNlThwtrsTRokpsP30MR8oqITAPBEiQBQ9+KiqHkRlRafCBmQFB9MBu+AmiIOD81EHo16oXOmfE4bzMeGTEm7HupAf/3G5GVkwW8hx5MEk+pMQq5xVjTH1s7UJk2mpyHljHGJTQttBRqN6nfhDhC+xLCCGEEEIUjbmnrVppW4dFyABNFbGzmALIKGira/3MD6fPWesrEEngvG2f1B5JliSUucpQ5Cii0JacUxTaNiJtE9pib8leWoysjsJV2vK+tV6/F16/FzaPDeVe5ZdYeoz+H1seWvKqV6NohCRK6h8FT29+GvHmeLw54s1Ae4RqQtuMGGWRMR7Y8V+U4RZCC2mPYNS3R0gyJ6mBlhra+lzqc+ahH+9pG0wSJTV85GMXICDVmopjdqWPMr8sn1faahci420hgiUYE+D0OFFQqQSlkSpttcHc2RJvisfpytNqFatZMle7oFc4wePkPWJrYjVYYRJN8MgenLCf0N3HX28Bgjo/scZY9X4RYtjgMpJLci6BQTDgwswLq91OlhkKK9w4UeLAyTInEq1GtEmJwYZDxfjlaAmOlzjg9QeCVL9QCcQAJiOD2SBDEk2Y0LUDWsWnIddVim9Px6JDogG5Fcq5OaSTHf/XXV/Vy/srp8ekI8+RB7ffHfYSIrXFgWTWPXd+/lqNVsAJXQDPg3RetUyVtoQQQgghAdpgs7E50/YIPJD2yT6Uu8uRaKm/tTGao+DFx2wuG4W2dcAXImuT0Aap1lSUucoa5c8Xad4otG1E+OJBtBhZ3YQLba1GKyq9lfDKXryy7RVsyd+i3pcZk6nblgdqXZK7wCAa0CWpi3q7x6u0V7B77Mhz5KmVgpF62gKB0JbjQSyv9NUKXpSLh3o80OJ/qABVvTw9SngV3AYgUkhpEA3qfbxKONYYq++lWhXq8qpf7UJkkcLgeGM88j35anVppNBWe/vZwiuEeWhb29YIQGj1ZrgWBOEIgoAkSxIKHAURQ1uzZFYXGOOV1IASlmvnKpr2CJe1vSzsfXk2F9bsK8DO3DLsz6+AxyeH3Y6zGEW0TYlF+9QYZCSl4aPcGBglZYwCBNwxuCckUcLGU8ewpkBQ22AAwK8Fv+L/uv+f7nh8AThtH2CHzxHSv5gfJ9mcrOvhy89Rfv6XukrV+3ilLa8Sp0pbQgghhJCAxtxCQA2/6lhpazVaYTVY4fQ5UewsptC2BsF9bMvd5WgVf2ZX6bVE2grxtJg0HCo91Ch/vkjzRqFtI9I2oS0A4LidKm3rQtt/lbMalNDWz/zYX7pfd5+2itIoGtVALSc+B2+NfEut5Au+PJ73qDVL5mqr/YJDW/7pZrjQNs4YB0mQ1OfAA8juqd2RHZuNYTnDAs9JUoJWt9+thmT82JEu5ZcESb3svtRdqj5muNBWXYhME9ryuQkWb9QHpZEqRs9laJtXmQeg9ouQAaGVttGGtoBSDV3gKFAr5RPMCSj3lKt/NGmPzQN8QJl3bUuEaNoxyDLDzpM27D5lg83pRbnTh5JKN37Ps0PThQAGSUB2khU5SVYU2t04WlyJHtkJuLx7JrplxSMz3gKxqp9shacCy04HXudEc6IaovLXj39IACj/ThU5i3RzxCtt40xxsEgWuPwuOLyhoe2pilMAgNbxrdV9gMCHAzxw17YR4b2C+Qcm56J6mxBCCCGkqWjMLQTOtKctoPTsPVF+AsWOYnRMrr+1MZqjcKEtqR3GmO68bcyV7KR5o9C2EcmJz4EAAWXuMtjctpDqS1K9cJW22mpLm0e5TKRvel9kxmbqWhIEh4raMJNX+HEHSg8AUEKt6v4YCgltq8bC++vy1g2AUjVokkxqFSGvNMyIycDLl72sO47ZoIRVbr9bDbxqao9gEA1qiMorbeNMcbrgi8+B2h7BE2iPEOm4fFselDZkaMvHwi+pr20/WyD0kvvahLbZcdm6DwbSrGko95Sr5522MlQbKAdX2mqrpX1+GSfLnDBIIvJsTmw7VobjJQ4cLa5EmSPQp1nrwrZJGNwpFT2zE5GdFFjkqybBFb68dy4QaB0S7NeCX3FFuyvU73mv3lhjLGKMMWpoGyy3Qqm2yI7L1rWDUXvahgnc+bHV9ghUaUsIIYQQouILkXn8HlR6K3VXdjUku9uuXq6fk5BT5+OkxqQqoS2FZjWyuYLaIwS1SyA1K3OVqe8/Wie0btQ9o0nzRqFtI2I1WJEZk4k8Rx6Olx9H7/TeDT2kRo8xht+KfkOb+Da6xca44GBHhIhHBjwCSZTU8BKoXajIK22r62cLhLZf0PYxBYD2ie2RZk1DgikBoiDCIlnU0FZbiRmMB6NOn1PdXm2PECm0FQKhLQ+KE82JuvkJrrR1+Bzw+JW2EDVV2vLqx55pPQOP2QA9bYEza49gEA0QIKh9iKPtaQsAE7pMwMZTG+H2KaFimiUNh22H1U+2g+eaV6IaxUBo6/bKOFTgxMIfDiEj3oyvd51Gfrk79MEAxJkNuKhDCjISzIi3GBFvMaBbVjxaJdY+rAZCW2skmzWhbdDPB//AYUveFl1oq1Z+G2IQY4hBCUrU27hyT7labZ4dm428irzAGKrO31iD/mcFUEJbv+ynhcgIIYQQQsKIMcbAYrDA5XOhyFHUaEJbfol5ojkR8eb4Oh+HQrPo8fcfaTFpKHIUUaVtHfDzNtWaihhjTKNuP0KaNwptG5l2Ce2Q58jDMfsxCm2jsL90P57a/BQuzLgQfjm0PYJZMuvaDiRaApd8a0OfSJWE4fCew9pQK5wYYwzijHHqAkrBoW2sMRYP9X8oMIaqYMxqsFa7gBYPQD1+T0h7hEj7SaIUUkmZFZMVNrSNNcaqoRz/VDZipa0xQbf/pTmXqt9rL/k/J6GtUf9HYHX9hiMRBEFd6A2oXaVtRkwGbup6E97b/R6AwB+W/FjBVby8ElWEEUcKnThZ6oTT64fJ78VXp0+r21mMIkRBQJzZgAvbJeO8zHi0SrTgvMx4mAzhw/S60L5eAJBiSVG/Dg5tB2QNwM95P2NH4Q5syduCAVkDAASqYWOMMeo5yW/jTlacBKAE4rzCnOPnb6TWFhXeikBoSwuREUIIIYTopFpTcdJ+EsWOYrRPat/QwwGgaY1Qx362nHp5OoVm1ZKZrIa0bRLaoMhRFFJ5S2oWfN5SewTSUCi0bWTaJrTF5rzNukuGSWT8UvgCR4HaHoFXMAJK5aRRNMLvV0LbFHMgiDJLZjWcrC5UfHzg4/j52M9ol9YOb+9+Gz6mPA5fsKs6GTEZqLCFD22DQyc+huDwMRgPWrWXnvNWAJH6oRpEQ0golx2XresDzPcVBRFxpjiUe8pR5i4DgIhtILRjHZw9WL/AlmYs56Q9gub1ECFiXIdxdTpOXUNbABjdYTT2Fu/FybKT6JDYQXcff93KHB5sP1GGk8UM+c5KHPPaYPYXw2lSXovsxFiM7pqN4yUO9G2ThHF9WsFijBzi1xdBEGAQDOr5rQ29g38+uqd2R2ZsJj4/9Dne3Pkmzks+D4nmRF3lNz/fg9sj8NC2dVxrAEGL1wmR2yMASgBM7REIIYQQQsJLjakKbRtRsKQu5nQG/WyBwN/ljem5NUaVnkr1qsE2iW3wa96vVGlbB8HnLW8/QucfOdcotG1k2iW0AxCo5iTV45WmTp9TDRa1oZtBMMAoGdXvtX06BUGA2WCG0+esNlTsndYbmXIm8oQ83e01tUcAgPSYdBy2HQYQGkQFh058DDUtoMXDXrfPrbscHYhcESsJoZW2reJa6X7pGKVAyBpvilf6sVZV2gYHvpy20lZ7mTxw7tsjaFtKjOkwBu0T29fpOGaDGfAE+rLWhiiIeLDfgygoKEAuU/q2+mUGl9ePA3kuPPDhrzhcqFSeFlkE+CQGEyQkx1hgMpuQYDFiQKt03HlRwyyuIIkSfH4ltNV+wBH885FoTsSItiOwo2AHjtmP4cvDX+KW7rfoK22rzsng9gh8EbLsuOyQYwcvRMalWFJQ4iqB3WNXg2GqtCWEEEII0VODpUZUjZpbrvxNfKahLVXaRkd7pWRWbJbuNhK94POW2iOQhlJ/19aSetE2vi0AZaGecAtrET0e4Dh9TrU9gu6Sf8moq/jUhrZAoEI1mkrQ4KrLaEJbbV/b4Erb4IWyeAjFe7NGwsfq8rvg9CrP32qsWogsQnsE7UJkXHZsti5M1c4TX9SrpkrbLGsWuiR3weBWg9ElqUvIY6pjrkX7ibrKjsuGRbIg2ZKM67teX+fj8NchzVK7KltA6bEMAJVuPzYesuFEiRNHiipx2ubCgXy3Gth2SItF14w0tE6y4ooe2bh9SGekxJpgkISIAfm5oH3NtD8rwRXcSeYkGCUjhuUMAwCUukoBBKpqYwyB9giHyg5hS94WyEzppcxDW7XSVqy+PYJZMqutSCq8FWql7bn4IIAQQgghpClpjH1f6609gpUuT48Gr6pNtCQi0ZKou41ET620DWqP0Jh+tkjLQJW2jUx6TLp6ef/pytNoE39mv9yaO21oyxfL0oa2kiDpQiFtn05AE9pGESrWJbTNiMlQvw5eXClSpW1wuBuMj9ntj77SNji0tUgWJJmTwva0BUJD2+qO++SQJyGKoZ//6ELbc9AeId4Uj/mXzYdZMocE4rXBx8orFaJxtKgS7244iu0nypAaa0JheSVcUgHcVuWDBJNBxHnJKfhjj/NwQZskJMWYsGDHJqw9sR9Wg1k3V8Hh+rmkDYy1oW3w68fPfR6c8iBV22OZn5PrT63H+lPrMbr9aIxJGxPSHkFb4c0fX/uzEmuMVX8mKjwVtBAZIYQQQkgEjTHY5OFXTkLOGR2HQrPo8IA2wZygto+j0Lb2+IcN/LxtjD9bpGWg0LaREQURbRPaYn/pfhwvP06hbQ14aMvA1Co/7WXTBtGgC4WCFw/j4V40VXsmyYQEUwLKPcovvVqHtkFhbPAl4HwM2sv8w1GDMp9bV9kIVNPTVtCHtq3jWkMQBN1caeeJVzraPXYAUAPx2jjX7RGA0ErqulArbavpZ1tod6PM4YEkCvhix2l893s+qopskW93wedjyElNhGg0I85igCQKuLxTDi7rGhrimySTrkK6IUNb7Ti0H3AEv3783Ff7K/tc8MpeeGUvAOXnqkdqD3x1+CvEmeJQ5i7DiiMr4K50o8hZBAhA6/jWIccOV2kba4xVq88rvBURF3YjhBBCCGnpGmMLgXrraUs9RaPCFx1LNCci0axU2lJ7hNqL1NO2xFkCxljEK1EJqW8U2jZC7RLaYX/pfhwrP4aLW1/c0MNp1LSLHMlQLr/WVuAZRIOuivZM2iMASpCnhraahZoiybAGQrrg/qjB1aBmQ1Voa6ohtK3azuV3BRZ+qjp2pPYIkijpqmV5f6NIlbY8SOPHj1RpW51zXWlbX/j8akNbxhi2HS/DxkNF+OVYKYoqPCH7Xdw5Ddf3z0Gly4vK8jK0aWPEQz8G5jQ4ZORBpEE0wChoqk0bQaWtCFHXpkMURBhEA3yyD0bRGPJhh9vvhtvnVre3GCzom9EX7415D5Ig4YvDX2DJniX49tS3MBqMiDfFq9XcuvYIYXraxhnj1J8Ju8euPg5V2hJCCCGE6DW2YJMxVv/tERpRIN0YUaXtmWOMBXraBrVH8Mk+lLvL1dYThJxtFNo2QryvLS1GVjMeKmrpqkdFo66CNNWSGnbbaCtB062BhcUSTTX/Q50Zm4kh2UMQa4wNCS6DQ6deqb2w6dQm9ErtVe0xzWJVaOtzVdseQYSoBtkG0aALZfkiUNq50oZnfKx8fsO1P6iJ9lL7phTaXppzKcrd5bgo6yIAQLnLi/mrDmDL0RJ1G1EAkmNNcHj86JwRh9sGt0O3LOWPIlmWUWB0Q5L0QXfw631+xvlYc2INBmQNgNfvVW9v0NC26rGTLEkh1dUm0QSf7EOSOUm36B+gfIDAWyQYhMC5xo93VcerYBAMWHN4DcrkMlze9vLAcaXqe9rGGGPU6vNSV2nYD2cIIYQQQkjj62lb5ipTF6qtr/YIjSWQbqx4Va02tOXVtyQ6RY4itSUbvzrQYrAgxhgDh9eBIkcRhbbknKHQthFql9AOAHDcfryBR9L4Ba9MDwQqJYHQsDK40pYHP9GGivwPoThjnC4MjkQURDxw4QP/z96dx0dR3/8Df83eu0k2931x31cEhICAFRTFG6q19aRWrV9pLdhWaS2KWtG2Hj+rlXpr1XpUqrZWRFFQJICAXALhEHLfx+4me+/M749hJhtykOzO7Mzuvp+PBw+Sze7MZ2cngbz3Pa83AIiXjgtO77SdUzAHs/NnnzGKQFizJ9AVjyBs6/RBUi1u/j81p8cj5CXkddvW6Y+VutM2WoZGcRyHNO04TDHn4a0yO2raGlDR4oTLF4Bey2D+2GzMHJaOcblWmA39H5PTn/Ppnw9LHoanznsKAPB1zdfi7X1FXESCUDQ9PfsZ4L9HnH6neJkVEHQu+j1dsQW9FFMZhsGFQy7EWZazkJWV1e1NgN4ybU/vtBW6fptcTeLt0XJOEUIIIYREitoKm8Il5unm9B5XHQ6W8HuY0+eEy+cSBzGT7mgQWfiELtvshOxutYV0czqcPidaXC0YjuFKLY/EGSraqpCQY9vqboXD6+h2mTLp7kydtsFdf3qNvkeurPD5QPMxhUvmgwtXAxXceQr0XtwaSHas8Din3wkvy1+mL/wnKHgfGeYMsWir1Wi7F20TexZtgwvXQkFMKAqHkmkbXHwcyKA3JXEch6+PteAf206itt3d4+t5KSbcfeEYDMvsP7oi2OlFxf46Q9WSaSvs+/TsZ6DrNQw+94PjEYR3owdbTNUxOoxJG4MOb4f4s06v1UOv0cPH+roNIhOKtgaNIaRzkhBCCCEklqktQuD0S8zDYTVaxbiuFlcLCvThde7GKqGr1moI6rSlTNtBEfNsTztvMywZqLJXqeb7i8QHKtqqkEVvQZY5C42uRlQ6KjE+fbzSS1Itl6+Xoq2u90FkqabUHoHh5xWdB7vXjrkFcwe0P6GgLmTCDgbDMOJ/NICenbYDJRTF2txt4m3CtoKLfxnmDJS3lfO3M1oEuID4NWH9Bo0BDBhw4HrNtBW6J2Mx09brZ3GssQPf1dqwq6IN39Xy70AbdBqcVZSCYZmJyE8xoyDVjOL0BGg1gwub12l04rEF+n9jILjYrmSnrbCO3ga6Ca9hcEFXeE7ugLvfTtv+MAyD+0vvBweuWyHWorPA5rUhUZ8o5t+2ulpD2gchhBBCSDxQXaetTZohZAD/f8Z0czoaOhvQ4mwJO24hVnXrtDVSp20o+jpv1fb9ReIDFW1VqshahEZXIypsFVS07UdvnbbBnX56rV7sEOztku9ia7EYXzAQEzMm4rfTf4thycNCWC1fFPMjvKKtUCgTBqIZNAaxQBpcXBXeaQf4AmJ+Yj6mZE5BpiVTLHoxDAOj1gh3wN1r0VYQSldj8FrUdCn70QYHPthTi63Hm+ELcOLtOi2Dq6YW4sqS/DNGHwxE8LEF+i80Bhe41dBp29v3ivAaduu0PXW5kMfvEd9AGWjXejCGYcCge1HcoueLtgmGBOQn8llSfs4f8j4IIYQQQmKdMIisw9sBj9/T7dJuJQgdi1IVWNMtp4q2VDTrU2+DyBweB1iOpSvVBqiv81ZtmdEkPlDRVqWKrcXY2bATFQ4aRtaf0zNtg+MQAL5wKHzeWyFqsBiGwdTsqSE/Xq/Vi0W8kDttT/vPV3A+VHDBz2qwwqAxwMt6odPooGE0WDljZY/tmXVmvmgblC16emdsKP/Aq6nTluM47DjRin9/WyN21AJAslmP8XlWjMuzYuawdGRbpS0GBr/e/XbaqqRoKxRm+8q0BboXbYXnxIJFh6+Dv02iLlghEiFBl4BMS6Z49YGU+yCEEEIIiSXJxmTxCrsWVwvykvIUXY94mbkEnbYAFc0GQohCSDYmi0VbDhw6vB3i56R/fZ23aosfIfGBirYqJQwjE35gkJ58rK/HcC+dRtejACYUolKMKZFcXq+CC8qhdgsm6Lrn8gYPbQrubrXoLUjQJ8Dr8fbI0w02ImUE9jfvR25Crnjb6Z2xocQj9FcEjgSO41Bvd6OyxYn399TgQA1frNVoGMwbmYFLJ+dhRFZij8gMKRm1Rjjg4D/up9Oh2znbz2slt8tHXI40Uxqm50zv8bWhyUNR3lqOkSkjxduCzxPhP4hSFVRn582Gy+/CuPRxAIBx6ePQWN3YY7+EEEIIIYTHMAzSzGlocjahxamCoq2t92zQUImXp1PRrE/BnbYmnUmcE2H32KloO0B9nbcUj0CUQEVblSpKKgIAVDoq6VKGPgiDj4JpNdoeQ53mFMxBTUcN5hXMi+TyehVcnAu10zbFlILZebPxde3XALpiEoDumbZmnRkWvQVtnrZ+uzdXTFsBT8DTbT1SxCMEFx8jWWTz+lms/64e6w/Uoaq1Kz5Dr2Vw2eQ8XDo5D+mJkVlP8PMeaKatkp2249LHiUXS090w7gYsGbkEiYauYWzCgDs/60e7px2AdNEFi4YtwqJhi8TPx6aPxabqTfw+qNOWEEIIIaRX6ZZ0vmirgsKS1J22wlBoNTw3tRIaKaxGKxiGgdVoRYurBTa3jXKAB6iv81aIH6Hzj0QSFW1VKjshG0atEZ6AB3WddWKmI+ni9Dl73KZjdNAzXR2eeo0ew1OG4/czfx/JpfVJ6LTVa/TdCqyDdfvk2/G97XvUddZhdNpo8fZunbY6i3iJeX/70jCaHgXkaI1HqG134U/rD+N4Uye/Bi2D/BQzRmcn4UdnFyIrKbLFvuDnHQ2Ztv1hGKZbwVZg0prQwXZI3ml7uuBiMmXaEkIIIYT0TiwsKdyNynEcqu3VAKjTNpKCB5EJf7e4WmgY2QCxHIsaew2AXjptKR6BKECd1QECDaNBYVIhjrUfQ4W9goq2vehtCJnQ+SdQ8lLz3ghrC440CIVeq8ejcx/F55WfY3Lm5B7bB0512p7az2ALgVLEIwTvU65O2wDL4VCdHbXtLuyqbMOOE63wBzgkmXS4dkYxfjAmExaDcueAMAQP6L/QeHp3eDQxao3o8HUVbeV6rbMsWcg0Z6LJ1USdtoQQQgghfVBL7muLq0W8MjI/SZrfZcWiGXU69ik4HiH4byraDkxjZyN8rA8aRtMjXkR400Dp7y0SX6KrOhBniq3FONZ+DJX2SszKm6X0clTn9CFkQO+ZtmoidNpKUXQyao24aOhF3W7rLdMWGHzxWupOWzkKeS0dHqz5+DDK6x3dbp+Qn4y7LhiFjAhFIPRHOI5aRtvvuRicday2c/ZMhHNZiEcINfZjIMamj0VTNRVtCSGEEEL6opbCppALmp2Q3e9sh8GgotmZ2dxdg8iC/xYaLEj/hPM2NzG3x+9lavneIvEluqoDcabI2pVrS3rqrdNWr9HHTdG2N8HP16KzYHz6eOyo34ERKSMGtR0pMm2DC5HBH4fLF2CxqbwJ/9hWgbZOL8x6LcbkJmFIegLOHZ2JYZk9L+FXinAcTTpTvwPPgl83KY9VJAjPUe54BABYWLwQ1Y5qlOaVyrYPQgghhJBoppYIASEXVMocVcoU7V+ADaDTx8fEUadtaPo7b9USPULii7oqWqQbYRhZhb1C4ZWok1C01UADFiwAvqM0uNtUbQUwqeIRzrR9gO+0nV88H/MK54UfjxBC/m7w6yBFpu3+ahs+PViPb6va0e70AQCK0iz4/cVjkZciX3dnOITjeKZO4+BOaLWds2ciPDeHz9HtczmMSB2BNXPWyLZ9QgghhJBop5ZuQKFjUao8W4AyRc8kuDB7etFW6MAl/evvvBXeEHH5XXD6nLDo5fmdnpBgVLRVsWJrMQCg2dWMTl+neKk74QlF2xRTClrdrQD4oqVe21X0CmfYlxwi1WnLgBGLZ6F0G0sZj6BjdGF1PHMch3d3VeP1bRXgOP62FIseV5bkY9HEXJj06nqNgwnn4pkGZwUfn1Dyg5V0+rksZzwCIYQQQgjpn9ANqHSEgNCxWGiVsGhrUUdBWq2Eoq1RaxQjKYR4BOq0HZj+ztskQxJ0Gh38rB8tzhZYkqloS+RHRVsVS9AnIMOcgWZXMyrtlRibPlbpJamK08dn2qab0sWibY9BZCqNR5CrsJVuSsfZOWcjw5wRUqFVoNPwHcsBLgAgtEKi1WiFBhqkmdJCWkNlixNvbK/AwTq72Fn7gzFZmD8mC2NzrTDoQn9+kRIcj9Cf4DcXgt90iAand9bK2WlLCCGEEEL6p5bCpixF21Odtu3udvhZv+p+11OaEFcmdNcGf0yZtgPT33nLMAzSzelo6GxAi6tF0i5yQvqi/qrHAJ08eRI333wzhg4dCrPZjOHDh+O+++6D1+vt93HnnnsuGIbp9ufnP/95hFZ9ZmJEgoMiEk4ndNqmmbuKglpG2+1Sc7X9Qy6sR66iLcMwuGvaXbhx/I1hbyu42zaUArDVYMX9s+7H72b8bsCPqWl34eP9dXhpywn86u1vsfV4C9qdPhh1Gtzxg+FYcf4oTC5MiYqCLTCIeITgNxoGOTROaacXpGlIGCGEEEKIctQSIVBtrwYgbTxCqjlV/LjV1SrZdmOF0E2bbEoWbxM+pk7bgTnTeUu5tiTSoqs60I/Dhw+DZVn8/e9/x4gRI3DgwAHccsst6OzsxF/+8pd+H3vLLbfggQceED+3WNTT5l5sLcbuxt2otNMwstM5/V2dtgKdpvul+HpGXV2LwtrOdLm8Gpi0pq7c4BC7dkenjR7wfT892IBnNx2DL8CJt00bkoqrpxVieGZi1BRqgwmF7zMV6dX8RsOZnF6QjoZzmxBCCCEkVqmm09YmfaetTqNDqikVbe42tDhbkJWQJdm2Y4FQmO2t05aKtgNzpvNWLd9fJH5EV3WgHxdeeCEuvPBC8fNhw4ahvLwczz777BmLthaLBTk5OXIvMSRFVhpG1hehoJhqShWHkek1elXHIwgDyJIMSQqv5MyCO23lylndW9WOt76pQnWbU4xAGJWdhKI0CyYXJmPeqEwwDCPLviNhoPEIDMOIcRRqO2fPpEfRljptCSGEEEIUI3QCtrnaEGADisz4YDlW7FgssBZIuu10SzpftKWiWQ/CsDEhxzb4Y4pHOLMAG0CtoxZA3+etWjrZSfyIrurAINlsNqSlnTlP84033sDrr7+OnJwcXHrppfjDH/7Qb7etx+OBx+MRP7fb+XetWJYFy7LhLzxIYWIhwAGV9kr4A/6wckrPhGVZcBwn+XOQi9PnBDi+s8+sM6PT1wkto4UGGuBUs6YGmrCfj5TH5YLiC6BltJhXME/1x9mgMYjHkQHTY73hHBe7y4eXvj6Jz8sbxdu0DINrzi7EVWcVQKPhC7Ucx4HjuL42o0rBx2VKxhSUJZdhVu6sMx4no9YIp88Jg8ag+nMjmFFjFM8TAH2uP9p+vpxJrDwPQgghhMQWITqOA4c2d5tYxI2kxs5G+FgfGDDIS8qTdNvp5nQcwzHFB62pEXXahqeuo05soslJ7L2pTyja0vlHIiVmi7bHjh3DX//61zN22f7kJz9BcXEx8vLysG/fPtx9990oLy/HunXr+nzMmjVrsHr16h63NzU1we12h732YBpOA7BAp78TBysPIsss3yUgLMvCZrOB4zhoNOq/FL3V0Qqf3wdPhwdaVst/7PLA1mqDz893bba3toPrCK/oJ+Vx0UCD89PPh9fmRSMaz/wABbE+VjyOzg4nGhu7rzeU4+JnOXz9vQ3v7m1EhycAhgHOG5mKOcNSkJ2kh1mvRXNzk+TPJZKCj4tBY8CdI+8EgB7H73RX5F+BZnczWAeLRoe6z41g3k6veJ4AgKPVAaajZ3d0tP18OROHw6H0EgghhBBCetBpdEg2JsPmsaHF2aJI0Va4xDw3KVfyIbvi5enU6dhDv4PI3NRpeybCeZuXlNdnhzrFI5BIU33R9p577sGjjz7a730OHTqEMWPGiJ/X1NTgwgsvxFVXXYVbbrml38feeuut4scTJ05Ebm4u5s+fj+PHj2P48OG9PmblypVYsWKF+LndbkdhYSEyMzNhtVp7fUw4hqYOxQnbCXQaOpGVJW/RlmEYZGZmRkVRhTvCQa/TIzcjF8nNybAH7LAmWpGdmQ29jv/PQU5WTthRBNF2XKSSnJAMvZs/jsnW5B7n3mCOC8dx+PJoM17fVoUGhxsAg+HZVtzxgxEYk6P+qIjBCPV8uTTrUhlXJZ8Mdwb0NV3/GS/MLex18FqsfR+ZTBQDQQghhBB1Srek80VbhQpLVXbp82wF4iAoKpr1IA4iM9IgslAM5Lyl849EmuqLtnfddRduuummfu8zbNgw8ePa2lr84Ac/wKxZs/Dcc88Nen8zZswAwHfq9lW0NRqNMBp7FiU0Go0sxYji5GKcsJ9AVUcVSjWlkm8/GMMwsj0PqbkDboABEg2JsOgtAAPotXoYdAbgVKOfQWeQ5LlE03GRiklnEo+jVqPt9bkP5Lg02N14bEM5DtXxnYmpFgOWnFWASyblQqeNzeMZT+eLWWcWzxMGDEw6U585xLF0XGLhORBCCCEkNmVYMvB92/eKdaMKebaFydIXbSlTtG9CN22vnbaUaXtGAzlv6fwjkab6om1mZiYyMzMHdN+amhr84Ac/wNSpU/Hyyy+H9Ev1nj17AAC5ubmDfqxcipOKAfC5tqSL0+cEwBeNzDozAP5yIKPWCA34wpBeI+3lOPFEikFkh+vt+ONHh9Du9MGo0+DqaYW4bEoeTPrID0Qg8ggePGbUGqN6cBwhhBBCSCxQOndTuMxcjk5bsWhGnY492L2nOm1NPQeROX1O+Fl/1A09jqSBnLdCPAJl2pJIiZnv2JqaGpx77rkoLi7GX/7yFzQ1deVi5uTkiPeZP38+XnvtNZx99tk4fvw43nzzTSxatAjp6enYt28fli9fjrlz52LSpElKPZUeiq180bbCUaHwStTF5XcB4Iu2Fj0/OE7H6GDSmXBHyR3QMlr6RykMwZe4D3YAnscfwDs7q/HermoEWA5DMxJw7yVjkZVEl5THGpO26zUV3jwhhBBCCCHKUTp3U854BCqa9a23QWRJxq4oOofHgVRzasTXFS0Gct7SmwYk0mKmovXpp5/i2LFjOHbsGAoKCrp9TZg+7/P5UF5eDqeT79A0GAz47LPP8OSTT6KzsxOFhYVYsmQJ7r333oivvz9F1iIAQKOzEU6fUyxQxjM/64eX9QIALDpLt05bADgn/xzF1hYrunXa9hHE3pvdlW14dtNx1Nv4oXylw9OxfMEomA3UXRuLgs+T4K5bQgghhBCiDKUv4RaKXwXWgjPcc/AoU7RvQjxCcKatQWuASWeC2++GzWOjom0/BnLeiucfxSOQCImZou1NN910xuzbIUOGiAVcACgsLMTmzZtlXln4kgxJSDOlodXdiipHFUanjVZ6SYpz+p3ix2adGQWJ/A/WnIQcpZYUcwbbaesPsHj+qxP43/46AEBaggG3zR2G0uHpdMl8DDs9HoFIy+Px9JqhTgghhBDSF6W7AcXLzCnTNqJ667QF+CKu2++mYWRnMJDzVuj0tnls8AV80GspjpHIK2aKtrGuKKkIre5WVDoqqWgLoNPbCYC/NFur0eLCoRdiUuYk5CfmK7yy2NGtaIu+i7a+AItDNXb8a1cV9lbZwDDApZPycN3MYuqujQPB5wl12obv448/xltvvYWvvvoKVVVVYFkWCQkJKCkpwQUXXIClS5ciLy9P6WUSQgghRMWEbkAlIgQCbAC1jloA8sYjUKdtT8KwsdOLtlajFQ2dDWInLunJG/CivqMeQP/nbaopFQwYcODQ6mpFdmJ2pJZI4hQVbaNEkbUIe5r2oMJOubYA0Onji7aJhkQAfCdoQZL0l9/Es+DL3nsb6lfT5sKbO+rwbd0JdHoDAACTXoNfXzAaM4alR2ydRFnBObbB+bZkcP7973/j7rvvhsPhwKJFi3D33XcjLy8PZrMZra2tOHDgAD777DM8+OCDuOmmm/Dggw8OeEgnIYQQQuKLkoXNuo46BLgAdBodchKlvwoyuNOW4zi6oi+I0EkbPIgs+HPqtO1braMWHDgYtAZkJvT9f2ytRosUUwra3G1ocbVQ0ZbIjoq2UUIcRkZFWwBAh68DAJCgT1B4JbEruACnY7r/qDja4MDv/70fdqcHOr0OqRYDphan4sqSfBSn02sST4KL+0YdXcYfqj/96U944okncNFFF/X6JsnVV18NgB+o+de//hWvv/46li9fHullEkIIISQKKBkhUG2vBgDkJeUNai7GQAkF6QAXgM1jQ4opRfJ9RKu+4hGEz6lo2zfhvC2wFpwxGjDDksEXbSmig0QAFW2jhFC0rbRXguXYAWWMxjKnj8+0paKtfIKLccHvYB+qs+OB/xyE0xfAiAwzbp43CpMLU6HR0Lvc8Sg4HsGsNfdzT9KfsrKyAd0vPz8fjzzyiMyrIYQQQkg0U7LTVswFlSEaAeDjuBL0Cej0daLF2UJF21O8AS/cfn4QdPAgsuDPhfgE0tNgztt0SzqOth6liA4SEfFd+YsiuQm50Gl0cAfcaHZFPptIbYRO20R9osIriV3BxTgto4XbF8Dazcdx93v70OHxY0xOEn79gyJMLkyhgm0c0zAa8VyhTlt5dHZ2wm6nzghCCCGEDEzwhPvgQdyRUGXni18FVvmi6yjXtqfgLtokY1K3r1Gn7ZkN5rylYXgkkqhoGyV0Gp04ZIsiEroybS16i8IriV3BnbYuL4vfrduPj/bVgeOAH4zOxP2XjoNJTz9CSFeBnzJtpXXw4EFMmzYNSUlJSE1NxcSJE7Fz506ll0UIIYQQlROKSj7WB4fXEdF9y91pC3Q9PyUGramVMGQsQZ8Anab7BdVC0ZYGkfVtsJ22AJ1/JDKo4hJFKNe2iziIjDptZSMU4jw+Fi9uqcDRxg4kGnV44PLxWHHBaFgMlK5CeEKxNngoGQnfbbfdhmXLlqGjowMtLS1YvHgxbrzxRqWXRQghhBCVM+vN4v/LIt0NKHQsFibLWLS1UKfj6frKswW64hGo07ZvgzlvxU5b6vQmEUBF2ygSnGsb7ygeQX56xgCb04fqNifaO/3ISTbhL1dPRklRqtJLIyojdGUHR2qQwbv88stRU1Mjft7U1ITLLrsMFosFKSkpWLRoERoaGhRcISGEEEKihVIRAmLxS8ZOWzH+gYpmIiGvtreirdhpS5m2fRrMeRscP0KI3KhoG0WKk04VbR1UtBUGkVE8gjxq2l14dlMFmjo84ACMzU3G41dPRn4KdVKSnkw6U7e/SWiuu+46nHfeeXjqqafAcRyWLVuG8ePH45prrsGSJUtw4YUX4le/+pXSyySEEEJIFFAqd7PaXg1A5k5byhTtQeiiTTYl9/iacBt12vZtMOctddqSSKKibRQpshYBAOo768XJkPGKOm3lIQwb+7/Xd+FovRsMgMxEI24oHYokk17p5RGVSjfx/3FJM6UpvJLodtVVV2HHjh04ePAgZs6cidmzZ2PDhg2YPXs25syZgw0bNuDee+9VepmEEEIIiQJCN2Akczd9AR/qHHUAIpNpS0WzLv3FI9Agsv55/B40djYCoExboj4UShlFko3JSDYkw+a1ocpRhZGpI5VekmKEom2CPkHhlcQOjuPw1Maj+Ooo/4/PlKIMlMMCvVbTI8yekGA3TbgJs/NnY1LmJKWXEvWSk5Oxdu1abNmyBTfeeCPOP/98PPjgg7BY6KoCQgghhAycEvEItY5acOBg0BqQmZAp236oaNaTMGRMyK8NJtxG8Qi9E7pszToz0sxnbkKhNw1IJFGnbZShXFueEI9ARVvpfLCnFl8dbYZGw+APl4zD7y6aBL2W/xHBgFF4dUTN0kxpmJE7AxqG/kkJV2trK3bt2oWJEydi165dsFqtKCkpwf/+9z+ll0YIIYSQKKJEhICQC5qflC/r/wsp07Yn6rQNnXDeFlgLwDBn/r2XMm1JJNFv2FFGKNpWOCoUXomyKB5BOizL4a0dlXjp6xMAgFvmDMXZQ9O6DZXSMlqllkdI3HjzzTdRUFCAiy++GMXFxfj4449x33334YMPPsCf/vQnXH311TSIjBBCCCEDokQ3YJXt1DAnGfNsAcq07Y3QRdtbp604iMxNnba9Gex5K3R6t7pawXKsbOsiBKCibdQRcm3judOW5Vi4/C4ANIgsHCebO/Ho+sO47fVdeGN7JTgOuGxyHi6emAsA0Gu6Mmy1GiraEiK3lStX4qWXXkJ9fT02btyIP/zhDwCAMWPGYNOmTTj//PNRWloq+X5rampw3XXXIT09HWazGRMnTsTOnTvFr3Mch1WrViE3NxdmsxkLFizA0aNHJV8HIYQQQqSjRKat0LEoZ54toEz0g9r112lLg8j6N9jzVnjTIMAFqBBOZEdF2yhTlMQXbSvsFeA4TuHVKKPT1yl+TPEIoWm0u/GHDw5gy9Fm1Nvc0GsZ3Dl/JG6ZO0y8JIRhGLHbli57J0R+HR0dGD16NABg+PDhcDqd3b5+yy23YNu2bZLus62tDbNnz4Zer8fHH3+MgwcP4rHHHkNqaqp4nz/96U946qmnsHbtWmzfvh0JCQlYuHAh3O74HohJCCGEqJkShU2xY1Huoq2ZMm1PJ3Ta9heP4Al44PF7IrquaDDY89aoM4p1CHrjgMiNpgtFmfykfGgZLZx+J1rcLcgwZyi9pIgTirYmrYkGZIWgw+PHgx8dQrvThyEZCfjp7CEYnpUIq0nf475GrRGegIeKtoREwI033oiLL74Y5557Lnbu3Inrr7++x32ysrIk3eejjz6KwsJCvPzyy+JtQ4cOFT/mOA5PPvkk7r33Xlx++eUAgNdeew3Z2dl4//33cc0110i6HkIIIYRIQ4kIgWoHP9BJ9niEUwVpt98Np89JV1+iq4tW6KoNlmRI6na/TJ18Q+KiUSjnbYYlA522TrQ4WzAibYRcSyOEOm2jjV6jR35iPgC+2zYeCUVb6rIdvMoWJ+56Zw9ONncixaLHHy4Zi5Ki1F4LtgCQYkwBACTpk3r9OiFEOo8//jj+/ve/o6SkBE8//TRWrVol+z4//PBDTJs2DVdddRWysrJQUlKC559/Xvz6iRMnUF9fjwULFoi3JScnY8aMGSgrK+t1mx6PB3a7vdsfgC8AsyxLf1iWjgUdBzoOdBzi4lio1TPPPIMhQ4bAZDJhxowZ2LFjR5/3/e6777BkyRIMGTIEDMPgySef7HGf+++/HwzDdPszZswYGZ/BwMRyp22SIUmMcqNcW15/8QhajRaJhsRu9yNdQjlvKaKDRAq1KUahImsRKh2VqLRXYmr2VKWXE3E0hGzwWJbD/w7U4dWtJ+H2schMMuLei8ciK8nU7+N+UfIL1HXWITcxN0IrJSS+XXrppbj00ksjtr/vv/8ezz77LFasWIHf/e53+Oabb/DLX/4SBoMBN954I+rr6wEA2dnZ3R6XnZ0tfu10a9aswerVq3vcbrPZ0NjYCI0mvt8vZlkWNpsNHMfF9bGg48Cj48Cj49AlVo6Fw+FQegm9evvtt7FixQqsXbsWM2bMwJNPPomFCxeivLy816tZnE4nhg0bhquuugrLly/vc7vjx4/HZ599Jn6u0yn/a7YSE+6FbNACa4Gs+2EYBumWdNR31KPF1SJ7Z280ELJVextEBvDF3A5vhxijQLqEct7SMDwSKcr/a0IGrdhajC01W+K309bLd9rSZTAD9+RnR/BFeRMAYFJBMn67cAySLb131wYrshaJw+8IIfJ56623Bhw1UFVVhcrKSsyePTvs/bIsi2nTpuHhhx8GAJSUlODAgQNYu3YtbrzxxpC2uXLlSqxYsUL83G63o7CwEMnJycjKyorqIoQUWJYFwzDIzMyM62NBx4FHx4FHx6FLrBwLk6n/xgClPP7447jllluwdOlSAMDatWvx0Ucf4aWXXsI999zT4/7Tp0/H9OnTAaDXrwt0Oh1ycnLkWXSIhKJSp68Tbr8bJp28r8nbB95GY2cjAOC6f1+HB3/wIBaPXSzb/tLNp4q2VDQD0H+nLcAXc2sdtdRpexqnz4lWVyuAwcUjCJ22lKscXdYdWofVm1fjSPMRjMoYhfvm3Tfon1NSbGMwqGgbhYRhZJWOSoVXEnksx6LTzxdtqdN2YA7V2fFFeRM0DHDL3GFYNCEXGg2j9LIIIUGeffZZrF69GkuXLsWll16KsWPHdvu6zWbD119/jddffx2ffvopXnzxRUn2m5ubi3HjxnW7bezYsXjvvfcAQPwFtKGhAbm5XR33DQ0NmDJlSq/bNBqNMBqNPW5nGAYajSaqixBSoWPBo+PAo+PAo+PQJRaOhRrX7vV6sWvXLqxcuVK8TaPRYMGCBX1G/gzU0aNHkZeXB5PJhNLSUqxZswZFRco2PliNVug0OvhZP1qcLci35su2r3WH1uGa97refD7UdAhL3lmC965+T7ZiBhXNuutvEFnw7UJHLuEJ0QiJhsQ+u5R7I3baUjxC1Fh3aB2WvLMEDBhw4LC/YT+WvLME9865F+cUnTOgbWyp3IKHvnqoxzbk/FlHRdsoVGwtBgDUddTBG/DCoDUovKLI2F63HU99+xSGWIcAABIMlGk7EG9u54v7543JxiWT8hReDSGkN5s3b8aHH36Iv/71r1i5ciUSEhKQnZ0Nk8mEtrY21NfXIyMjAzfddBMOHDjQI64gVLNnz0Z5eXm3244cOYLiYv7fmaFDhyInJwcbN24Ui7R2ux3bt2/H7bffLskaCCGEkEhobm5GIBDoNfLn8OHDIW93xowZeOWVVzB69GjU1dVh9erVmDNnDg4cOICkpJ5zITweDzwej/j56dnvUkozp6GxsxFNnU2yxp2t3rRaLGIAAAcODBis3rwaV4y+YsDbCc50PhOhaNbsbFZ1hnKoBnMsOI4TO2iTDEm9PkYo2ra726PqeA3mOISiop2/ernQWgiO48Bx3IAeF+nzT+7jEC3COQ69/ZwCgIe+emjQ2wr3Zx2AAT8HKtpGoRRjCpIMSXB4Hah2VGNYyjCllxQRb5e/DT/rx7H2YwCABB0VbfvDcRy2fd+KPVXt0GgYXHM2ZT0RomaXXXYZLrvsMjQ3N2PLli2oqKiAy+VCRkYGSkpKUFJSInnn0vLlyzFr1iw8/PDDuPrqq7Fjxw4899xzeO655wDw3V6/+tWv8NBDD2HkyJEYOnQo/vCHPyAvLw9XXHGFpGshhBBCotFFF10kfjxp0iTMmDEDxcXFeOedd3DzzTf3uH8ks9+T9cloRCOO1x5HDiNffEN5S7lYxBBw4FDeXI7GxsYBb2cwmc4W8FF5FU0Vg9pHtBjMsXD5XfCzfgCAx+5Bo7vn8TCCvwqqtrk2qo6X3Dnfh2oOAQCyTFmDOi6GAN84V9sWmeMZK3nn4QrnOPT2cwoAGDAYnz5+QNv4ruU7SX7WAQPPfqeibRRiGAbFScU40HIAFfaKuCna5ibkoqajRvxcmIBJeqq3ufHYhnIcrud/EFwwLhvZVnVmixFCusvIyIhYQXT69On497//jZUrV+KBBx7A0KFD8eSTT+Laa68V7/Pb3/4WnZ2duPXWW9He3o5zzjkH69evV21eISGEENKbjIwMaLVaNDQ0dLu9oaFB0jzalJQUjBo1CseOHev165HMfs+x5uBo+1H4jf5eB61JZXT6aOxr3NftNgYMxmSMGdR+B5PpXJDGD43yaDyyPjelDOZY1Hfww2EZMBiaPxQapuf9s6z8MWINbFQdL7lzvm2H+biI4RnDB3VcijP5q9I62I6IHM9YyTsPVzjHoa+fU5OyJ2H3rbsHtI2Sv5dgf+P+boXbUH7WAQPPfqeibZQqshbhQMuBuMq11Wq03T6nQWS9q2134Xf/3o+WDi90Wgbnjc7CT2cPVXpZhBCVuuSSS3DJJZf0+XWGYfDAAw/ggQceiOCqCCGEEGkZDAZMnToVGzduFN8cZVkWGzduxLJlyyTbT0dHB44fP47rr7++169HMvtdyH1tc7fJWui579z7sOSdJeLnwiXI9827b9D7HehxyEjIAMBnisZqEWugx6LD1wEASDImQaftvcSTbOLzWh1eR9QdLzlzvqsd1QCAouSiQW0/MyETQGTPv1jIO5dCqMdBip9TwjaEx4bzs26g94/vVzuKCbm2FfYKhVcSOR6/p9vnNIisJ4fbJxZsC9PMeO76afjF/JEwG7RnfjAhhBBCCCExbMWKFXj++efx6quv4tChQ7j99tvR2dmJpUuXAgBuuOGGboPKvF4v9uzZgz179sDr9aKmpgZ79uzp1kX761//Gps3b8bJkyexdetWXHnlldBqtfjxj38c8ed3OnFYklPeYUmLxy7G1NypAACdRodJ2ZOw7up1uHLslbLtM8PSVbSNd8Jwsf4GadEgst5V2flBZAXWgkE9Tjz/ZP7eItJZPHax+LrpNfqQfk4tHrsY7139HiZlT4JJZ4rIzzrqtI1SRVZ+GmmlvRIcx4FhGIVXJD9PoHvRNs2UptBK1OvVrSfR0uFFXooJD185ESmW+BhSRwghhBBCyJn86Ec/QlNTE1atWoX6+npMmTIF69evF4eTVVZWdut+qq2tRUlJifj5X/7yF/zlL3/BvHnzsGnTJgBAdXU1fvzjH6OlpQWZmZk455xzsG3bNmRmZkb0ufUmkhPuhUzVD675AItGLpJ9f5EqSEcDYQiZUJjtjVDQtXvtEVlTtKiy8UXbwuTBzX8RuthbXC1xU4+JdtX2ajQ7m6FhNGi9uzXkuM3FYxdj8djFEq+ub1S0jVKFiYXQQAOHz4FWd6v4j1YscwfcAIBrx14Li86CsWljFV6RuhysteOT7/iMrl/OH0kFW0IIIYQQQk6zbNmyPuMQhEKsYMiQIWecJv/WW29JtTTJCV1lzc5m2fcldCwWWiMz/Di4aBbvbB6+e7a/oi112vYu1PNWqL+4/W44fU4kGGhIutqVVZUBACZnT46q+UgUjxCl9Fo9chNzAQBVjiqFVxMZQjzCiJQRWFC8gN7NOoXjOHx5pAkP/4+ffHn+uGyMz+v70hhCSHTwer0oLy+H3+9XeimEEEIIiUKRKmw6fU60uloBDL5jMVRC0SwSBWm1Ezpthdza3ghfE+5L+GMhHI/BnreJhkToNXoA9MZBtCir5ou2swpnKbySwaGirQpwHAe724dGhxss2/87ucHiLddW6LQ1ansG98ezt76pwp8/KYfN5UNRugU3zR6i9JIIIWFwOp24+eabYbFYMH78eFRW8gMnf/GLX+CRRx5ReHWEEEIIiRaRihCotvPDnBINif3mqkpJKEjbPXb4Ar6I7FOtBhKPIHyNirZdhPM2xZQy6M5LhmG63hShiI6osLVqKwCgtKBU4ZUMDhVtVSDAcrj2+e24+ZWd6PQOvKOqKInPtY2Xoq034AUAmHQmhVeiHlWtTrz9Dd9pffX0Qjxx9RRYTXqFV0UICcfKlSuxd+9ebNq0CSZT18+7BQsW4O2331ZwZYQQQgiJJpHqtBVzQa2FEbsaMtWUCgb8voQu33g1kEFkwteEKAXS/bwNBQ3Dix4unwu763YDoE5bEgKdVgO9lv8Hx+ULDPhxcddp66dO22Acx2Ht5uMIsBymD0nDdTOKYNDRtzQh0e7999/H008/jXPOOafbLz7jx4/H8ePHFVwZIYQQQqJJpDptxVzQCEUjAIBWo0WqORUAFc2o0zY04Z63NAwveuyq2wUf60NOYg6GpAxRejmDQhUelTDqtAAAt5cd8GOKrHynbW1HbcxfEuJn/fBzfBeySUudtp0eP5749Aj2Vdtg0Glw27xhlPFLSIxoampCVlZWj9s7Ozvp+5wQQgghAyZ0Ara52+Bn5cvIFzoWC5IKZNtHb6hoxhO6Z/vrtA0eRHam4XrxItzzVuhkp1xl9ROGkJUWlEbd71NUtFUJs4Ev2nr8A++0TTelI1GfCBYsajpq5FqaKngCHvHjeO+0/a7Whl/+81t8Ud4EDQPcMmcosq1UyCYkVkybNg0fffSR+LnwH4sXXngBpaXRlcFECCGEEOUInagA0OZqk20/SnTaAlQ0Ewyk01YYRBbgAnD5XRFZl9pJ1mkb553e0WBrNZ9nG23RCACgU3oBhGfW80XbwcQjMAyDwqRCHGo9hEpHJYYkD5FpdcoTohE00ECnid/T9t/fVuOVr0+C5YBsqxF3XTAaY3P7/seZEBJ9Hn74YVx00UU4ePAg/H4//t//+384ePAgtm7dis2bNyu9PEIIIYRECZ1GhxRTCtrd7WhxtSAzIVOW/YjFrxCzQUNFmaI8odO2v6Jtgj4BGkYDlmNhc9tg0VsitTzVCve8Fc+/OO/0VjuO48QhZNFYtKVOW5UwnsoidXkHXrQFunJtT9pOSr0kVRE6bU06U9S1s0tly9FmvLSFL9j+YEwWnvpxCRVsCYlB55xzDvbs2QO/34+JEydiw4YNyMrKQllZGaZOnar08gghhBASRSIRISAOdIp0py3FIwDo6rQVuml7wzAM5dqeJtzzljpto8OJ9hNo7GyEQWvAWblnKb2cQYvflkWVMZ2KR3D7B55pC3Tl2lY6KiVfk5q4A6eGkOniMxrh+6YOPPnZEQDAFSX5uPmcoQqviBAip+HDh+P5559XehmEEEKIYlasWDHg+z7++OMyriS6ZVgycLztuKwRAtX2agCR77SlohlvIPEIwtfb3e1UtAXffRnueUvxHNFB6LI9K/csmHTRFytJRVuVEOIR3IOIRwCAIdYhAIBKe2wXbT3+U522cTiErLzegfs//A4eP4sphSm4adYQpZdECJGRVqtFXV1dj2FkLS0tyMrKQiAwuH8nCCGEkGj07bffdvt89+7d8Pv9GD16NADgyJEj0Gq1dBXKGQiFJbkKmw6PQ7w8v8Aa4UFkVDQDwA8XA/ofRAYEDSM79XrFs3Z3Ozp9nQBCP2/pTYPoIEYjFERfNAIQY/EIQ4YMAcMw3f488sgj/T7G7XbjjjvuQHp6OhITE7FkyRI0NDREaMVdTHr+pRhs0bYgqQAMGNi8tpj+4SvEIxi0BoVXEjkcx+GL8kb84f0D6PD4MSo7Cb+9cDS0mviMhyAkXvQ10dfj8cBgiJ+fgYQQQuLbF198If659NJLMW/ePFRXV2P37t3YvXs3qqqq8IMf/AAXX3yx0ktVNbkjBIRc0GRjMpKMSbLsoy+UacsbaKetUNSlTtuu8zbdnA6z3hzSNijTNjqUVZcBiM48WyAGO20feOAB3HLLLeLnSUn9/8OxfPlyfPTRR3j33XeRnJyMZcuWYfHixfj666/lXmo3Jl1onbZGrRE5CTmo66zDSftJTM6cLMfyFCcUbc260H6gRhuW5fDkxqP44nAjAGByYTJ+v2gczKdiNAghseepp54CwGeOvfDCC0hMTBS/FggE8OWXX2LMmDFKLY8QQghRzGOPPYYNGzYgNTVVvC01NRUPPfQQLrjgAtx1110Krk7d5O4GVCrPFqBMWwBgOXZAmbZAUKetO3abvQZKivNW7i52Ej6Hx4F9DfsAAKWFpQqvJjQxV7RNSkpCTk7OgO5rs9nw4osv4s0338R5550HAHj55ZcxduxYbNu2DTNnzpRzqd0IxbjBDiID+Fzbus46VNorY7Zo6/afyrTVxkem7TcnW/HF4UZoNAx+PL0QV00rpA5bQmLcE088AYDvtF27di202q43aQwGA4YMGYK1a9cqtTxCCCFEMXa7HU1NTT1ub2pqgsPhUGBF0UPuCAGhYzHSebYAFc0AoNPbCQ78VVpn7LQ1UaetQIrzVnjTwO6xwxfwQa/VS7I2Ip0dNTvAciyKk4uRl5Sn9HJCElPxCADwyCOPID09HSUlJfjzn/8Mv9/f53137doFn8+HBQsWiLeNGTMGRUVFKCsri8RyRUZ9aIPIgK5c2wp7hZRLUhVhEFk8ZNpyHId3d/Gh6ItL8nHN2UVUsCUkDpw4cQInTpzAvHnzsHfvXvHzEydOoLy8HJ988glmzJih9DIJIYSQiLvyyiuxdOlSrFu3DtXV1aiursZ7772Hm2++GYsXL1Z6eaomd4SA2LGoRNHWTJm2QgFWy2jPeFWq1WDt9ph4JsV5m2JKAQP+9/R4fuNAzaI9GgGIsU7bX/7ylzjrrLOQlpaGrVu3YuXKlairq+tzmmh9fT0MBgNSUlK63Z6dnY36+vo+9+PxeODxeMTP7Xb+hx7LsmDZwRddAcCkY8CBg8vrH/Q2ChMLAY4fRhbq/gF+/RzHhbUNubh9boAD9Bp9xNcX6eNyoMaGw/V2GLQaXDIpR5WvB6Du80VJdFx6F2vHRc7n8cUXX8i2bUIIISQarV27Fr/+9a/xk5/8BD6fDwCg0+lw8803489//rPCq1M3uSMEqu18s4ki8QinOm1bXa1gORYaJuZ60s5ImGuTbEoGw/Tf6CN02sbyLJyBqnaEf95qNVqkmlPR6mpFi7MFOYkDu+KbRI4whKy0IDqjEYAoKNrec889ePTRR/u9z6FDhzBmzBisWLFCvG3SpEkwGAy47bbbsGbNGhiN0l1Wv2bNGqxevbrH7U1NTXC73SFt0+PsgN/nR0u7A42NjYN6rNljhs/vw4m2E6itr4VOE9rLyrIsbDYbOI6DRqOuf/Ca25vh8/vgd/sHfXzCFcnj4nD78ezmKvh9fswdkgpfRzsaO2TdZcjUfL4oiY5L72LtuMh9KWZ1dTU+/PBDVFZWwuv1dvtaX29EEkIIIbEoEAhg586d+OMf/4g///nPOH78OABg+PDhSEhIUHh16id3hICi8QinCtIsx8LmtiHVnHqGR8SegQ4hC74PddpK1yGeYcngi7bUaas6LMdSp20k3HXXXbjpppv6vc+wYcN6vX3GjBnw+/04efIkRo8e3ePrOTk58Hq9aG9v79Zt29DQ0G8u7sqVK7sViO12OwoLC5GZmQmr9cw/LHuT3cJBp2+B1mBCVlbWoB6byWXCesgKl98Fv8WPPGtoWR0sy4JhGGRmZqquqKJv0UOv0yMjOWPQxydckToula1OPLLpEBocfiRZjLh+zihkWdUbB6Hm80VJdFx6F2vHxWSS73tz48aNuOyyyzBs2DAcPnwYEyZMwMmTJ8FxHM466yzZ9ksIIYSokVarxQUXXIBDhw5h6NChmDRpktJLiipyd9qKRVsFOm2NOiMSDYno8HagxdUSl0VbYahYsrH/IWRA0CAy6rSV7LylYXjqdbj5MNrd7bDoLZiUHb3/bqi+aJuZmYnMzMyQHrtnzx5oNJo+i3xTp06FXq/Hxo0bsWTJEgBAeXk5KisrUVrad/u00WjstXNXo9GEXIywGPVgwMDjZ0PaRnFyMQ63HkZVRxWGpAwJaQ0AP7U8nOchFy/rBRjApDcpsja5j0tNuwt/+OA7tDt9yLGaseqScchNsciyLymp9XxRGh2X3sXScZHzOaxcuRK//vWvsXr1aiQlJeG9995DVlYWrr32Wlx44YWy7ZcQQghRqwkTJuD777/H0KFDlV5K1AnOtOU47oyX0A8Gx3Fix2KBtUCy7Q5GujmdL9o6WzAibYQia1DSYDpthcJuvHfachwnxnqEe97KPeiPhK6siu+yPTv/7KgeEhf9vzmfUlZWhieffBJ79+7F999/jzfeeAPLly/Hddddh9RU/h23mpoajBkzBjt27AAAJCcn4+abb8aKFSvwxRdfYNeuXVi6dClKS0sxc+bMiK7fpOdfCpcvENLji5KKAACVjkrJ1qQmbj8fO2HUShdzoRZNDg9+/+/9aHf6MDQjAY9dPRlF6eov2BJC5HHo0CHccMMNAPi8PpfLhcTERDzwwANnjAsihBBCYtFDDz2EX//61/jvf/+Luro62O32bn9I34Sikp/1S16sa3e3o9PXCUDBom2cF82CM23PROy0dcd3p22zs1msL+Qn5Ye1LbHTluIRVCcW8myBEDttq6qqwDAMCgr4H8w7duzAm2++iXHjxuHWW2+VdIEDZTQa8dZbb+H++++Hx+PB0KFDsXz58m4xBj6fD+Xl5XA6neJtTzzxBDQaDZYsWQKPx4OFCxfib3/7W+TXr9MCANwhFm2LrcUAgAp7hWRrUhNvgM90jLWibYDl8OdPDqOlw4uiNAsevHwCks3R+y4QISR8CQkJYo5tbm4ujh8/jvHjxwMAmpvj8xcSQggh8W3RokUAgMsuu6xbp6jQORoIhPY7VDww6Uyw6C1w+pxocbUMqLg3UMIl5unmdFj0yjSdBHcSx6NBddqaqNMW6DpvsxOyYdSFV18Qzz+KR1CdrdV80Taa82yBEIu2P/nJT3Drrbfi+uuvR319Pc4//3yMHz8eb7zxBurr67Fq1Sqp13lGZ511FrZt29bvfYYMGQKO47rdZjKZ8Mwzz+CZZ56Rc3lnZDYIRdvQJpIXJvFZLJX22Oy0dfldAACzzqzwSqT1xvYKHKpzwGzQ4t5LxiLZQgVbQuLdzJkzsWXLFowdOxaLFi3CXXfdhf3792PdunURvwqEEEIIUYMvvvhC6SVEtXRzOl+0dbZgWGrv82BCIQ5zUiDPVhDvmaJi0dZAg8gGSsrzljpt1anV1YrDzYcBADMLovv3p5CKtgcOHMDZZ58NAHjnnXcwYcIEfP3119iwYQN+/vOfK1K0jXYmPV+0DTkewcrHI7R52mDz2AYURB5NPAEPgNjptOU4Du/urMa7O/ksnV+cNwK5ybFVkCaEhObxxx9HR0cHAGD16tXo6OjA22+/jZEjR+Lxxx9XeHWEEEJI5M2bN0/pJUS1DEsGquxVkkcICLmghVYVFG3jtGgmDiIbQAe1UCOI90FkUp638R7PoVbbqvmGzlHpo8Ru6GgVUtHW5/OJg7g+++wzXHbZZQCAMWPGoK6uTrrVxRGTjs+09fgCIQXEm3VmZFuy0eBsQJWjKuaKtu5A7GTasiyHF7Z8j//s5b9XfjS9EHNGhjZsjxASe4YN6+qASUhIwNq1axVcDSGEEKIeTqcTlZWVYoyQYNKk6J0MHglCYUnqwqZwmbmiRds4L5oNJh5BuI/D4wDLsdAwMTPiaFCkPG/j/U0DtRLybKM9GgEIcRDZ+PHjsXbtWnz11Vf49NNPxWnWtbW1SE9Pl3SB8UKIR2A5wBsILSIhlnNtYyXT1hdg8ZcN5WLB9mdzhuK6mcUKr4oQEg3WrVtHv5QSQgiJS01NTbjkkkuQlJSE8ePHo6SkpNsf0j+5IgSE4pdSQ8gAyrQVB5ENoGlLKNpy4NDh7ZB1XWom5XlLmbbqVFZdBgCYVRCnRdtHH30Uf//733Huuefixz/+MSZPngwA+PDDD8XYBDI4plODyIDQc22FiIRYzLUVOm1NOpPCKwkdx3F48rMj+OpoMzQaBnddMAqXTwlvWiUhJLb8/e9/xw9/+EP85Cc/wfbt2wEAn3/+OUpKSnD99ddj9uzZCq+QEEIIibxf/epXaG9vx/bt22E2m7F+/Xq8+uqrGDlyJD788EOll6d6cnUDUqat8gbTaWvSmaDX6Ls9Lh5JmmkrUxc7CZ2f9WN7Nf97VGlhqcKrCV9I8QjnnnsumpubYbfbkZqaKt5+6623wmJRZmpktNNoGBh0Gnj9LNy+AJLNgx9IVZx0qtPWEXudtm7/qaKtNnqLtut21+DLI3zBdtUlYzG1OE3pJRFCVOSRRx7BqlWrMGnSJBw+fBgffPABfv/73+Ovf/0r7rzzTtx2223d/s0lhBBC4sXnn3+ODz74ANOmTYNGo0FxcTHOP/98WK1WrFmzBhdffLHSS1Q1uSIE1BSPEK9FM7HTdgCZtgzDwGq0osXVApvbpmiHtJLkiEdodbXGdeSEmuxv2I9OXyesRivGZY5TejlhC+mMcrlc8Hg84i+PFRUVePLJJ1FeXo6srCxJFxhPTHr+5XCHOYys2lGNABvaNtSI4zh4/PwgMoPWoPBqQrPjRCteLTsJALh1zjAq2BJCenj55Zfx/PPPY+fOnfj444/hcrmwdetWHDt2DPfccw8VbAkhhMStzs5O8ffM1NRUNDU1AQAmTpyI3bt3K7m0qCBHhADHcV0DnVTQaUuZtmfutAW6irvx2mnLcixq7DUApO20ZTkW7e72sLdHwidEI5QWlMZEET2kZ3D55ZfjtddeAwC0t7djxowZeOyxx3DFFVfg2WeflXSB8cSs5yMSXCEWbbMsWTBpTfCxPtR21kq5NEX5WT9Y8JER0RiPcLTBgT+tPwyOAxaOz8aiiTlKL4kQokKVlZU477zzAABz5syBXq/H6tWrkZCQoPDKCCGEEGWNHj0a5eXlAIDJkyfj73//O2pqarB27Vrk5uYqvDr1kyNCoMXVIl4NmZ+kXOSb2GnrbAHHcYqtQymDLdoK94vXom1jZyN8rA8aRoO8pLywt2fQGpBoSAQQvxEdaiMMISstiP5oBCDEou3u3bsxZ84cAMC//vUvZGdno6KiAq+99hqeeuopSRcYT4ynirahZtpqGA0Kk/h3i4SW/1jgCXjEj6NtEFmD3Y0H/nsQHj+LkqIU/HzecDAMo/SyCCEq5PF4YDJ1vTFlMBiQlkZd+YQQQsidd96Jujp+kO99992Hjz/+GEVFRXjqqafw8MMPK7w69ZMjQkDIBc1OyIZRp9zvaEIXsSfggdPnVGwdSrG5Bz6IDOgq2gqxCvFGOG9zE3Oh04SUFtpDvA/DUxuhaDurMPqHkAEhZto6nU4kJSUBADZs2IDFixdDo9Fg5syZqKiIvTzVSDGLRdvQow2KrcU42n4UFY4KzEJsnKTCEDKdRifZD9ZIcLh9uP/D79Du9GFoRgLuuWgMdNrob88nhMjnD3/4g5gN7/V68dBDDyE5uft/wh9//HEllkYIIYQo5rrrrhM/njp1KioqKnD48GEUFRUhIyNDwZVFBzk6bcVcUAWjEQAgQZ8Ag9YAb8CLFlcLEgzxc4VSgA2g09cJYBDxCMb4jkeQ47xNN6fjZPtJ6rRVgfqOepxoPwEGDGYUzFB6OZIIqQI2YsQIvP/++7jyyivxySefYPny5QCAxsZGWK0D+2FBehIybUONRwC6cm0r7ZWSrEkNonEIGctyeHT9YVS3uZCeaMCqS8fBYoiegjMhJPLmzp0rXvoJALNmzcL333/f7T7UqU8IISQeff/99xg2bJj4ucViwVlnnaXgiqKL0AkoZe6r0LGo9DArhmGQbk5HXUcdWpwtKEouUnQ9kRRceB1sPILQoRtv5Dhv5Rr0RwavrIrPs52YPXHA3xNqF1IVadWqVfjJT36C5cuX47zzzkNpKZ8VsWHDBpSUlEi6wHhi0vGdtp4wO20B4KT9pBRLUgUhHiGahpD970Ad9lbZYNRpcP+l45GRGF2xDoSQyNu0aZPSSyCEEEJUacSIESgoKMC8efNw7rnnYt68eRgxYoTSy4oaQlHJ5XfB5XPBrDeHvU2xY9GqbKctwD+/uo66uCuaCUVbo9Y44IgK6rSV/rwVO9kpHkFxsZZnC4SYafvDH/4QlZWV2LlzJz755BPx9vnz5+OJJ56QbHHxxmwIL9MWAIqS+HcWW92t6PB2SLIupQlF22jptK1td+GVr08CAG6aPQRDMuLnEh1CCCGEEEKkVlVVhTVr1sBsNuNPf/oTRo0ahYKCAlx77bV44YUXlF6e6iUZksSYOakKS2oq2sZrpuhgh5AF35eKttKdt+L5R/EIittaHVt5tkCIRVsAyMnJQUlJCWpra1FdXQ0AOPvsszFmzBjJFhdvTKcybcOJR7DoLcgyZwEAKh2xEZEgFG2VDLgfKJbl8ORnR+Dxs5hUkIxFE2iaLSGEEEIIIeHIz8/Htddei+eeew7l5eUoLy/HggUL8M477+C2225TenmqJ0QIANIVloTLzJXOtAXkyeyNBsIwsWTTwIaQBd833geRSZ1pC8TfmwZq4/F7sKt2FwAq2oJlWTzwwANITk5GcXExiouLkZKSggcffBAsG3qXaLwz6viXI5xBZEDXu0axkmvr8rkAAGZd+JfxyO2DvTU4VOeAWa/FnfNHQqOh/ElCCCGEEELC4XQ6sWHDBvzud7/DrFmzMGnSJOzduxfLli3DunXrlF5eVJA6d7PazjduqaHTNl6LZtRpO3hynLeUaasO39Z/C0/AgwxLBoanDld6OZIJKdP297//PV588UU88sgjmD17NgBgy5YtuP/+++F2u/HHP/5R0kXGCyniEQCgOKkYuxp2xUyurdPvBABYdBaFV9K/yhYn/lFWAQC4ec5QZFmjI86BEEIIIYQQNUtJSUFqaiquvfZa3HPPPZgzZw5SU1OVXlZUkTJCgOXYruKXGjpt47RoJgwTE3JqB0IcRBaHnbYBNoBaRy0A6rSNRUKe7azCWTE1vDmkou2rr76KF154AZdddpl426RJk5Cfn4//+7//o6JtiIRBZOHEIwBAkZXPtY2VTluxaKtXb9E2cCoWwRfgMLU4FReMy1Z6SYQQQgghhMSERYsWYcuWLXjrrbdQX1+P+vp6nHvuuRg1apTSS4saUkYINHY2wsf6wIBBbqLycXCUaTvwTtt4HkRW11GHABeATqNDdoJ0v69Tpq06lFWXAQBmFcRONAIQYjxCa2trr9m1Y8aMQWtra9iLildCp60nzKLtEOsQAECVowosF/1xFU4fX7RVczzCe7uqcbSxAwlGLZadNyKm3tkhhETW+vXrsWXLFvHzZ555BlOmTMFPfvITtLW1KbgyQgghRBnvv/8+mpubsX79epSWlmLDhg2YM2eOmHVLzkzKbkAhFzQ3KRd6rT7s7YWLMm1D6LR1x1+nrXDe5iXlQavRSrZdodM73t40UBOO48RO29LCUoVXI62QiraTJ0/G008/3eP2p59+GpMmTQp7UfHKpOdfjnA7bbMTsmHQGOBlvWjobJBiaYpSezzC/mob3tjBdzXfNnc4MhLVPzCNEKJev/nNb2C3890P+/fvx1133YVFixbhxIkTWLFihcKrI4QQQpQzceJEzJ49G6WlpZg+fToaGxvx9ttvK72sqCBlhECV/dQwJxXk2QLxWzQTO20Ng+i0NcVvp61c523wmwYcx0m6bTIwlbZK1DpqodPoMC1vmtLLkVRI8Qh/+tOfcPHFF+Ozzz5DaSlfxS4rK0NVVRX+97//SbrAeCLEI4Q7iEzDaFCYVIjjtuOocFSo4pKVcAidtmqMR6hpd+Hh/x0Cy3KYOyoD547OVHpJhJAod+LECYwbNw4A8N577+GSSy7Bww8/jN27d2PRokUKr44QQgiJvMcffxybNm3Cli1b4HA4MHnyZMydOxe33nor5syZo/TyooKUEQJCx6Ia8myBrqJZvGXa0iCywZHrvBXeNPAEPOj0dSLRkCjp9smZCdEIJTklqqwbhSOkTtt58+bhyJEjuPLKK9He3o729nYsXrwY3333Hf7xj39Ivca4YZJoEBnQlWtbYasIe1tKU2unLcty+NP6w+jw+DE6Jwl3zh9FsQiEkLAZDAY4nfzPvc8++wwXXHABACAtLU3swCWEEELiyT//+U+MGjUKr732Gpqbm7Fz5048/vjjuOyyy2gg2QBJGSEgDiFTW6ctxSOckZBp2+nrhJ/1y7IutZLrvE3QJ8CgNQCIv3NQLcRohILYikYAQuy0BYC8vLweA8f27t2LF198Ec8991zYC4tHZj1ftHV6w+u0BbpybSsc0V+0dfldANRXtN16vAXfN3XCbNDi94vGwqAL6T0QQgjp5pxzzsGKFSswe/Zs7NixQ7zs88iRIygoKFB4dYQQQkjkffPNN0ovIepJGSGgtngEoYvY4XXAG/CKBbRYF0qnbZIxSfzY4XEg1Rw/b3rIdd4yDIMMSwZqHbVocbWgOKVY0u2TMxOKtrMKY2sIGRBipy2Rh1C0DTceAejqtBV+MEUzNcYjsCyHN3fwBfErpuQjNSE+/mNACJHf008/DZ1Oh3/961949tlnkZ+fDwD4+OOPceGFFyq8OkIIIUQZX331Fa677jqUlpaipqYGAPCPf/yj2/BO0jcpO23F4pdK4hFSTCnQMHxpo9UVP4PRhWFiQvfsQBi0Bph0Jv7xnvgaRibneRuvw/DUoNPbiT31ewDEZtE25E5bIj2zQei0Df8yhaIkvmjb6GqE0+dUVcFzsIR4BLPOrPBKunxR3oiqVhcSjTpcPiVP6eUQQmJIUVER/vvf//a4/YknnlBgNYQQQojy3nvvPVx//fW49tpr8e2338Lj8QAAbDYbHn74YZqrMgBCN6okg8hOZYMWWNVxBZCG0SDVlIoWVwtanC3IScxRekkREUqnLcAXed1+d9zl2sp53ko56I8Mzs7anQhwARRYC1TzRpKUqNNWRYSirS/AwR8IL9c20ZCINFMaAKDSURn22pSktniEJocHz3/1PQBg8Vn5SDDSex+EEOns3r0b+/fvFz//4IMPcMUVV+B3v/sdvF6vgisjhBBClPHQQw9h7dq1eP7556HX68XbZ8+ejd27dyu4sughFJVsHltYWaYBNoBaRy0A9cQjAPFZNAsl0xboKvIKnbrxwBvwor6jHoA8563YaStB/AgZnFjOswUG2Wm7ePHifr/e3t4ezlrinhCPAAAuXwBJ2vBq6kOsQ9DqbkWFvQJj0saEuzxFcBwHl48v2pr1ynfasiyHxz8tR6cngJFZibiyJF/pJRFCYsxtt92Ge+65BxMnTsT333+Pa665BldeeSXeffddOJ1OPPnkk0ovkRBCCImo8vJyzJ07t8ftycnJ9DvoAKWaUsGAAQcOra5WZCVkhbSduo46BLgAdBqdqjpaMywZONJyJK6KZiF32p4q8sZTp22toxYcOBi0BmQmZEq+faGTneIRIm9rdezm2QKD7LRNTk7u909xcTFuuOEGudYa8/RaDfRaBgDgkmAYmZBrW2mP3k5bH+uDn+PfCVZDp+1/9tXiQI0dJr0Gv144GrowC+uEEHK6I0eOYMqUKQCAd999F3PnzsWbb76JV155Be+9956yiyOEEEIUkJOTg2PHjvW4fcuWLRg2bJgCK4o+Wo0WKaYUAOEVloRLzPOS8qDVaM9w78iJx0zRUIu2wv3jqWgbHI0g5B9LiTptlcFxHMqqygDEbtF2UJ22L7/8slzrIKeYDVr4XH64JBhGVpzETy2M5ngEIRqBASMGpiulwe7GP8r44WM3nzMUeSnKd/4SQmIPx3FgWT4i57PPPsMll1wCACgsLERzc/xc8kcIIYQIbrnlFtx555146aWXwDAMamtrUVZWhrvuugurVq1SenlRI92SjjZ3W1gRAtX2agDqikYAuuIR4qVo5g144fa7AQxuEBkQFI8QR4PI5D5v4zGeQw2Oth5Fi6sFJp0JU3KmKL0cWVAYp8qY9VrYXX44Jei0FX4gVdorwXKsLO8oyc3p44eQmXQmRdfPcRye3fQ9PH4WE/KtuGCcei4FIoTElmnTpuGhhx7CggULsHnzZjz77LMAgBMnTiA7O1vh1RFCCCGRd88994BlWcyfPx9OpxNz586F0WjEb37zG/zsZz9TenlRI8OSgWOtx8IqbFbZ+Y5FtQ38ETod46VoFtwlm2RMGtRjhSJvXHXaynzeUqetMoQ822l502DQGhRejTyir4oX4ywGvo4uRdE2LyEPeo0e7oAbjc7GsLenBKefL9oqHY1QdtKO3VVt0GsZ3PGDEdBoGEXXQwiJXU8++SR2796NZcuW4fe//z1GjBgBAPjXv/6FWbNi87IfQgghpD8Mw+D3v/89WltbceDAAWzbtg1NTU1ITk7G0KFDlV5e1JAiQkC8zDypQJI1SUXMFI2TopkwRCxBnwCdZnC9ePE4iEw4b+XqtKVMW2WI0QgFsfs7EnXaqowwjMwtQTyCVqNFQVIBTthOoNJeiZyE6OsOFTptzTrloghsLh/e3N0AgME104tQkKp8ti4hJHZNmjQJ+/fv73H7n//8Z2i16smOI4QQQuTm8Xhw//3349NPPxU7a6+44gq8/PLLuPLKK6HVarF8+XKllxk1pIgQUHunbbwUzULNswXiu9O2wCrPmw3xFs+hFsIQstLCUoVXIh/qtFUZs4H/hVyKTlugK9e2wlEhyfYiTey01StXKH3p65Po8AQwJC0Bi8/KV2wdhJD40d7ejhdeeAErV65Ea2srAODgwYNobIzOqyYIIYSQUKxatQrPPvsshgwZghMnTuCqq67CrbfeiieeeAKPPfYYTpw4gbvvvlvpZUYNKSIExKItZdoqSii4JpsGl2cLBA0i88Zf0Va2TNs4e9NADWxuG75r/A4AUFoQu0Vb6rRVGaFoK8UgMgAoshYB4HNto5HQaatUPEJVqxObypsAAMvOGw6dlt7nIITIa9++fZg/fz5SUlJw8uRJ3HLLLUhLS8O6detQWVmJ1157TeklEkIIIRHx7rvv4rXXXsNll12GAwcOYNKkSfD7/di7dy8YhuLKBkuKS7jFy8yp01ZRwhCxkDptTxV64zIeQa5M21NvGji8DngD3pjNV1WT7TXbwYHD8NThyE6M3bkfVIFSGcupeASX1y/J9oqS+KJthZ06bUPx7s4qcOBQUpCIUdmDC3gnhJBQrFixAkuXLsXRo0dhMpnE2xctWoQvv/xSwZURQgghkVVdXY2pU6cCACZMmACj0Yjly5dTwTZE4Q5L8ga8qO+oB6DeTtt4G0QWStFW7LSNk3gEt9+NJiffiCXXeZtiShEHp8fLGwdKE4aQzSqM3TxbgIq2qiN1PILQadvgbIDL75Jkm5EkrFmJTtvadhc2H+F/uF82ISPi+yeExKdvvvkGt912W4/b8/PzUV9fr8CKCCGEEGUEAgEYDF0dazqdDomJiQquKLqFGyFQ56gDBw4GrQGZCZlSLi1sQhdxm7sNLMcqvBr5CV2yQj7tYIiDyDzx0WlbY68BwM/JSTOnybIPDaMRtx0vER1KE4q2sRyNAFA8gupIHY+QbExGqjEVbZ42VDmqMCp1lCTbjRQxHkGBTts3tleA5YBpxakYmqbcIDRCSHwxGo2w23t2Phw5cgSZmer6BYkQQgiRE8dxuOmmm2A0GgEAbrcbP//5z5GQkNDtfuvWrVNieVEn3AiB4GFOQlehWggFM5Zj0e5ul604pxY0iGzggofnydmln25OR7OzmTptIyDABrC9ZjsA6rQlEWY+FY/glqjTFojuXFshHsGsi2zR9LtaG7480gyGAa6bURTRfRNC4ttll12GBx54AD6fDwDAMAwqKytx9913Y8mSJQqvjhBCCImcG2+8EVlZWUhOTkZycjKuu+465OXliZ8Lf8jAhBshIOSCFlgLJFuTVAxaA5IMfJxdPBTNhC7ZsDpt4yTTNlLnbbxFdCjpYNNB2D12JBoSMSFrgtLLkRV12qqM5VSnbaeERdtiazH2Nu2NylxbJeIRWJbD3zd/DwBYOD4HwzIT0djojNj+CSHx7bHHHsMPf/hDZGVlweVyYd68eaivr0dpaSn++Mc/Kr08QgghJGJefvllpZcQU4QIgVZXKziOG3TXodixqLI8W0G6JR0OrwPNzmaMTB+p9HJkFVanrSlOO21lPm/DzYwmA7e1mo9GmJE/A1qNVuHVyIuKtipjNvAviVTxCEDXMLJKRxR22ioQj/DWN1U40dwJi0GL62YUR2y/hBACAMnJyfj000/x9ddfY+/evejo6MBZZ52FBQsWKL00QgghhEQxoagU4AKweWxIMaUM6vFCx6Jai7YZlgycbD8ZF0UzoeAqFGAHQyj0egIeePweGHVGSdemNpE6b4U3ReKh01tpZdVlAGI/GgGIoXiETZs2gWGYXv988803fT7u3HPP7XH/n//85xFceXdyxCMUW/nCY4W9AhzHSbbdSIh0PMK271vwzx18cfvWucOQbNFHZL+EEHK62bNn4//+7//w29/+lgq2hBBCCAmbUWdEgp7PAw6lsBScDapG4Wb2RhMhHiGUTlshRgKIj27bSJ231GkbOduqtwGgom1UmTVrFurq6rr9+dnPfoahQ4di2rRp/T72lltu6fa4P/3pTxFadU9CPIJTwqJtbmIudIwOLr8LTa4mybYbCZGMR2h0uPH4hiMAgEsm5WL+2GzZ90kIIaf75S9/iaeeeqrH7U8//TR+9atfRX5BhBBCCIkZ4eRuVturAai301Z4bvFQNAsnHkGr0SLRkNhtO7EsUudtPJ1/Smp2NeNo61EAfDxCrIuZoq3BYEBOTo74Jz09HR988AGWLl16xqwei8XS7bFW6+B/8EnFdKrT1ilhPIJeo0d+Yj6A6BtGJnba6uXttOU4Dk9/fgwuXwBjcpJw8zlDZd0fIYT05b333sPs2bN73D5r1iz861//UmBFhBBCCIkV4iXcIRSWoqXTNh4GQQlDxEIZRAYEDSPzxP4wskh32sbD+aekXQ27AADjMsch1Zyq8GrkF7OZth9++CFaWlqwdOnSM973jTfewOuvv46cnBxceuml+MMf/gCLpe/OTo/HA4/HI35ut/PvTrEsC5Zlw1q3SceAAweX1x/2toIVJhWiwl6Bk7aTOCvrrF7vw7IsOI6TdL/hcvqcAAeYNWZZ1/XZoQbsrmyDQavBL+ePgIaBuD81Hhc1oOPSOzouvYu14yLn82hpael1ErbVakVzM/0nkBBCCCGhCzVCwOP3oLGzEQBQYC2QfF1SiKdM0XA6bQG+2FvrqI35Tlunz4lWVysAyrSNFTsbdgIAZhXEfjQCEMNF2xdffBELFy5EQUH//6D85Cc/QXFxMfLy8rBv3z7cfffdKC8vx7p16/p8zJo1a7B69eoetzc1NcHtdoe17k63H36fHw6fH/UNDdAMcqJnX1K4FPj8PpQ3lKMxubHX+7AsC5vNBo7joNEo34Qd4ALocHcAADraO8B0SnMsTuf2sXhu0zH4fQEsHp8FvdeBxkaH+HW1HRe1oOPSOzouvYu14+JwOM58pxCNGDEC69evx7Jly7rd/vHHH2PYsGGy7ZcQQgiJB8888wz+/Oc/o76+HpMnT8Zf//pXnH322b3e97vvvsOqVauwa9cuVFRU4Iknnug1qmgw21RaqJdwC5eYm3QmsfCrNvGUKSp0yIYyiAwI6rR1x3anrTCELNGQGHKBe6AoHiEyhKJtaWGpwiuJDNUXbe+55x48+uij/d7n0KFDGDNmjPh5dXU1PvnkE7zzzjtn3P6tt94qfjxx4kTk5uZi/vz5OH78OIYPH97rY1auXIkVK1aIn9vtdhQWFiIzMzPsaIVkXwA6/Qn+49QMmE9l3IZrLDcW/639L9q5dmRlZfV6H5ZlwTAMMjMzVVFUaXY1Q6/Tg2EYFOcWQ6eR53R965squFkGRRlJuH7uGGg13YvDajsuakHHpXd0XHoXa8fFZDLJtu0VK1Zg2bJlaGpqwnnnnQcA2LhxIx577DE8+eSTsu2XEEIIiXVvv/02VqxYgbVr12LGjBl48sknsXDhQpSXl/f6O5LT6cSwYcNw1VVXYfny5ZJsU2mhXsItXmJuLTxj/KBSjrcdBwD8+9C/MXntZNw37z4sHrt4wI9fd2gdVm9ejSPNRzAqY9SgHx8pHMeF32l7qtgby5226w6tw683/BoA4Av48O/D/5b19YynQXihCPf7a92hdbh/0/3Y37gfANDh7ZBrqaqi+qLtXXfdhZtuuqnf+5zeefTyyy8jPT0dl1122aD3N2MGH2R87NixPou2RqMRRqOxx+0ajSbsYoTJwEDLMGA5wOVnkWDSh7U9QYG1AGCAus46gAE0TO/rZBhGkuchhUpHJcDw0Q4GnUGWfdjdPrz/bS0YMLi+tBh6Xe9FcjUdFzWh49I7Oi69i6XjIudz+OlPfwqPx4M//vGPePDBBwEAQ4YMwbPPPosbbrhBtv0SQgghse7xxx/HLbfcIkborV27Fh999BFeeukl3HPPPT3uP336dEyfPh0Aev16KNtUWqiXcAsdi2rNs113aB2e2PYEAIAFi/0N+7HknSV47+r3BlQYWndoHZa8swQM+LjCwT4+ktx+N/ysH0DoRVvhcbFatA1+PQHAE/DI/noKnbatrlYE2AC0Gmka8GJBuN9fp7+eAHDn+jtRYC1Q3fen1FRftM3MzERmZuaA789xHF5++WXccMMN0OsHX/Dcs2cPACA3N3fQj5UCwzAwG7To9ATg8ko3jCzLkgW9Rg8f60OjsxE5CTmSbVsuJ+x8x/GQ5CGSb5vjOGw42IB3d1bB5QtgaEYCZg/PkHw/hBASittvvx233347mpqaYDabkZiYGJH9PvLII1i5ciXuvPNOsavX7XbjrrvuwltvvQWPx4OFCxfib3/7G7KzsyOyJkIIIUQKXq8Xu3btwsqVK8XbNBoNFixYgLKysohts6/5KJHK/k8zpQHgO20Hs79KGz/QuiCpQLZ1hjMDYfWm1WJBCID49w3/vgFPbX/qjI/fWbuz2+M4cGDAYPXm1bhi9BWDXk+4+jsWba42AAADBhadJaTjlWRIAgC0u9tVPXMi1HPi9PMBgOyvZ4oxBQB/7rQ6W8UirhSifT6I1N+fgPyvp9wG+lqqvmg7WJ9//jlOnDiBn/3sZz2+VlNTg/nz5+O1117D2WefjePHj+PNN9/EokWLkJ6ejn379mH58uWYO3cuJk2apMDqeWY9X7R1+6Qr2moYDfIS81Bhr0C1ozoqirYVtgoAwBDrEMm3XXa8BU9/fgwAkGLR444fjIBGo87LfAgh8eXEiRPw+/0YOXJktzctjx49Cr1ejyFDhsiy32+++QZ///vfe/z7t3z5cnz00Ud49913kZycjGXLlmHx4sX4+uuvZVkHIYQQIofm5mYEAoEebzpmZ2fj8OHDEdtmX/NRbDYbGhsbZb8iSefjSwD1tno0NvY+66Q3RxuOAgDSdGmDetxghDMDobylvFtBR9Dp68Tmis0hrYcDh/Lmctmeb3/6OxYn2vnmpkRDIpqbQhtSqw/wDW71bYM7DyIt1HOit/MhEq9nkiEJDq8DR6qPYHhK71duhyLa54PE2venFAY6IyXmirYvvvgiZs2a1S3jVuDz+VBeXg6n0wkAMBgM+Oyzz/Dkk0+is7MThYWFWLJkCe69995IL7sbi0EHwAunhJ22AJCfmI8KewVqO2sl3a5cKuynirYydNp+tL8OAHD+uGzcOncYTHq6dIEQog433XQTfvrTn2LkyJHdbt++fTteeOEFbNq0SfJ9dnR04Nprr8Xzzz+Phx56SLzdZrPhxRdfxJtvvinm67788ssYO3Ystm3bhpkzZ0q+FkIIISSW9TUfJTk5GVlZWbIXZIY6hgIAHAHHoDJ3m318cXB07mjZsnrDmYEwOn009jfu79GJV5RchEcX9D8jBwB++9lvUWWr6vH4MRljFMkm7u9YVPj535NTTCkhry0nlW/i8ml9qsxeFoR6TvR1Psj9emZYMuDwOgALJN1PtM8HibXvTykMdEZKzBVt33zzzT6/NmTIEHBc14tcWFiIzZtDq+rLSSgguiTstAX4oi0AVDuqJd2uHDq8HWh08e+YFCcVS7rtOpsL+6ptYBjgmumFVLAlhKjKt99+i9mzZ/e4febMmVi2bJks+7zjjjtw8cUXY8GCBd2Ktrt27YLP58OCBQvE28aMGYOioiKUlZVR0ZYQQkjUyMjIgFarRUNDQ7fbGxoakJMT2lWIoWyzr/kokcr+z0zgr+JpdjYPal/Vdv53yKLkIlnXGOpxuO/c+7plZgp/P7HwCVw59sozPl6v1Xd7PMB38t037z7FimR9HQthAJPVaA15bSmmFACAw+tQfREwlHNCOB/EbZx6XeV+PdMt6TjRfgKtrlbJ9xPN80H6ej1C/f6M1Ospp4GuO+aKtrHAbOBfPCkzbQE+fwgAajpqJN2uHCoc/LuHWeYsJBqkzXLc8B3/n6qzilKRZZVvAjwhhISCYZheL5ex2WwIBKT9dwEA3nrrLezevRvffPNNj6/V19fDYDAgJSWl2+3Z2dmor6/vdXtKZ/WpXbRnkkmFjgOPjgOPjkOXWDkWaly/wWDA1KlTsXHjRlxxxRUA+HVu3Lgx5DdF5dim3MRBZK5BDiKznxpEZlXnILLFYxfjvavfwwObH0B5SzlGp4/GffPuG1BB6PTH72vYBw4cVs1dNeDHR5IwPCzZlBzyNmJ9EJnwel717lVgORaj0kdhzfw1sr+e6WY+x3aw31+xbvHYxVg8ZjHWHV4HLaPFhKwJIX1/rt68GuXN5RidMRr3z7tfld+fUqOirQolGPiXRY54BIDvtOU4Dgyj3gzXk7aTAIBiq7Rdth5/AJ8d4ou2F4ynITqEEPWZO3cu1qxZg3/+85/QavkrAQKBANasWYNzzjlH0n1VVVXhzjvvxKeffjrgS3TOROmsPrWL9kwyqdBx4NFx4NFx6BIrx2KgWX2RtmLFCtx4442YNm0azj77bDEmb+nSpQCAG264Afn5+VizZg0AftDYwYMHxY9ramqwZ88eJCYmYsSIEQPaptoIRSW33w2nzwmL3nLGxzh9TrS6WgEAhcnqLNoCpwpDYUySFx5//b+vx+v7Xlft78s2jw1AV+E1FELB1+a2SbImNVowbAFYjn8DaeetOyVvBuuN+KaIk4q2p7MY+J81D533EO45555BP37x2MW4YvQVaGxsjEiUjFpQ0VaF5IpHyEnIgQYauANutLpbxX+w1eik/SQA6fNs/727Bu1OHzISDTh7SJqk2yaEECk8+uijmDt3LkaPHo05c+YAAL766ivY7XZ8/vnnku5r165daGxsxFlnnSXeFggE8OWXX+Lpp5/GJ598Aq/Xi/b29m7dtv1d9ql0Vp/aRXsmmVToOPDoOPDoOHSJlWMh1RuBUvvRj36EpqYmrFq1CvX19ZgyZQrWr18vDhKrrKzsdtxra2tRUlIifv6Xv/wFf/nLXzBv3jwxY/5M21SbREMi9Bo9fKwPLc4WWJLPXLStslWJj002ht7dGS1mFczC6/teR1l1mdJL6ZXQHRtO0TbWO22BrvM2xZQSkYItQJ22/RFeD7V266sVFW1VyGw4VbT1+iXdrl6jR05CDmo7a1HdUa3qou2xtmMAgCHWIZJts9Hhxru7+CympbOHQqeN3v8IE0Ji17hx47Bv3z48/fTT2Lt3L8xmM2644QYsW7YMaWnSvtk0f/587N+/v9ttS5cuxZgxY3D33XejsLAQer0eGzduxJIlfA5VeXk5KisrUVpa2us2lc7qiwZ0LHh0HHh0HHh0HLrEwrFQ89qXLVvWZ3TB6cM+T5+JEso21YZhGKRb0lHfUY9mZ/OAOmeFPNtCa6Fqu0+lNKtwFgBgW/U2BNgAtBp1zUARumPDKaALRVuhazcWBZ+3kZJuOVW0pU7bHsTXQ8Xd+mpERVsVspwq2kodjwAARdYi1HbW4qTtJCZnTpZ8+1JodDaitrMWGmgwLn2cZNt95euT8PpZTMi3Ys7IDMm2SwghUsvLy8PDDz8s+36SkpIwYcKEbrclJCQgPT1dvP3mm2/GihUrkJaWBqvVil/84hcoLS2lIWSEEEJIlMqwZKC+o37A3YBinm2cFFsmZE1AoiERdo8dB5sOYmL2RKWX1I0UnbZCwTemO20VOG+FxrhmV3PE9hkNOI5TpIgeC6hoq0JmvXxF2+Epw7GtbhuOtx+XfNtS+bbxWwDA6LTRA8pYGogDNTZ8dbQZGga4Zc6wuHiHmBASnb788st+vz537twIrYT3xBNPQKPRYMmSJfB4PFi4cCH+9re/RXQNhBBCCJGOeAn3ALsB4+2yZq1Gixn5M7DxxEaUVZeprmgrdMdK0mnrtql+3k2olDhvKdO2d03OJngCHjBgkG/NV3o5UYWKtiqUYBQGkUkbjwAAw5OHAwCO29RbtN3TuAcAMCVriiTbC7Ac/v7l9wCAhRNyMCwzMnk2hBASinPPPbfHbcH/kQ4EpH9DL9jpl4aaTCY888wzeOaZZ2TdLyGEEEIiQ7yEe5CdtgXWAtnWpDazCmdh44mN2Fq1FbdOvVXp5XQjSaftqUFkAS4Al98lWbOUmihx3g72eyteCAX07MRsGLQGhVcTXdQbNhTHhHiEThk6bYcmDwUDBs2uZlXm1/gCPhxoPgAAmJI5RZJtfnygDiebO5Fo1OG6mcWSbJMQQuTS1tbW7U9jYyPWr1+P6dOnY8OGDUovjxBCCCFRTryE2zmwS7jFy8zjpNMWAEoL+Oz+rVVbFV5JT0LRVii8hiJBnwANo+m2vVijxHk72C72eBGPP0OkQp22KiR22nqk77S16C3IS8xDTUcNvrd9j5KskjM/KIIOth6El/Ui1ZSKYmv4BdY6mwuvfH0SAHDdzGJYTfqwt0kIIXJKTu75H/Dzzz8fBoMBK1aswK5duxRYFSGEEEJiRcjxCHGSaQsAMwv47P6jrUfR1NmEzIRMhVfURWi+CqfTlmEYWI1WtLvbYXPbkJOYI9XyVEOJ81botG12Nsds7EQohNcinrr1pUKdtiokZ6ctAAxLHgYAONZ+TJbth+NQyyEAwOTMyWH/gGNZDk9+ehQeP4sJ+cm4aELs/UNECIkf2dnZKC8vV3oZhBBCCIlyYu7mYAeRxVGXXKo5FeMy+aHY26q3Kbya7qSIRwh+fCx22nIcp2inrY/1ocPbEbH9qh0NIQsdddqqUIJBvkxbABiRMgJf1XyF79u/l2X74XB4HQCADHNG2Nv6cG8tDtbZYdZr8asFI6HR0LtchBD127dvX7fPOY5DXV0dHnnkEUyZMkWZRRFCCCEkZgwmd9PusYtFvXjqtAX4iISDTQextWorLh19qdLLEdnc4Q8iA4KGkakwNjFc7e52OH1OAJHt7rToLTDpTHD73WhxtSDJmBSxfauZWECPs58hUqCirQpZjKc6bT0BWVrqh6XwnbbH24+rrmXf5XcBAMw6c1jbqWp14rWykwCAn54zFNlWU7hLI4SQiJgyZQoYhgHHcd1unzlzJl566SWFVkUIIYSQWDGYeAShQy7FlIJEQ3wNdJ5VOAsvfvsitlarK9dWqk5boegbi522QpEww5IBsz682sJgMAyDdHM6ahw1aHG2YEjKkIjtW83isVtfKlS0VSGh0zbAcvAGWBh1Wkm3P8Q6BBpoYPPa0OpuFf/RVgN3wA0AMGtD/8EaYDk88ekR+AIcphanYuH4bKmWRwghsguGg/sAAIkrSURBVDtx4kS3zzUaDTIzM2Ey0ZtPhBBCCAlfcO7mmcRzFuWswlkAgG9qvoEv4INeq/x8FJZjJRlEBgR12rpjr9NWyfM23cIXbQc66C8exGMutlSoaKtCZr0WDANwHODyBiQv2hq0BuQm5qKmowZVjip1FW39fNHWpAu9OPHermocbexAglGLZeeNUFUnMSGEnElxcfhDGAkhhBBC+jKYTNt47pAblT4KqaZUtLnbsLdhL6blTVN6Sej0doIDfzVW2J22ptjvtFXivBU72QeYGR3rAmwANY4aAPH5cyRcNIhMhTQaBia9vMPICpP4b5YqR5Us2w9VuEXb75s68OaOSgDAbXOHIyPRKNnaCCFETmVlZfjvf//b7bbXXnsNQ4cORVZWFm699VZ4PB6FVkcIIYSQWCEUleweO3wBX7/3FTvk4rDYomE0KC0sBQBsrVJHRIJQYNVpdGFHCloNsTuITMnzVnxTZADxI/GgobMBftYPDaNBblKu0suJOlS0VakEA1+0dXrkGUYmFG2rHdWybD9U4WTaun0BPPbpEQRYDqXD03Hu6Eypl0cIIbJ54IEH8N1334mf79+/HzfffDMWLFiAe+65B//5z3+wZs0aBVdICCGEkFiQYkoBA/5qxFZXa7/3jfcBQrMK+IiEsuoyhVfCE4aGWY3WsK8ojeVBZEqet9Rp251QQM9NzIVOQxf7DxYVbVXKYuRP5rjrtA2E1mnLcRz+9sUxVLY4kWLR4//OHU6xCISQqLJnzx7Mnz9f/Pytt97CjBkz8Pzzz2PFihV46qmn8M477yi4QkIIIYTEAq1Gi1RzKoAz59rGczwC0JVrq7ZO23CjEQCKR5CLkBlNnbY8YZhhvL7xEy4q2qqU3J22RUlFAPiiLcuxsuwjFGKn7SAHkX1R3ogvypugYYC7LxyDFItBjuURQohs2trakJ3dNThx8+bNuOiii8TPp0+fjqoqdb3RRgghhJDoNNBc23gvuEzPnw4No0GlrVI8FkoShoYlG8MbQgbEdqetkuet0Gnb7KJBZAC98RMuKtqqlMUgb6dtdkI29Bo9vKwXjc5GWfYxWBzHwePn8xoH02nr9Prx8tcnAQDXzijGhPzw/wEjhJBIy87OxokTJwAAXq8Xu3fvxsyZM8WvOxwO6PXKTy0mhBBCSPQTL+HupxuQ47i4zrQFgERDIiZnTwYAlFUpH5EgaaetMTY7bTmO6yraUqat4uL9Z0i4qGirUgnGU522Xnk6bTWMBgVJBQDUE5HgZb1gwXf9DqZo+69d1Wh3+pCXYsKVZ+XLtTxCCJHVokWLcM899+Crr77CypUrYbFYMGfOHPHr+/btw/DhwxVcISGEEEJihXgJdz+dtu3udnT6OgEA+db4/T1LiEhQQ66tUGAVog3CIRR+Y61o2+xsFgec5yXlRXz/A/neiifxnosdLiraqpTYaeuRp9MWUF+urfCDFQCMWuOAHtPocOP9b2sAAD+dPRR6LZ3ShJDo9OCDD0Kn02HevHl4/vnn8fzzz8Ng6Ip6eemll3DBBRcouEJCCCGExArxEu5+Mm2FYku6OR0WvSUi61Kj0oJSAOrItQ0eRBYuofArRC7ECuG8zU7IhlE3sLqClAbSxR5PKB4hPDS6TaXETFuZOm0B9RVthTxbk9YEDTOw4ut/9tbBF+AwId+Ks4emybk8QgiRVUZGBr788kvYbDYkJiZCq9V2+/q7776LxMREhVZHCCGEkFgykMKSeFlznHfICZ22u+t2w+13D3potpTETlsJM21jrdNW6fNW6LQ905C/eKH06xHtqC1RpSxG+TtthWFklfZK2fYxGOIQMt3AhpC5vAFs+K4eALD4rAIwDCPb2gghJFKSk5N7FGwBIC0trVvnLSGEEEJIqAYyiIw65HhDUoYgJzEHPtaHXbW7FF2L0BUrRadtrA4iU/q8Fd4Q6fR1ijN74pWf9aOuow4AUGAtUHg10YmKtiqVcCoeIRKdtnWddfAFfLLtZ6CEeISBvnO58XADnN4A8lJMmFqUKufSCCGEEEIIISRmDCR3U8lhTmrCMIxqIhLkGETm8DjAcmzY21MLpc/bZFMytAzfgBHvubZ1jjqwHAudRofshGyllxOVqGirUpZTg8g6ZSzappnSYNFZEOACqOusk20/A+UODLxoG2A5/GdvLQDg0sl50Gioy5YQQgghhBBCBmJA8Qg0QEgkRCRsrVa2aCt0xUoZj8CBQ4e3I+ztqYXS562G0SDNzEc3xnuurfBa5CflQ6vpeSUhOTMq2qqU2GkrYzwCwzCqyrV1+boybc/kw701qG13I9Gow/wx9I4NIYQQQgghhAzUQHI3hSxKuqy5q2hbVlUGjuMUW4eUnbYmnQl6jb7bdmOBmKGqYIf4QDrZ4wHl2YaPirYqZTHI32kLdEUkVDqUz7V1BQaWadtgd+ONbfx6l84eArOB3rEhhBBCCCGEkIGiTNvBOSv3LOg1ejR0NuBE+wnF1iEOIjOF32nLMExMDiMTzlsl32wQOtnjfRgZ/QwJHxVtVUoo2jq98nXaAl3fPGrotB1opu1zX34Pj5/FhHwrzh9HXbaEEEIIIYQQMhhCUanV1dprninHcV3ZoNQlB5POhKl5UwEom2srxCNI0WkLdBV/hQFn0Y7lWNTYawAoe96Kb4rEezyCCrqeox0VbVUqwcjHI3R65O20LUoqAtD1DoiShKJtf522h+rs2HGiFRoG+L9zR4BhKMuWEEIIIYQQQgZDuHyb5dheC3bNzmbx97P8pPyIrk2tZhV0RSQoRey0lSDTFkDMddo2dDTAx/qgYTTIS8pTbB1iZnScxyNUO/g3fihiJXRUtFUpodPWF+DgC8g3ybEgif/maXQ1wuV3ybafgRAHkfWTafvG9goAwHljslGYZonIugghhBBCCCEklhi0BiQaEgH0fgm30NSTnZANo84Y0bWplRqGkQkFdqk6bYXtCB280U44b3MTc6HT6BRbh5hpS522AKhbPxxUtFUpYRAZIO8wMqvBihRjCgCgpqNGtv30x8f64GN9YtG4r3iEAzU27K2yQathcM3Z9E1PCCGEEEIIIaHqrxuQohF6Ki0sBQDsa9gHh8cR8f0H2AA6fZ0AJIxHONWxGyudtmo5b8VMWxdl2gIUjxAOKtqqlEbDwKyP7DAyJXJtWY7Fbzb/Br/Z/Bs4fU4AvccjsCyHl77mA98vGJ+NbGv/ubeEEEIIIYQQQvrWX+4mZVH2lJeUh+LkYrAcix01OyK+/+DCquSdtjGSaauW85YybQFvwIuGjgYAyhfRoxkVbVXMYhSGkcVu0bbJ2YS6zjrUddahuoN/V6y3ou1Xx5pxtKEDZr0WP55eFOllEkIIIYQQQkhMES/h7qXTVuiQoyzK7oSIhLLqyOfaCkVbo9YoWWRFrHXaquW87e97K17U2GvAgYNRa0SmJVPp5UQtKtqqmBCR0CljPALQlWsrFE0jqd5ZL35c4+DjGU6PR/D4A3h160kAwJKp+UhNMERsfYQQQgghhBASi8RLuPvJtFW6Y1FtSgv4iIStVZHPtRWHkJmkGUIGxN4gMrWct2L0SBx32gYX0GmAfOioaKtiwjAyueMRChL5oq1QNI2khs4G8WM/xz/P0weRrT9QjyaHB+mJBlw+hSaXEkIIIYQQQki4+iss0QCh3gV32rKcfAPDeyMMC5MqGiF4WzEziEwl563QadvbGyLxQi2vRbSjoq2KJRgj02mbn8gXQlvdreIwsEhpcDb0uC04HsHjD+Bfu/gO4GumF8F0KueXEEIIIYQQQkjoxNzNfuIRlO5YVJtJ2ZNg0VvQ7m5HeXN5RPctdMNKWbQVunap01Zawhsi7e52BFh56zlqJQyFUzqqItpR0VbFEsWirbydtomGRKQaUwEADe6eRVQ51XfW97gtOB5h/YF6tDt9yEoyYv7YrEgujRBCCCGEEEJiVl+5myzHosbOX4VJXXLd6bV6TM+bDiDyEQnCsDAhh1YKsdRp62f9qHPUAVD+vE0zpwEAOHBoc7cpuhalqKWAHu2ipmj7xz/+EbNmzYLFYkFKSkqv96msrMTFF18Mi8WCrKws/OY3v4Hf33/Bs7W1Fddeey2sVitSUlJw8803o6OjQ4ZnMHiJJr5o65C5aAt05drWOetk31ew3jpthaKt29fVZXv19ELotVFzuhJCCCGEEEKIqvWVadvY2Qgf64OG0SA3MVeJpamaEJEQ6aKtLJ22MTSIrL6jHgEuAJ1Gh+yEbEXXotfqxWMbr7m2VLSVRtRUwbxeL6666ircfvvtvX49EAjg4osvhtfrxdatW/Hqq6/ilVdewapVq/rd7rXXXovvvvsOn376Kf773//iyy+/xK233irHUxi0hAh12gJdEQn1rp6dr3LhOA6NzsYetwuZtp98x3fZZluNOG8MddkSQgghhBBCiFTETtvTikpCFmVOYg70Wn3E16V2wbm2kUSDyPonnLf5SfnQapSPVeyrkz1eUKatNKKmaLt69WosX74cEydO7PXrGzZswMGDB/H6669jypQpuOiii/Dggw/imWeegdfr7fUxhw4dwvr16/HCCy9gxowZOOecc/DXv/4Vb731Fmpra+V8OgOSdKpo2+GOzU7bdk87PAEPNKedhmaduVuX7VXTqMuWEEIIIYQQQqQkDiI7rahEHXL9m1kwEwBwqPkQWl2tEduvOIjMIH2mrRC9EM2E81YtGap9dbLHC/o5Io2YqYSVlZVh4sSJyM7uaoNfuHAh7HY7vvvuuz4fk5KSgmnTpom3LViwABqNBtu3b5d9zWcidNp2RLDTts4VuaKtkGebYc5AmilNvN2kM3Xrsp1PXbaEEEIIIYQQIilxEJmzBRzHibdTh1z/MiwZGJU+CgCwrXpbxPZLnbb9U9t5G/z9FW9cPpdYrFbL6xGtdEovQCr19fXdCrYAxM/r63u/5L++vh5ZWd0LgjqdDmlpaX0+BgA8Hg88Ho/4ud3O/4BjWRYsy4a0/t4kGDTgwMHh9km63d7kJeSBA4dWTyucXicsBous+wOAuo46gAOyLFkIsAG0ulph0BrAsRw+3FMLDhx+OLUAGgayP//+sCwLjuMUXYMa0XHpHR2X3sXacYmV50EIIYSQ+CVcvu0JeOD0OZFgSABAHXIDMatwFo60HMHWqq1YNHJRRPYpdtpKmGkrbKvT1wk/64dOE70lIrWdt/Ecj1Dj4AcZWvQWpJpSFV5NdFP0O/Kee+7Bo48+2u99Dh06hDFjxkRoRQOzZs0arF69usftTU1NcLvdku3H63TC7/Ojxd6Jxsae2a9SM8EEm9+GA1UHMCRpiOz7O95wHD6/DwlcAgJcAD6/DybGhLJDlahp7YBJr8HYFC4iz70/LMvCZrOB4zhoNDHTnB42Oi69o+PSu1g7Lg6HQ+klEEIIIYSEJUGfAIPWAG/Ai2ZnMxVtB2FWwSy8sueViObayjGILHhbDo8DqeboLbCp7bwV40fisNNW6HousBaAYRiFVxPdFC3a3nXXXbjpppv6vc+wYcMGtK2cnBzs2LGj220NDQ3i1/p6zOkFQb/fj9bW1j4fAwArV67EihUrxM/tdjsKCwuRmZkJq1W6H6Cdmk7o9DXwQ9ujI1gOI9JHYE/DHtRxdTg762zZ9+escUKv02N41nD4Aj7sbNuJZEsyDraw0Ol1OGdUJgrz+n4dIoVlWTAMg8zMzJgoNkmFjkvv6Lj0LtaOi8lkUnoJhBBCCCFhYRgG6eZ01HXUocXVguKUYgBAtZ2fLUKXNfettLAUALC9envEOlSF3Nlko3TxCAatASadCW6/GzaPLaqLtmo7b+M501ZtBfRopmjRNjMzE5mZmZJsq7S0FH/84x/R2NgoFjg//fRTWK1WjBs3rs/HtLe3Y9euXZg6dSoA4PPPPwfLspgxY0af+zIajTAajT1u12g0khYjrGYDGDDo8ATAMIzs71CU5pViT8MebKndgitGXiH7/ppcTQAD5CTkwMf6AAYwa83YcrwFDBjMHZWlmuIOwzCSv76xgI5L7+i49C6WjkssPAdCCCGEkAxLBl+0DeoGFLNBqeDSp3GZ42A1WmH32LG/YT9Kcktk36ccnbYAXwR2+91Rn2urtvNWzLSNw3gEteULR7Oo+a2zsrISe/bsQWVlJQKBAPbs2YM9e/ago6MDAHDBBRdg3LhxuP7667F371588sknuPfee3HHHXeIBdYdO3ZgzJgxqKnh8zXGjh2LCy+8ELfccgt27NiBr7/+GsuWLcM111yDvLw8xZ6rIPHUILIAy8Hjlz8/cWbuTOg1elQ7qnHCfkL2/XX4+NcuyZCEKZlTMC59HEYlzUZbpxeJRh1KilJkXwMhhBBCCCGExKvTczcDbAC1jloA/KXNpHcaRoPSAr7bNlIRCXIMIgNiYxiZN+BFfQc/l0gt5208Z9pSp610oqZou2rVKpSUlOC+++5DR0cHSkpKUFJSgp07dwIAtFot/vvf/0Kr1aK0tBTXXXcdbrjhBjzwwAPiNpxOJ8rLy+Hz+cTb3njjDYwZMwbz58/HokWLcM455+C5556L+PPrjUmvgUbDd7t2ePyy7y9Bn4BJqZMAAF9VfyX7/pw+p7jfREMi7iu9D61N/BTO0uHp0Guj5vQkhBBCCCGEkKhz+iXcdR11CHAB6DQ65CQqH1WnZkLRdmvV1ojsT45BZEBXEViIX4hGtQ5+kLlBa0BmgjRXc4crrjNtqWgrmagZDfjKK6/glVde6fc+xcXF+N///tfn188991xwHNfttrS0NLz55ptSLFFyDMMgyaiDzeVDh9uPjMSekQxSm5E5A/ts+7ClZguuG3sdtBqtbPty+vmirUVnAQDUtruw5Sj/n4WLJ+XKtl9CCCGEEEIIIT0LS8JlzXlJebL+LhgLZhXOAhC5oq3YaSthpi0QG522wYOvNIw6mr+ETtt4zLRVW75wNFPH2Uz6lGDk/6GMRKctAIxNGQuD1gC7185nzsrEF/DxObbgO20B4F+7qsFywNTiVAzPTJRt34QQQgghhBBCeuZuUofcwM0omAEGDE60nxAvzZeLN+CF2+8GIH2nrbA9oZM3GqnxvBXfEHG19GgejHVqyxeOZlS0VblEox5A5Iq2WkaLLAs/yK2+U75/eIQuWwYMTDoT6m1ufH64EQDwo+n0jU0IIYQQQgghcjs9d5M65AbOarRiQtYEAEBZlby5tsFdsEnGJEm3LXTuRnOnrRrPW+F7y8/64fA6FF5N5HR6O9HmbgOgnnzhaEZFW5VLMvEJFh3uyBRtASA3gY8mkLVoeyrP1qQzgeMYPLahHAGWw+TCZIzNlfadQ0IIIYQQQgghPZ2eaUsdcoMTqYgEIW82QZ8AnUbalEux0zaKM23VeN5a9BaYdWYA8ZVrK3Q9JxmSJB+aF4+oaKtyQjxCpzdyRdtsSzYAoK6zTrZ9dPo6AfD/6Ly5vQKH6x0wG7T4xXkjZdsnIYQQQgghhJAuYqets3s8AnXIDYxQtC2rjkynrdTRCEBsdNqqMR4B6NnJHg/EArqKup6jGRVtVU6IR3BEsNM2J4GfEhqJeAS/X49/7eIvZVj2gxHItppk2ychhBBCCCGEkC7BuZuAeotfaiUUbXfW7oTH75FtP+IQMhk6F8VBZN7oL9qq7c2G0zvZ4wH9DJEWFW1VLjHCg8iAyBRtO32d4Djg+wY/WA74wehMzB2VKdv+CCGEEEIIIYR0Jw4iEzptqUtuUIanDkeGJQOegAff1n8r236EIWFydNrGVDyCys7b07+/4oGYL0xFW0lQ0VblEk9l2nZGsmhr4Yu2jc5G+Fl59uv0O9Hm9MLp1iLFosfP5g6TZT+EEEIIIYQQQnonXL7t8DrQ6e1EfQffuEMFl4FhGCYiubZip61R+k5boXs3WuMR3H43mpxNANR33lI8AgkXFW1VTol4hFRTKvQaPViwaHbJ08bf6XXC5vKBgRE3nzMUVpNelv0QQgghhBBCCOldiikFGoYvC+xv3A8OHAxaAzIT6CrIgZpVIH+urdAFK2unrSc6O22Fzk6zzow0c5rCq+lOjB+Jo05btUZVRCsq2qqcOIgsgp22GkYje0RCZXsbAiwHg8aMWcMzZNkHIYQQQgghhJC+aRgNUk2pAIA99XsA8MUWoZBLzqy0sBQA32nLcZws+6BBZH0TL8dPLgTDMAqvpjvKtCXhop/EKpd0qtM2kpm2QFdEglxF22NN/DtNhSkpMOjoNCSEEEIIIYQQJQi5m3vr9wKgYstgTcubBp1Gh1pHLSptlbLsQ854BHEQWZQWbcXL8VV43oqZthSPQEJE1TKVS1BgEBkA5CbmAgDqOutk2X5FWxsAYGRGuizbJ4QQQgghhBByZkLupjBIiy5rHhyL3oKSnBIA8kUkyDmITMi0jdZBZGq+HD/eMm1tbhscXgcAdRbRoxEVbVVOGETW4fHLdqlFb7It2QDk6bTt8PjR1Mm/izc2m6IRCCGExId164CSEgZDhmSjpITBunVKr4gQQgjpuoR7X8M+AFRsCUVpQVdEghzETluTfJ22noAHHr9H8u3LTc2dtvGWaSsU0FNNqUgwJCi8mthARVuVE+IR/AEOHj8bsf0WJPHvUh23HQfLSbdfT8CDbyvaEIAHBq0GudYUybZNCCGEqNW6dcCSJcD+/YDHw2D/fv5zKtwSQghRmtAN6PK7ANBlzaGYVcgPI5OraCtnp22SIUn8OBojEsQMVRWet8L3Vrxk2gbnCxNpUNFW5Ux6DbQaPkzb4Y5cRMKIlBGw6CxweB042nZUkm2etJ3ErRtuxfMHngfHuGExaGHRWyTZNiGEEKJmq1fzf3McI/7NMMADDyi4KEIIIQRd3YACNXYsqp1QtN1Tvwed3k7Jty9npq1Wo0WiIbHbfqKJmgdfiZ22cRKPoOau52hFRVuVYxgGyWa+29bm8kVsvzqNDlOypgAAdjXskmSb/z72b7j9bhy17QcLDxKMOiraEkIIiQvl5T1v47jebyeEEEIiSRiWJKAuucErTC5EflI+AlwAO2t3Sr59IW9Wjk7b4O0KHb3RRM2Dr4TvLafPCbffrfBq5KfmfOFoRUXbKNBVtPVGdL9Ts6cCkKZoW99Zjx11O+DyBeDl7GC0Tpj1Wlh0VLQlhBAS+7Kze97GMMDo0ZFfCyGEEBKMOm2lIWdEgtABK1fRVujgjbZO205vJ9rc/JBzNZ63VqMVOg0/pygecm3V3PUcrahoGwVSLJHvtAWAKZlToIEG1R3VaHQ2hrWtj77/CCxYdHr4iAezEQADJOgpnJoQQkjsS0zs/jnDcOA44L77lFkPIYQQIhByNwHApDMhzZym4Gqil1i0rZavaCvHIDKgqxgcbUVbIUM1yZAk27EJB8Mw4vdTPEQkqLnrOVpR0TYKCJ227c7IFm0TDYkYnca3AO1u2B3ydvysH5urNwMAXF7+XaZEoxYAKB6BEEJIzPvuO+DgQUCjAdLTOQBAUhI/hOzKKxVeHCGEkLgX3GlbaC0EwzAKriZ6CUXbsqoycBwn2XY5jpN1EFnwdoUYhmgRDZfjC99f8TCMjDptpUdF2yigRKatQIhI2NkQei5Pp68TnoAHHh8LjWc4GAAWgw46RgeDxiDRSgkhhBB1WruW//vyy4GPP+Z/ieM44JJLFFwUIYTEqWeeeQZDhgyByWTCjBkzsGPHjn7v/+6772LMmDEwmUyYOHEi/ve//3X7+k033QSGYbr9ufDCC+V8CpILzrSlDrnQTcmZApPOhBZXC462SjPMGwDcfjf8LH/FqhyDyICuDt5o67SNhs5O4fsr1uMROI4TO5/V/HpEGyraRgGlOm2BrqLtoZZDcPqcIW3D5XcBABwuBjo2HQlGHRgGMOvN9C4uIYSQmNbRAbz2Gv/xz38OlJQAqaksHA4G27cruzZCCIk3b7/9NlasWIH77rsPu3fvxuTJk7Fw4UI0NvYeBbd161b8+Mc/xs0334xvv/0WV1xxBa644gocOHCg2/0uvPBC1NXViX/++c9/RuLpSCY4HoE65EJn0BowLW8aAGlzbYUuWwYMEgzyxAtaDdE5iCwaOjuF769Yj0doc7eJNSM1dz5HGyraRoEUC9+NqkSnbV5iHnITcuHn/NjXvC+kbTj9Tnj97KmibRrSEvjnQ0PICCGExLp//hOw24Hhw4EFC/iIhHnzPACADRsUXhwhhMSZxx9/HLfccguWLl2KcePGYe3atbBYLHjppZd6vf//+3//DxdeeCF+85vfYOzYsXjwwQdx1lln4emnn+52P6PRiJycHPFPampqJJ6OZL6s+FL8+OOjH2PdoXUKria6ZZj5rsqfffgzTF47WZJjKXS/JhmToGHkKeFI3Wm77tA6TF47GeaHzJIdh96InbYqLto6PA4AwC8+/oWsx6I/kXg9hNci05IJk84k+fbjFRVto4DQaWtXoGgLACVZJQCAXQ27Qnq8y+9Ca6cXDGfC2YXDYdDxpx0NISOEEBLLOA549ln+45//nC/YAsC8eV4AVLQlhJBI8nq92LVrFxYsWCDeptFosGDBApSVlfX6mLKysm73B4CFCxf2uP+mTZuQlZWF0aNH4/bbb0dLS/R01K07tA4/+tePxM+bnE1Y8s4SKtyGYN2hdXi//H0AQIALYH/DfkmOpTiETKZoBEDaQWTrDq3DkneWYH/DfrgDbsmOQ2+qHeq+HH/doXXYeGIjAH7Wj5zHor81ROL1iIZ84WikU3oB5MxSLKfiERQq2k7Lnob/nfgfvm38FizHDvrdvcq2dnR4/NBzBiw9ewr+8A0DDhx12hJCCIlp33wDfPstYDQCS5d23T53rkf8emsrkEZDugkhRHbNzc0IBALIzs7udnt2djYOHz7c62Pq6+t7vX99fb34+YUXXojFixdj6NChOH78OH73u9/hoosuQllZGbRabY9tejweeDwe8XO7nS+ScRwHlmVDfn6hWr1pNRjwv58BAAcODBis3rwaV4y+IqJrYVlWseMgBSmPZfCxaHO1AeALq3IdGyEeod3dHvY+5DoOvRG6O/OT8lV53qzetLrb56Eei3C+NyL1PV7RXgGAL9rK9VpE+8+IYAN9DlS0jQJdmbZecBwX8RzY0WmjYdFZ4PA6cLj1MMaljxvU4zcf5d/9ykmyYmR2KjLMGWhyNVGnLSGEkJgmdNlefTWQ3hUXiLw8FuPGcTh4kMHnnwM//KEy6yOEEBK+a665Rvx44sSJmDRpEoYPH45NmzZh/vz5Pe6/Zs0arF69usftNpsNjY2N0GgiezFseUu5WMwRcOBQ3lzeZ9avXFiWhc1mA8dxET8OUpDyWAYfi6pGvjBp0Vjke034i4DQbG8Oex9yHYfezolKWyUAwOwzR/x8HYjylvIet4VyLML53ojU93h5Hf9cM/QZsr0W0f4zIpjD4RjQ/ahoGwWEoq0vwMHtY2E29HzHVk46jQ4zcmfgi6ov8L/v/zeooq3D7cPuqgZAB4zN5vN9chJy0ORqgllvlmvJhBBCiKJaW4G33uI/vv32nl8//3zg4EE+IoGKtoQQIr+MjAxotVo0NDR0u72hoQE5OTm9PiYnJ2dQ9weAYcOGISMjA8eOHeu1aLty5UqsWLFC/Nxut6OwsBDJycnIysqKeCFidPpo7G/c362ow4DBmIwxyMrKiuhaWJYFwzDIzMyMyoKMlMcy+Fjg1CmYlpgm22uS35wPAHDDHfY+5DoOp58Tdo8dDi9f+JoydAoSDYlhrVsOUh2LcL43RqePxr7G7vOJ5PgebwvwHeGjskfJdp5G+8+IYCbTwHJ/o/tZxgmTXgvjqRzYdpdXkTVcMuwSAMDOhp2o6agZ8OM++a4BXtYNg06DotQUAPxwMwBI1KvvhyohhBAihVdfBdxuYPJkYObMnl8//3z+P+8bNvDZt4QQQuRlMBgwdepUbNy4UbyNZVls3LgRpaWlvT6mtLS02/0B4NNPP+3z/gBQXV2NlpYW5Obm9vp1o9EIq9Xa7Q8AMAwDjUYT8T/3nXufeLk0APEy6vvm3afIepQ6DnIcSwBhHUvhWHR4OwAAKaYU2daeauaH59k9dsmOQzApjsPpf2ocNeJxsZqsir/+AzkW4Xx/hfq9sWreqm6vhVzf40K+cFFKkazHNJp/Rpz+ZyCoaBslhFxbm0K5tgVJBZiWPQ0cOHx4/MMBPcbtC+CDPTXg4EGK2QCLns+wvXDIhZiTPwfnFZ0n55IJIYQQRXAcsHYt//HttwO9pRrNnQsYDEBFBXD0aGTXRwgh8WrFihV4/vnn8eqrr+LQoUO4/fbb0dnZiaWngsdvuOEGrFy5Urz/nXfeifXr1+Oxxx7D4cOHcf/992Pnzp1YtmwZAKCjowO/+c1vsG3bNpw8eRIbN27E5ZdfjhEjRmDhwoWKPMfBWjx2Md67+j1Myp4Ek86ESdmTsO7qdbhy7JVKLy3qCMdyZPpIAICG0eBfV/0r7GNpc9sAdA0Lk4OwbZvHFva2Fo9djEUjFnW77eHzHpb8nBIGXxVa1TmEDOg6J1JNfFE8KyEr4t9fE7Mndvs82ZQsyxqEfGE1vx7RiOIRooTVrEeD3QObU5miLQBcPuJy7GzYiS3VW3DT+Jtg1vUfb/DxgTq0O31IsAaQaNKJ989LzMOykmWRWDIhhBAScZ9/Dhw5AiQlAdde2/t9EhKAc87h77thAzBqVGTXSAgh8ehHP/oRmpqasGrVKtTX12PKlClYv369OGyssrKyW/fTrFmz8Oabb+Lee+/F7373O4wcORLvv/8+JkyYAADQarXYt28fXn31VbS3tyMvLw8XXHABHnzwQRiNRkWeYygWj12MxWMXK72MmLB47GJcPvpypDyagg5vB0alh/8PvN3DD6uTs2ibbEzutq9wNTr5TFOL3gKnzwm9Vi/JdoOJRcJkdRcJF49djKbOJvz8o59jQtaEiL8hsrVqK4Cu1yLZmCz5GjiOQ7Wd77RV++sRbajTNkqkmA0AgHaFOm0BYFTqKKSZ0uDn/KiwV/R7X5c3gPd28ZcrjMk1gWEgdtoSQgghsUwYQHb99UBiP0lAF1zA/71hg/xrIoQQwlu2bBkqKirg8Xiwfft2zJgxQ/zapk2b8Morr3S7/1VXXYXy8nJ4PB4cOHAAixZ1dRCazWZ88sknaGxshNfrxcmTJ/Hcc8+JRWASn7QaLWbk8+eVUDALh1BIFQqrchAKwnaPHVyYuU2d3k58W/ctAOCnU34KQJrjcDqxSBgFnZ2zCmcBALbXbEeADUR038Kxv2HSDdAwGlTYKlBjH3jk5UA0OZvgCXjAgEFeUp6k2453VLSNEsIwMiU7bQFgaPJQAMBJ28l+77fhYD1sLh9ykk3ISuavCz1TZy4hhJDIWrNmDaZPn46kpCRkZWXhiiuuQHl59ym3brcbd9xxB9LT05GYmIglS5b0GMpCutTWAu+/z3/c2wCyYELR9osvAK8ykfWEEEIIkYFQpNtaHX6xUogskLXT1sQXhP2sHy6/K6xt7azdiQAXQH5SPn404UcA+MJhuMXg00VDPIJgXOY4WI1WdHg7cKDxQET3XVZdBgBYOGIhJmVP6nabVISu5+zEbBi0Bkm3He+oaBslks18koVSmbYCoWh7wnai3/vtq+b/YbloQg7cAf6HPhVtCSFEXTZv3ow77rgD27Ztw6effgqfz4cLLrgAnZ2d4n2WL1+O//znP3j33XexefNm1NbWYvFiuoSyLy+8AAQCfPTBqatn+zR5MpCZCXR0ANu2RWZ9hBBCCJFfaQE/rK6sKvzimNhpa5Kv0zZBnyAOUAs3IkEoCJYWlmJa3jToNXo0dDbgZPvJcJfZjVC0LbAWSLpdOWg1Wsws4CfTytF13Jd2dzu+a/wOAH9OSnleBoumAnq0oaJtlEixCPEIyrbiDLWeuWjLcRyONDgAAGNyrHD6nQAAi47iEQghRE3Wr1+Pm266CePHj8fkyZPxyiuvoLKyErt27QIA2Gw2vPjii3j88cdx3nnnYerUqXj55ZexdetWbItglXHdOr7AaTbzf69bF7FdD4rfDzz/PP/xz39+5vtrNMD55/MfU0TCwEXL+RAN6FgSQog8hALd0dajaOpsCmtbkei0ZRimaxiZO7xhZEJRclbBLJh0JpyVe1a326USLZm2AqFgKkX39UBtr94ODhyGpQ5DdmK2pB3gwSjPVj5UtI0SYjyCwp22Q5KHAACqO6rhC/S+luYOL9qdPmgYYFhmAlw+6rQlhJBoYLPx/0lPS0sDAOzatQs+nw8LFiwQ7zNmzBgUFRWhrEzad+j7sm4dsGQJsH8/4Hbzfy9Zos7i0kcfAdXVQEYG8MMfDuwxVLQdnGg6H9SOjiUhhMgn1ZyKcZnjAIR/KXokMm2Brk7ecDptOY4Tn69QIBQLhRIWbTmOi7ruTuE4SN3l2h+xgH7aa7Grdhfcfrdk+xEL6FHyWkQTndILIAOTbOGLtu0KZ9qmm9KRZEiCw+tApaMSw1OG97jP0QYHOPiRltYMrYYVM3FoEBkhhKgXy7L41a9+hdmzZ4tTsevr62EwGJCSktLtvtnZ2aivr+91Ox6PBx6PR/zcbuf/489xHFiWHfS6Vq9mwDAAxzGntgMwDIfVq4ErrpA2Gy1cf/sbA4DB0qUc9HoOvT1dlmW7HYv58wFAg507OTQ3czhVL495px+HgYqm82EgQj0OUlDTsVTyOKhNrByLaF8/IVIoLSjFwaaDKKsqw2WjLwt5O0Lnq5ydtsHbFzp7Q3Gs9Rianc0wao0oyS0BwB+HJ/CEpDmqbe42OH38Fb3REI8AADPyZ4ABg+Ntx9HQ0YDsRPkHFopRFae6fIemDEVWQhYaOxuxu263WMQNV7QV0KMJFW2jROqpeIQ2p7LxCAzDYKh1KPY178NJ28lei7blDQ506HfAyWzFf7/XdhVtKR6BEEJU64477sCBAwewZcuWsLazZs0arF69usftNpsNjY2N0GgGd5FPeXm2WFQScByD8nIOjY2N/7+9+46Pqsr7B/65k0kmjTRIT+i9J5QQdK0Iuj4qxbqsIroorthw3UdWhR+uLqy762N5FMUCrqKgEsv6uKyIYoHQCQKBANJCKiGk98z5/XG8U8IkmV4/79drXjOZOXPvmTM3c5LvfO/3ONRXZzp5MghffRUPRRGYNasC5eWWVwbW6/Worq6GEAIajQbBwcCQIT1RUBCMTz6pwnXXNVt8nr/pOA7W8pXjwVr2joMzeNNYenIcvI2/jEVtba2nu0DkcZPTJ+OtvW85fCq6mvnq6qCtmsnrSKatmtk5PmW8YUGq7HQZMNxXtg91LXWIDIl0sKfG0/F7hfdCWLBvnNEbHRqNEQkjcKD8AHLP5GL60Oku3V+7vh3bzshyZmpwVlEUTE6fjE8Pf4qthVudHrT1lQC6L2HQ1kfERcgPvJrGNrS06RGi9dwfcX2j++Knip9wosZyXdsjZXVoCTqNaG0QjlUdQ5toA8DyCERE3mrBggX44osv8P333yMtzfjHVlJSElpaWlBVVWWWbVtWVoakpCSL21q0aBEWLlxo+Lmmpgbp6emIjo5GQkKCzUGIIUOA/fuFWXBJUQSGDgUSEhJs2pYr/eMfsn9TpwITJvTstJ1er4eiKIiPjzeMxTXXKCgoALZvj8Hdd/tetqg9LI2DNXzleLCWvePgDEOGAD/9JAB4fiw9OQ7exl/GIjQ01NNdIPI4NSC2s2gnWttbERwUbPM2hBBuWYgMMAaFnRG0NQ0GpkWloXd0b5yuPo0dRTtwRb8rHOsofPd0/Mlpk3Gg/AC2Fm51edD24NmDqG2pRWRIJEYmGFfHnZxmDNo6i6/VF/YlDNr6iKhQLbRBCtraBaoaWpAQ5bk/hPpFy8XIjlcdv+AxvV7gWHktWoNLERqswena04bHQrX8442IyJsIIfDAAw/gk08+webNm9GvXz+zx8eNG4fg4GBs2rQJs2bNAgAUFBTg9OnTyM7OtrhNnU4HnU53wf2KokCj0dgchFiyRNbZNO+3giVLAI1GsfwkN2tqAlatkrd//3ul2351HItp04AXXgA2blSgKPKU9UBgzzHhC8eDrez93XDU448Dv/mN+X2eHEtPjYM38oex8OW+EznL4J6DERcWh8rGSuwr24fxKeNt3kZdSx0E5Be6biuP4MBCZB1Px1dlp2XjdPVp5BbmOido66OZnZPTJ2PlnpVOLRXRGbV27sTUidBqjKE/NfM590wuhBBQHPzDs13fjqLaIgC+F0T3BZxNfYSiKOj5S7btuXrPlkgYEC1LIpyqPYVWvbHGbu7P57B8w2HUtVUCmiaEBGlQ3iBPrwsNCoVG4eFGRORN7r//frz33nt4//330aNHD5SWlqK0tBSNjbKsTXR0NO6++24sXLgQ3377LXbv3o25c+ciOzsbkyZNcksfZ84E1q8HBvxSjScoCPj4Y2DGDLfs3ioffwycOwekpwPXXmv78y+5BAgJAU6fBo4ccX7//MnMmcC8eeb3/fWv3nU8+Aq19HRwMAxfFPzhDxxLIiJn0SgaTEqTfy/Zm9WoZr1qNVqXn7nqaHmE6qZqHCg/AMAYGFQZFiNzsFSEylczbdVx2Vm0Ey3tro3rqGM9Oc28BMK45HEI1gSjtK4UJ6tOOryf8vpytOnboFE0SO6R7PD2yJzPRNGeffZZTJ48GeHh4RcsiAIA+/btw2233Yb09HSEhYVh2LBhePHFF7vdbt++fX/JajFeli9f7oJX4DhDXVsPB20TwhPQI7gH2vRtOF0jM2nrmtuwfMNh5P58Dq2aUoSHBJmebcdFyIiIvNCKFStQXV2Nyy67DMnJyYbLunXrDG3+53/+B//1X/+FWbNm4ZJLLkFSUhJy3Ly8/MyZQH4+EBkJtLcD/fu7dffdWrFCXt9zjwwq2yo8HPjVr+Ttr75yXr/8VVub+c8REZ7ph69Tj9unnwYeekjerrY/uYqIiCxQA2b2Bm3VRcGidFEOZ0R2x9GFyLYXbYeAQP/Y/kiKNC+jpQZtcwtzoReOL1RoWPjKx07HHxQ3CD3DeqK5vRl7S/a6dF+WSlUAQFhwGDKTM83aOEJ9L1J6pJhl9JJz+EzQtqWlBTfddBPuu+8+i4/v3r0bCQkJeO+993Dw4EE88cQTWLRoEf73f/+3220//fTTKCkpMVweeOABZ3ffKeIivSPTVlEUwwJkx6qOAQAKSmug1wv0jAzB1LFAYofyDVyEjIjI+wghLF7uvPNOQ5vQ0FC88sorqKysRH19PXJycjqtZ+tKISHA5ZfL294U2PzpJ2DrVkCrBX73O/u3M3WqvPam1+atdu2S12PGmP9M1tuzB9ixQ2bZ3nWX+fEnAqOsMhGRWxgyTB3MtFWzYF1JrZlrb6at+ho7lkYAgDGJYxCmDcP5pvM4cs7x04oMQVsfy7RVFwID4NISCWfrz+JYpYzVqNneptT3yBl98NWsZ1/hM0HbpUuX4pFHHsGoUaMsPn7XXXfhxRdfxKWXXor+/fvjt7/9LebOnWtVNlCPHj2QlJRkuER4acqGWh6h0sNBWwCGoO3PVT8DAA6XyhViR6dGo0VTekE9Pi5CRkREjvLGwKaarThjBuBILFt9bd9+C7R4fpr3WvX1wMGD8vbvfy+vd+70XH98lXrczpoFJCQYS3ScOgUcPerZvhER+ZMJqROgUTQorCnEmZozNj9fDaC6up6t6T7sDdqqAcCOmZ0AEBwUjAmpEwA4KbvThxe+UgOmzlwIrCP1vRjWaxhiw2IveNzRLxNM+WrWs6/w69zl6upqxMXFddtu+fLl+POf/4zevXvjN7/5DR555BFotZ0PTXNzM5rVQmCQK2MDcrVXvd7xVP/OxIYHQ0Cgoq7ZJfvR6/UQQli17f7R/QEBHDt/DHq9HvnFNRAQGJwYifUlPwMCiA2Nxfmm8wBk0NaVY+NKtoxLIOG4WMZxsczfxsVfXoevUQObP/4og3ee/o61thZ47z15u5MTgaw2erQMnpWXA7m5wKWXOt4/f5SXB+j1QEoKcN11wL33AocOAXV1snwGda+6Gnj/fXlbPW4jIoCLLwa++UZ+KTJ4sOf6R0TkTyJDIjEmcQz2lu5FbmEubhpxk03PNy2P4GpqNq895RHa9e3YdmYbAMtBW0CWivj+1PfYWrgVd2XcZXc/hRCGALgvZnc6M2Damc5KI6jU2rr7yvahrqUOkSH2/xGlBtDTevjWonC+wm+Dtlu3bsW6devwf//3f122e/DBB5GZmYm4uDhs3boVixYtQklJCZ5//vlOn7Ns2TIsXbr0gvvPnj2LpqYmh/vemaDWRrS1tqGoohrl5eVO375er0d1dTWEEN2u+BrVEoXWtlacqjqFk0UncfBMJdpa9QgSRahurEawJhgDwgYgt05+wyNahEv67A62jEsg4bhYxnGxzN/Gpba21tNdCEiDBgF9+shswO+/B665xrP9WbNGBguHDAEuu8yxbWk0wFVXyW1+9RWDtp1Rs2rHjweSk4HUVKCoCNi711gXmLr27rtAQwMwYoT5mE2dagzaLljguf4REfmbyemTsbd0L7YWbrU5aGsojxDq+vIIjmTa5p/NR01zDSKCIzAyYaTFNs4KVlY0VKC5XSbRpUalOrQtT5iQOgFBShCKaotQWF3okgzVrrKeASAtKg3pUekorCnEjqIduKLfFXbvi5m2ruXRoO3jjz+Ov/71r122OXToEIYOHWrTdg8cOIAbbrgBS5YswVQ1LacTCxcuNNwePXo0QkJCcO+992LZsmXQ6XQWn7No0SKz59XU1CA9PR3x8fGIinLdN2D9mkOgDS5Hkz4ICQkJTt++Xq+HoiiIj4/vNqiSgASkHE3B2YazONJUgTZo0CM8GEfachGsDcbQuKEYED8Au87LQnM9o3q6pM/uYMu4BBKOi2UcF8v8bVxCQ0O7b0ROpygysPTGGzKw5MmgrRDGU8znz8cFZYHsMXWqMWj77LOOb88fqfVrx483XhcVyfsZtO1eV8ft1KnA448bS3SEhHimj0RE/iY7LRuv7HzFrvqhniiPUN1ke6at+tqy0rI6XYxKra16qOIQzjeet3javjXUIGFiRCJCgnxvsgoPDkdGcgZ2Fe/C1sKtuCX6Fqduv7W9FTuKdgCwXF9YNTl9MtYdXIfcwlyHgra+nPXsCzwatH300UfNFjuxpL+NS0Tn5+fjyiuvxD333IMnn3zS5j5lZWWhra0NJ0+exJAhQyy20el0FgO6Go3GpcGIXj1CoUBBZUOLy/ajKIrVr2NAzACcbTyLr0/8AGAiYnudxNbSrdAoGvx2+G9R1lAG/PLPQERwhE8HamwZl0DCcbGM42KZP42LP7wGX2UatPWk3Fy5CFlYGDBnjnO2edVV8nr3bqCiAujVyznb9Sdq0HbCBOP1Z5+xrq21fvgByM8HwsOB2283f2zMGCA+Hjh7Fti2Tda5JSIix6nZjntK9qCxtRFhwdav9+IrC5EZTsdPs5zZCQDxEfEYFDcIRyuPYtuZbbhmkH3fvvtyPVtVdlq2MWg70rlB27zSPDS1NSE2NBZDelmOaQHGoO3WM45lPjPT1rU8+l9nfHw8hg4d2uUlxIav+Q8ePIjLL78cc+bMwbN2pqjk5eVBo9F4ZVZo3C8LkdU3t6Optd3DvQGykrMAALsqvsfZsLdwsv1jAMD0gdMxKHYQ4sPiDW1tmZiIiIg6c8UVspRAfj5wxvb1PJxGzVa89VYg1r5EkQskJwMjR8psyE2bnLNNf1JdDRQUyNummbaAMZhLXVOP29mzgegO//+rJToAz38pQkTkT/rG9EVSZBJa9a3YXbLbpue6s6atIdPWjpq2atBWrZXaGWeUSDAECX04s9MwDg4GTC1Rs56z07OhUToP+alZuLmFudAL+9braNO3obi2GIBvvx/ezGdShU6fPo28vDycPn0a7e3tyMvLQ15eHurq6gDIkgiXX345pk6dioULF6K0tBSlpaU4e/asYRs7duzA0KFDUVRUBADIzc3FCy+8gH379uH48eNYs2YNHnnkEfz2t79FrLP+A3Oi8JAg6LTyLTvf4PmlpSenTMYtA+eirkmPNs1ZhAZrMC5xHGYOngkA6BVmTBEK14Z7qptERORH4uKMWZYbN3qmDxUVwIcfytuOLkDWkVrViUGzC+3ZI6/79jVmIatB26NHgaoqT/TKd5SVAevXy9udHbc8/oiInE9RFLMAmS3cmmn7yz5qm2ttCuJVNFTgaOVRAMYSCJ0xjIMdpSJUhkxbHw4SqkHbvNI8NLQ2OHXbhgB6F6URAGBs0liEacNwvuk8jpw7Yte+SmpLoBd6BGuCkRiZaNc2qGs+E7RdvHgxMjIysGTJEtTV1SEjIwMZGRnY9Utqxccff4yzZ8/ivffeQ3JysuEyQf3PDkBDQwMKCgrQ2toKQJY5WLt2LS699FKMGDECzz77LB555BGsXLnSI6+xO4qiGLJtz9V5PmgLAAXH+6Bn42wMjZiGV696AX+c8EcEa4IBALGhsdAqsgJHmJaZtkRE5ByezgZctUrW/Bw3zhhAdhY1aLZxo8y4JSPTRchUPXsC/frJ27ttS14KOG+/DbS2AllZQEaG5Tbq79auXUBlpfv6RkTk7+zNrPRETVsBgfqWequfpwaih/UahriwuC7bquOwvWg72vRtdvXTH07HT49KR0qPFLTp27Cr2LmnCxlKVXSyCJkqOCgYE1InmD3HVup7kRqV2mVWL9nPZ0Z19erVEEJccLnsl+Wa/9//+38WHz958qRhG5dddhmEEOjbty8AIDMzE9u2bUNVVRUaGxuRn5+PRYsWdboAmTfoGSmDtpX1ng/a5hVWYevP5xAq0vDslXcjrUea2eMaRWP40A4PZqYtERE5h2lgU2/f2Vx20+uB11+Xt52dZQvIxbR0OqCw0FgKgKSO9WxV6s8skdC59nbrjtuUFGDECJboICJyNtOyAMKGb2XdWR4hVBtqSMCypUSCtUFCABgePxxRuijUtdThQPkBu/rpDwtfKYrilFIRHZ2pOYPCmkJoFA0mpk7str1ag9juoO0vWc9pUWndtCR7+UzQlqTYcO8J2v7nYCkA4OqRyejbK8Jim3EJ4xAaFIr+0bYtKEdERNSZSZOAyEjg3Dlg71737nvjRuDnn2U90Ftvdf72w8Nl4BbgKeodWcq0Nf2Zi5F1bsMG4NQpWX/55pu7bssSCUREzpeZnIlgTTDK68txouqE1c+rba4FYFwkzJUURTEEh21ZjMxQQ7Wb0/EBIEgTZCihYGupCJWa3enrgUI1YOpIqYiO1DEdkzgGkSGR3bZXaxDb2wd/CKB7OwZtfYxaHqGirtmj/Whp02P3yfMAgCuGdr5o250j78Rb095CQrj3LexGRES+KThYLkgGuD+wpC7kNGcOEGH5+0qHMWh2oYoKQD15atw488eYads99bi9804grJuKVabHH0t0EBE5R6g2FONS5ARmS1ZjdZP7Mm1N96Putzut7a3YUbQDgHWZtoAxuGvPIlx6oUdRjVyjyJfLIwDGgKmt2dddsbaeraEPv7TLP5uP843nbd6fPywK5+0YtPUx8T1k6YaztZ4N2h4orkZjaztiwoMxKKHrb3C0Gq2bekVERIHCtESCO+TkAMOHA599Jn8eMMB1+1Jf27ffAs2ene69hhqQHTxYZjmbysyU16dOASbrz9IvTp4EvvxS3p4/v/v2l1wChIQAp08DR+xbl4Q8JCcHGDNGBubHjJE/e2IbRGSZPaei17S4byEywJjRa22m7b6yfWhsa0RsaCyG9Bpi1XMcKQtQVleGVn0rNIoGKT1SbH6+N8lIyoAuSIeKhgocqzzmlG2qGbPWBtDjI+IxKG4QAGDbmW02788f6gt7OwZtfUxytEyPKKlu8mg/th+Xq1Nk9YuDRqN4tC9ERBR41MDmjz8C9davlWGXnBxg1izg0CHjfQ895LpgxqhRQGIi0NAA5DrvjDmf1lk9WwCIigKGDDFvR0ZvvCEzZq+8Uga9u8MSHb5J/Zzavx9oapLXs2bZ9jnljG0QUedMMyut5bFMWytr2qqvZVLaJKsXospKzYICBcfPH0dZXZlN/VODhMmRyT6fHKbT6jA+RdZ4ckaJhMbWRuwp2QPA+qAt4FiJBLWmLTNtXYdBWx+THB0KACitbnJaCr2thBDYfuIcACCrf0+P9IGIiALbwIFA375Aayvw3Xeu3dfSpYDS4ftJRQGefto1+9NogKuukrcZNJM6q2erUoO5rGtrrqUFePNNeduWhfNYosP3qJ9T6r8H6vWsWTJz2prLrFnmzxXCtZ91RIFGDaTtL99vqFXblXZ9O+pb5TfT7graqhm91mba2prZCchs3hEJI8yeby1DkNBPMjsNpSKcsBjZ7pLdaNW3IjEiEX1j+lr9PEcWI2OmresxaOtjEqJkeYTG1nbUNLV5pA/HK+pxrq4FOq0Go9Pcc5oGERGRKUVxX2DpyJELa3sKARQUuG6fDJqZUzNoOwvaqvcz09bcJ58A5eVAcjJw/fXWP8+0REeL59e+JStY+pxStbZad7HE1Z91RIEkpUcK+kT3gV7oDXVgu1LXWme47e5MW2uDtmqgz5agLWB/oNDfFr5ypFRER6bvhdIx28CKPmwv2o42vfUxppb2FkOmtL+8H96IQVsfo9MGoWekXIys1EMlEnadlKURxqbHQKcN8kgfiIiI3BXYtHRKuaIYT8l3hSlT5PWePazTWlwsLxoNkJFhuY1ppi0XzzJSFyCbN08u4Get0aOBhARZeoQlOnxDUtKF9ymKrMV95ox1l2HDLJ9V4MrPOqJAY0uJBLWerS5IB51W59J+qWxZiKyopginq09Do2gwMXWiTfuxN1jpbwtfqcfDgfIDVi/+1hl7sp4BYHj8cPQI6YG6ljocKD9g9fOKaoogIKAL0qFXeC+b9knWY9DWB6klEkqqGz2y/10n5aqC4/vGemT/REREAHDFFTKQd+gQUFjouv3Mm2f+s3oK8pIlrttncrIMnAkBbNrkuv34AjV7dvhwICLCcpuxY4GgIKC0VAZ4CcjPl6VDgoIuPIa7wxIdviU/Xx77ptTPqWeeAVJTrbs884yxJILpNlz5WUcUaNQMU2vKAtS1yExbdXEwd7ClPIL6GkYnjkZkSNeLk3ekBit3Fe9CS7v1p3SoQdu0qDSb9uetkiKT0D+2PwSEVdnXnRFCGALgaskFawVpgjApbRIAILfQ+m9q1azntKg0mzJ7yTYM2vqgpCi5GJknMm1rm1pxpEzW38nsw6AtERF5TmwsMPGXxI6NG123n+PH5XWPHkBoqAym5uQAM2a4bp8ASySoulqETBUeDowYYd4+0L32mry+7jogzY7/bXn8+YbKSln6oqlJfrExerT9n1MzZwLr1zu2DSLqmpoFmXsmF3qh77KtmmnrrtIIpvuyZiEyw+n4abZldgLAoLhB6BnWE83tzdhbstfq5/lbTVvAOXVtj58/jvL6cgRrgjEuZZzNzzdkPp+xvg+sZ+seDNr6IMNiZDXuD9ruPV0FvQB6x4UjoUeo2/dPRERkytWBpcZGYPVqeXvtWvlzXp57ghimry2QT/nvbhEylfo4FyOTZQ3eeUfetmUBMlNqpu3u3UBFhXP6Rc7V1gbcfDPw889Anz7A5s3Avn2OfU7NnCmf687POqJAMjpxNMK0YahqqsLhisNdtlVr2qrZr+6gZvVak2lryOxMty2zEwAURbGrRIK/lUcA7AuYdqRmPY9LGYdQre1xGnsCx4YAuh+9F96IQVsflKQGbT2QabvrlCyNMI5ZtkRE5AXUwObGjUB7u/O3v24dcP480LcvMG2a87fflYsvBnQ6oKhIloAIREJYl2kLcDEyUx98ANTUAAMGGOsj2yo5GRg1iiU6vNmjj8r3JiIC+PxzID7e0z0iou4EBwUb6r92dyp6bYs8w9UTmbbdBW2b2pqwp2QPANtrqKrUQKE1pSIAoE3fhuJaWQPJn7I71fHbdmZbt9nXnbG3NIIqKy0LChQcP3/csLhYd/wxgO6NGLT1QUmGmrbuDdrq9QJ7TzNoS0RE3mPiRCAqSp4ivNf6s+uspi7kdO+9sjaoO4WFAZdcIm8H6inqp07JLM/gYHmqdle4GJkkhPG4nT9f1qe1l+mXIuRd3noLeOklefuf/+z+94OIvIe1GaaeKI+gZvV2Vx5hd/FutOpbkRiRiH4x/ezalzoOWwq3QFgxcZfUlkAv9NBqtEiMSLRrn95oZMJIRARHoKa5Bvln8+3ahqFUhZ0B9JjQGIxIkHWmrA2iszyCezBo64PUoG1lfQua21yQVtSJgrJaVDW0IiwkCMNT3DdxEBERdSY4GLj8cnnb2YHNPXuAHTvkPu66y7nbtlagB83UrNnRo2XWcVdGjZLvVWUlcPKky7vmtXbulMeuTgfceadj2zJdjCyQA+HeZssWY9mLpUtlSQMi8h3Wng7viYXIrM20NS2NYO8iVBNSJyBICUJxbbEhANgVdeGr1B6pCNK4+Zt0F9JqtMhKywJgX13b2uZa7C/fD8D+oC1ge4kEtTyCvywK560YtPVBPXRahIfID6my6ma37XfLMVnQbGLfOAQH8dAhIiLv4Kq6tupCTjfeCCQkOHfb1lJf2+bNQLP7pnyvYW09W0AGKceMMX9eIFKP25tuAnr1cmxbv/qVHNfCQqCgwPG+keNOn5ZB2tZW+dn05JOe7hER2WpS2iQAwOGKw6hsrOy0nSHTNsQDC5E1dZ1pqwac7VmETBUeHI6M5AwA3ZeKAPw7s1MdR2uzXE3tKNoBvdCjT3QfpPRIsb8P6bb1QQ2iszyCazHy5oMURTEsRlZS3eiWfQohsO34OQDA5AE93bJPIiIia6iBza1bgbo652yzuhpYs0betnchJ2cYNQpITAQaGuTrCzTW1rNVBXpd2/Pn5YJ5gHOO2/BwGbgFArdEhzeprwduuAEoL5dfUKxe7Vj5CyLyjF7hvTC452AAso5pZwwLkbkx09aahciEEIYgqyOZnYBt2Z3+nNmpLuZmT6atIwvCmVLfy51FO9HS3tJl26a2JpxtOAvAP4Po3oTTvI9KiQkDABRVuSdo+/PZepTVNCNEq0Em69kSEZEXGTAA6NdPZp59951ztvnuuzJQOmKEXBDMUxTFdZnE3k6vB3bvlretybQFzOvaBqJ33gEaG2U5iWzH/nczCNTjz9sIAcydC+TlyQXHPvtMLkBGRL7Jmrq2nqhpq+6rvrUebfo2i21OVJ1AWX0ZgjXBGJcyzqH9WVsqAvDvha/U7Osj546goqHCpueqmbGOZD0DwKC4QegZ1hPN7c3YW9L1QhFqlm14cDhiQxkfciUGbX1UWmw4AODMefcEbXN/lh8c4/rEIjTYf+rHEBGR73N2YLPjQk52lmpzmkANmh07JjOeQ0OB4cOte44a3N29WwZ9A4kQxtII993nvONWPf6+/TYwS3R4i7/8BfjoI0CrBdavB/r08XSPiMgR1mSY1rbUAjAuDuYOpgHi2uZai23UPmcmZyJUG+rQ/tSgbV5pHhpaG7ps689B27iwOAzrNQyAdaUiVHqhNwZtHcx6VhTFkK3bXYkENes5PSrd7prGZB0GbX1UWqzMtD1zvusPNmdobdfjm8PlAIBslkYgIiIv5MzA5g8/APn58tTw2293fHuOmjJFXu/ZA5w969m+uJNa4iAjQy4wZo3hw4GwMKC2FjhyxHV980bffivrzkZGArNnO2+7piU6cm0vtUdO8Nlnxtq1r75qLFlBRL5LDbDtKNrRaUaruhCZOzNtQ4JCDIHYzkokOKs0AiCDfik9UtCmb8Ou4q5rGxkChX56Or6tNWUBWRe5qqkKYdowjE4c7Xgf0rrPAAf8u76wt2HQ1kcZg7auz7T9ruAsKupaEBMejIsGOLiiBRERkQtccYWs7Xj4sFyoxxFqlu3s2UC0+5JbOpWUZFxg6+uvPdsXd7JlETKVViuDvEDg1bVVj9vbbwd69HDedjUa4Kqr5O1Ay/b2Bvv3A7/9rby9YAEwb55n+0NEzjE8fjiidFGob63H/rL9Ftt4ojwCYMzsrW62vBiZWspAzRZ2hKIoVpWKAPx/4Stb6vuq1AD6xNSJCA6y8hvurvrwS6btlsItEEJ02s4005Zci0FbH5USEwZFAWqb2lDd2Oqy/ej1Ah/vlh+O08emIkTLQ4aIiLxPTAyQlSVvb9xo/3bKyuSpx4BnFyDrKBBLJNi6CJkqEBcjKykBPv1U3nbFcRuIx583qKiQC4/V1QGXXw48/7yne0REzqJRNIY6pp0F6TyxEBlgDBJbyrStba7FT2U/AXB84SuVNdmdLe0tKK0rBeC/2Z2m2det7dbFeNQxc0bWMwBMSJmAICUIxbXFhmxaS9QAuj8uCudtGIHzUaHBQYiP1AFwbYmEbSfOoaiqERG6IFwzKsll+yEiInKUMwJLb78tFzTLyjJmbHoD09fWReKD32hrk+UgANsybYHAXIzszTflmF10kSxn4GyBWqLDk1pbgZtuAk6ckAstfvSR9WVCiMg3qMHKzk6H91Smrbq/6qYLM213Fu+EXujRO7q30wJ2pnVUO8vuLK4thoBASFAIeoX759m/Q3oNQWxoLBrbGg2B8e44M+sZACJCIjA2aSyArmvr+nN9YW/DoK0Pc0eJhO+PyAXIrh6RhPAQrcv2Q0RE5Cg1sPn110B7u+3Pb28HXn9d3vamLFsAuPhiuSBXcbGst+vvDh+WNVQjI4EhQ2x7rhrk3btXBjL9XVsbsHKlvO2q4zY5GRg9Wn5hsGmTa/ZB5hYuVLB5s/wd+PxzoCeXlSDyO92VBVBr2rpzITLAmNlrKdPW2ZmdAJCRlAFdkA4VDRU4VnnMYhs1SJgWlQaN4p9hLGuyr01VNlbicMVhAM7Lega6Py4B1rR1J/882gNEWmw4ANcFbdv1AnmF5wEAk7gAGRERebmJE4GoKKCy0pilaYsNG4BTp4DYWODmm53fP0eEhgJDh8rbY8fKGrc5ObZvJydHPjcszL5tOPp8a6lZsuPGyZqqthg8WNZ0bWz0/wB3Tg4wcCBw5gwQFCQvruKqEgk5OUBGhoK+fRORkaG47JhyNWf8bqhjkZ6eiFdflatxr1kDjBzp5M4SkVfISsuCAgUnqk4YTv1XtbS3oKm9CYAHM20t1LRVA3nOyuwEAJ1Wh/Ep482231Gg1FA1BEzPdB+03XZmGwBgcM/BTs0+NtTW7aIPgfJ+eAMGbX2YMdPWNeURDpfWoL65HZE6LQYnOHFFCyIiIhfQaoErr5S37QksqQs5zZ0rAy/eJCcHyMuTt9va5OJEs2bZFhjKyZHP2b8faGqyfRuOPt8W9tazBWSQd9w48+34I/X9OHVK/tzeDtx2m+sC6WrQduNG55XoMD2mmpsVlx5TruSM3w3TbbS1KYb7AyFbnChQRemiMDJBfivT8VR00yxXTy1E1jHTVi/0hkChMzNtTbfXWakIwyJkfp7ZaRiHLkoTqFyR9Wy6vbzSPDS0Xhhrqm+px/kmmdzn7++HN+D57j7M1Zm2e07JX8SM3jHQaJRuWhMREXne1KnAJ5/IoO0TT1j/vFOngC+/lLfvvdc1fXPE0qWAohiDZer1HXcAL7xg3TZ27zZ/rq3bsPR8RQGefhqYOdO6PlhLDbbaWs9WNWECsHmzzNi96y6ndcurdDwmANe9H4CxRMeZM7J8xbBhjm/T+Brk35lCKC59Da7i3N9P49/cvjgWRGSbyemTsb98P7YWbsWMYTMM96sB04jgCARpXHgahQWdLURWUFGA803nEaYNw5jEMU7dpyG7s7NM2wCpoToxdSI0iganqk+hqKYIqVGpnbZ1RdYzAPSO7o2UHikori3GruJduKTPJWaPq+9FlC7K7V8oBCIGbX2YmmlbXtOEljY9QrTOTZze9UvQdnzfWKdul4iIyFXUbMCtW4HaWnmavDVWrpSBliuvlKfXe5sjRyxnN9bXAz/84Ni2HdmGEEBBgWP776ilxZhVbE+mLWAM9vpzpq2lY8IV74cqLAy45BL5hchXXzknaOvu1+Aqrvr99MWxICLbZKdl4/Xdr19wKrq6CJgngmKdLUSmBgknpE5AcJBzV0ZUa7IeKD+A6qZqQ11dlSHT1s+DtpEhkRidOBp5pXnIPZOLG4ffaLFdm74NO4p2AHB+pq2iKMhOy8b6Q+uxtXDrhUFblkZwKwZtfVhMeDCiw4JR3diKn8/WYViy8z7QK+tbcPxsPQAgszeDtkRE5Bv695eX48dlpuV113X/nJYW4M035W1vW4BMNXiwPG26Y1Zl797AP/5h3TYefRQ4fdr+bXT2fFsXCuvOgQPyPYmNBfr1s28barB33z6guRnQ6ZzXP28xaJA8Jky54v0wddVVxqDtQw85vr3+/S3XHfbGL066Mngw8FOHhb6d9fvpyveTiDxPDbjtKt6F5rZm6LRywqppkVmu7l6EzHSfah9UhtPx05wbJASApMgk9I/tj+Pnj2NH0Q5cNeAqs8cDpTwCIMc3rzQPWwu3dhq03V+2H/Wt9YjSRWF4/HDn9yF9MtYfWm+xXIX6XqRFpTl9v3QhBm19mKIoGJrUA9tPVOJQSY1Tg7Y5e+Qv4qDESMSEhzhtu0RERK42dSrw2msysGRN0PaTT4DyciA5Gbj+etf3zx5Llsh6l+op2Or1//wPMGNG988H5HMc2UbH5wPyeskS+1+XJeoiZOPHy33Zo29fIC5OLkq3f7/9ZRa82RVXmAdt1ffF2e+HqalTgccek1+IOBoMb2kx/UkAUAzXffo40kv3+9OfgFtvNf7s2O+n+KVMhLx25ftJRJ43MG4geoX3QkVDBfaW7sWktEkAvDPTVg3gOTuzU5Wdlo3j549ja+HWC4K26in5gRAozE7Pxqu7Xu20vi9gDKBPSpsEjeL8paoMC6IVboUQAorJH2SBUqrCW3AhMh+nBmoPl9Y6bZtFVY34108lAIDZWb2dtl0iIiJ3MF0wyRrqAmTz5gHBzj3bz2lmzgTWrwdGj5Z1RUePlgsXWRsQcsY2TJ8f9Et5vcxM2/pgDUcWIVMpijFQqwaB/Y06TklJ9h8Ttho1CkhMBBoaZAkSewkBPPCAzLINC5PZpDqdMARr//Uv4J13nNNnd9Dr5bVWKwPZjvx+jholx2LUKNe/n0Tkeeqp6IB5PVe1nmxUqPuDtmppAtOatpWNlThUcQgADIFlZzMECjuUimhqa8LZhrMAAiNQqI7D7uLdaGprstjGEEB3QdYzAGQkZSAkKAQVDRU4VnnM7DFDeYQAyHr2Bgza+jg1aHuopAbCSUv5rtpyEnq9wLg+sRjXJ84p2yQiInKXyy+XQcWCArnAWFfy84HvvpPt581zT//sNXOmrPXa2Civ7QnmOLoN9fmH5P9t2LsXOHHC9n50xTTT1hFq0Ncf69ru3w9s2SKDhHv2OHZM2EJRjF+KfPWV/dtZsULWkVYU4OOPgfx8gZMny3D8uMDixbLNPfcA27Y53md3UL/4eeIJoKnJsd/PvXvlWOzdKxiwJQoQplmNqtoWmZQVFeK5TFvToO22M/IDeVDcIMRHxLtkv+o4bDuzDXqhN9xfUi8TysK0YYgL8//4RL+YfkiMSESrvhW7i3dbbGMoVeGirGedVofxKfIPsY4Zv8y0dS8GbX3cwIRIaIMUVDW0orTG8rcwtjhb14IdJyuhUYC7L7azkBwREZEHxcQAWVnydnfZtq+9Jq+vuw5I8/8z7pxm0CBgyhSZMblypfO229goa9oCjmXaAv69GJkaJJw+XZb1cCdHg7bffmush7t8OfDrX5s/vmSJDHi2tMjrM2fs76s7HDggFxvzhS9+iMg7qYG33DO5hkQstTRBxwW53EGtaVvdbCyPkFvo2tIIADAyYSQigiNQ01yD/LPGgufFdcUAZGanYm/dJB+iKIrZMdFRaV0pTlSdgAIFWWlZLuuHmsVr+mUCYBK0ZaatWzBo6+NCtBoMjI8EILNtHbXztPxGb2RqNNLjwh3eHhERkSdYE1iqrzeegu2tC5B5M3XM3npL1jd1hrw8oL1dnoKfmurYttSg78GD8nR+f1FbC7z7rrztieN2yhR5vWcPcPasbc89fhy46SagrQ2YPVvWx+1IowH++U9ZJqC0VAamGxsd7rbLqF/8XH+948csEQWm8SnjodVoUVxbjNPVpwGYlEfwYE1b00xbtWSBWsrBFbQarSEIaRooLKovAhBYmZ2WSmao1AD6yISRLj0+stMt98FQHiGA3g9PYtDWDxhLJDhe13Znofxg/tWgXg5vi4iIyFPUoO3XX8sgoCUffADU1AADBhgDUWS9668HUlJk4C4nxznbNK1n62gyTUqKrPfa3i6Dwf5izRqgrg4YPFiWAnG3pCRgzBh5++uvrX9ebS1www3AuXPy/X3jjc7f48hI4PPPgV69gN27gbvvNi5+503q6mSAGeAXP0Rkv/DgcIxNGgvAGCBTs1w9WR5BzfZt07dh+5ntAFybaQtYzu4sqZPlEQIps7PjQmCmXF0aQaUGjg+UHzAcCzXNNYbSHYGwKJw3YNDWDwxN7gEA2H+mupuWXSuracKJc03QKAom9e/pjK4RERF5xIQJQHQ0cP68DPp0JITxFPP582V2H9lGqzWeDq5mGzrKWfVsARkQVLNt/WUxso7HrafOErW1RIJeD9x+uywlkJwMfPKJXICsK337ynq3Wq38guWvf3Woyy7xwQcyGD1wIHDllZ7uDRH5MjVYqZ4Or2a5eqQ8wi/7bG5vRnNbMw6UH0B9az2idFEYHj/cpfu2VBaguF6WR0jrEThBwnEp4xCsCUZZfRlOVp00e0zNenZ10Da5RzL6xfSDgMCOoh0AjFm2saGxiAiJcOn+SeK/KH5gTFoMgjQKiqoaUVhp//l/W46dAwCMTIlCTHiIs7pHRETkdlqtMYhiKbC0a5c8vVunA+68061d8yvz5slant9/L8sQOMo009YZ/K2u7bZtwE8/AaGhwJw5nuuHadDWmgzYJUuAzz6Tv2+ffGJ9GYFLLwVeflne/tOfgC++sK+/rsAvfojImTqeiq5m2vbQ9XB7X3qEGPdZ01xj6FNWahaCNEEu3fektEkAgCPnjqCioQKAeU3bQBGqDUVmciYA86zj5rZmw+JkrixVoep4XLKerfvxzws/EKHTYmx6DAAg9/g5u7bRrhf4Kr8MAHDRQJZGICIi39dVNqAabLnpJnkKNtknNVWWSQAcz7atrQUOH5a3nZFpC/hfpq163N56KxDnwQW0L75YBo6Li4FDh7puu24d8Mwz8vbKlcZFAq01f74sPSAE8JvfAPn53T/HHXbsAPbu5Rc/ROQcatZkXmke6lvqUdssT0FXFwVzpyBNECJD5Lo5pkFbV2d2AkBsWCyG9RoGwFi71RC0DbAaqqYlElR7S/eiub0ZvcJ7YWDcQNf3QS1X8Ut2L+vZuh+Dtn5CLWew7Wf7grYb88tQXN2ISF0QLh3M/16JiMj3qUHb3FxZu1Z1/jywdq28zTqUjps/X17/85+yxqe99uyRgbnevYGEBOf0bdw4eV1QYH4M+KJz54APP5S3PX3chobKLFig6xIJe/YAc+fK23/4A3DHHfbt78UXgcsuk4H9668HKivt244zqQH0m28GerKqGBE5KD0qHak9UtEu2rGzeKdHFyIz3a+7g7am+1FLJKjlEQItu9MQtD1jDNqqYzI5fTIUN9RIUvuw7cw26IXemGnLoK3b+EzQ9tlnn8XkyZMRHh6OmJgYi20URbngslb9r6wTlZWVmD17NqKiohATE4O7774bdY78x+Ehk/rHQVGAo+V1KK9tsum5Ta3t+GCHXKXyuhG9EB6idUUXiYiI3KpfP1lrsq0N2LzZeP8778jV6EePBrJdf2aZ35syRS7mVlMja3zaSy1h4KwsW0AGf3v3lrct1Tb2JatWAc3NQGam88pHOKK7urZlZcD06fJ37eqrgeXL7d9XcDDw0Ueyzu3PP8tAaVub/dtzVGWlzCAGPB9AJyL/oCiK4VT03MJcQ3kET2Tamu73yLkjOFF1AgoUZKXaeKqEndTT/rcWbkV9Sz2qmqsABF6gUB2Hn8p+Ql2LjFGpQVt3lEYAgFGJoxARHIGa5hrkn81neQQP8JmgbUtLC2666Sbc181fRqtWrUJJSYnhMn369C7bz549GwcPHsTGjRvxxRdf4Pvvv8c999zjxJ67R0x4CIYny2/Dcm3Mtv3XvmJU1rcgoYcOVwyKcUHviIiIPKNjYEkI42n8993nuYWc/IlGY8y2XbHCuhqnljhzETJTaoDTl+va6vXed9yqv1ubN8tgsqnmZmDmTKCwEBgyRAbzgxwsg9irF/D550BEBLBpE/Doo45tzxGrVwNNTcCYMcCkSZ7rBxH5F9NT0b0l03bDzxsAACMSRrhtUTQ1u3NH0Q6cqDoBQNbZ9cSibJ6UGpWK3tG9oRd67CjaASGEWaatO2g1WkxMnQhABtHP1JwBEHgBdE/ymaDt0qVL8cgjj2DUqFFdtouJiUFSUpLhEhoa2mnbQ4cOYcOGDXjzzTeRlZWFiy++GC+//DLWrl2L4uJiZ78El7t4kCxr8MVPJWjXd/0fk14vIIRAbVMrPt4tf/FmZ/VGcJDPHBJERETd6hi0/fZbeap8ZCQwe7bn+uVv5s6VtT337pW1Pu3h7EXIVGoQ2Jfr2n79tcwwjYoCbrvN072RRowAkpNlJu2WLcb7hQB+/3tg61YgOloGWjs5Sc5mo0YB774rb7/0EvDWW87Zri28MYBORP7BtIapmmnr8aDtMRm0VQPK7jCk1xDEhsaisa0RXx79EkDgBglNS0WcqTuD4tpiaDVajE9x8jfcVvZBrWmbFpXmtv0HOr87D/7+++/H7373O/Tv3x/z58/H3LlzO631kZubi5iYGIw3SemYMmUKNBoNtm/fjhkzZlh8XnNzM5pNUgpqfimSptfrodfrnfhqbHPFkHis2XYaJdWN+PFoOX41KN5iO71e4L9z9uN8Qwv69IxAfUsb+sZF4FcDeuLcuQqPvgZvpNfrIYTguHTAcbGM42KZv42Lv7yOQHDZZTLD7+hR4ORJYx3K228Herh/QWa/1bOnPGX93XflGNu62FRlpQxKAsY6tM7iD5m26nF7xx0y09QbKApw1VWylvFXXwFXXCHvf/ll4O23ZQb2unXA4MHO3e+MGcDTTwOLF8ug6dChwEUXOXcfXfnmG/l50qMHv/ghIufKSM6ALkiHykZj4W6PlUf4Jau1tK4UgPsyOwFAo2gwKW0S/n3s3/gwXxZzT41Kddv+vUl2WjbWHliL3DO5iA+S8Z2xSWMRHhzutj6o7/2W01tQVFsEgOUR3MmvgrZPP/00rrjiCoSHh+Orr77C73//e9TV1eHBBx+02L60tBQJHVa60Gq1iIuLQ2lpaaf7WbZsGZYuXXrB/WfPnkVTk231ZJ3t0n4R+HR/Bd7b8jMGR+ktBqxPVjbh4JnzAIDiynoAwHXDolBRcRbV1dUQQkCjYcatSq/Xc1ws4LhYxnGxzN/Gpba21tNdICtFR8vTl7dskcGlTz+V97MOpfPdd58M2q5bBzz/PBAXZ/1z1XqzAwcCsbHO7ZcaBD5xQi7m5WuLRp05I7NVAWMZCm8xdaoxaLt8ObBxI/DII/Kxv/0NmDbNNft98klg/35Z53bmTJlFrdYudjU1y/b222XGPhGRs4QEhWB8ynhsKZSnLyhQEBHimW/qokLMM3zVervuMjl9Mv597N/YW7oXADNtt53ZhiRdkrzPjVnPADApTdYBOlp51HAfM23dx6NB28cffxx//etfu2xz6NAhDB061KrtPfXUU4bbGRkZqK+vx9/+9rdOg7b2WrRoERYuXGj4uaamBunp6YiPj0dUlGdOX1DddlEsNv1ci5L6dqw7UIN5v+qPsBBZREyvF9BoFHxfeAbaYC16RoTgfEMrxvWJxZQx/SCEgKIoiI+P94ugirPo9XqOiwUcF8s4Lpb527h0VXqHvM/UqTJo+8wzcvGiiy6Sp1mTc02aJGt87tsna36a/KnULVfVswXkqfmDBsnsyF27XBdIdJU33pCn5F9yiSxJ4E2mTJHXe/fKcgi33CL7OmeOMXjrCooiF2Y7ehTIywNuuAH48UfXZyEXF/OLHyJyrcnpkw1B2x4hPaBRPPN3s2n92J5hPTEobpBb998xszdQg7ZjEscgTBuG803n8enPnwJwb9YzAMSFxWFor6E4XHEYABAfHo9QLf8XcheP/uf86KOP4tChQ11e+vfvb/f2s7KycObMGbNSBqaSkpJQXl5udl9bWxsqKyuRlJTU6XZ1Oh2ioqLMLgCg0Wg8fokO1+HOyf2gURRsOnwWf/j4J9Q0teHLA6W4eeU2fH2oHHlnqqFAwU3j07Hunmw8ee1wBAUFQaPRQFEUj78Gb7xwXDguHBeOS8cL+Y6QEHnd2iqvnX36PUmKYgxkvfaabQuSuaqerUoNBjuzREJOjgxSh4XJ65wc521b1doqg7aAdwYJExOBvn3l7YsuAs6fl+UQXnvN9bVeIyKAzz4D4uNl4DY11bXvBQC8+SbQ3g5cfDEwcqRr9kGu98orr6Bv374IDQ1FVlYWdnRTiPujjz7C0KFDERoailGjRuHLL780e1wIgcWLFyM5ORlhYWGYMmUKjh492snWiLpmGpCLDPFcOr9pLd3J6ZM7LTnpKhNTJ5oFrNOiAzOzMzgo2LAQ2Pkmeba0u4O2gHl2L0sjuJdH/+uMj4/H0KFDu7yEqP9p2SEvLw+xsbHQ6XQWH8/OzkZVVRV2q+fkAfjmm2+g1+uRZWsxNi9y7ehkPDt9FHpGhuDM+Ub84aN9WPn9cbS2C6zeehL5xbIGb2bvWISFBCFIwxUUiIjIP+XkAIsWmd/30kuuC+oEutmzZa3Po0dl7U9rqcFUV2Tamm7XWYuR5eQAs2bJU/SbmuT1rFnOP64+/xwoKQESEmQZAG+TkyNrRZs6cgToENNymd69gYcekrerq137XrS1AStXytveGEAn66xbtw4LFy7EkiVLsGfPHowZMwbTpk27IJFHtXXrVtx22224++67sXfvXkyfPh3Tp0/HgQMHDG2ee+45vPTSS3jttdewfft2REREYNq0aR4vm0e+KTvNWIagpK4EGa9nIOeQ+/9oOVl10nB7Z9FOt/chMiQSvaONdW/+8sNfPDIO3iAuzFhvSqvRYmex+1dW1WmNMbVj544F7HvhCT6TKnT69Gnk5eXh9OnTaG9vR15eHvLy8lBXVwcA+Ne//oU333wTBw4cwLFjx7BixQr85S9/wQMPPGDYxo4dOzB06FAUFcniycOGDcPVV1+NefPmYceOHdiyZQsWLFiAW2+9FSkpKR55nc4yKi0af5kxCjHhwSiraYYQQJBGQW1TG9r1AolROiRHM6WdiIj829KlF2b8KQrw9NOe6Y+/i4yUtT4B4+JZ3SkrAwoL5fuSmemafjl7MbIlS+S1mk0shGuOK7V+6t13GzPGvYk3/H59+KF5H1z1XnzxBVBUBPTqJYPC5Juef/55zJs3D3PnzsXw4cPx2muvITw8HG+//bbF9i+++CKuvvpqPPbYYxg2bBj+/Oc/IzMzE//7v/8LQGbZvvDCC3jyySdxww03YPTo0fjnP/+J4uJifKrW0iCygVoaAQAEBPaX78esD2e5NUiWcygH7+x7x/BzWX2ZR/pgGjg+WXXS7X3wBjmHcvDJ4U8MP7fp2zzyXqzYZfyjrqalJiDfC0/xmYXIFi9ejHfeMX5wZGRkAAC+/fZbXHbZZQgODsYrr7yCRx55BEIIDBw40DApqxoaGlBQUIBW9fxIAGvWrMGCBQtw5ZVXQqPRYNasWXjppZfc98JcKCUmDEuvH4G/f1WAESnRGJUajb/9pwAAkNE71u2nOBAREbnbkSMXnqYvBFBQ4Jn+BIL584FXX5W1P4uLge6+B1cDqcOGuW5hp4wMQKORQbeSEiA52f5tCQHk51u+35nH1dGjwNdfywDkPfc4b7vO5A2/X+7qg/olxF13AZ2cxEderqWlBbt378Yik9MvNBoNpkyZgtzcXIvPyc3NNVvLBACmTZtmCMieOHECpaWlmKIWeAYQHR2NrKws5Obm4tZbb71gm83NzWbl+2pq5FmQQgjo9Xq7X58/0Ov1AT8OSzebL3guIKBAwdLvlmL6kOlu64MCBQIioPvgDTqOAwCPvxee6IPKnz4jrH0NPhO0Xb16NVavXt3p41dffTWuvvrqLrdx2WWXQXT4qy4uLg7vv/++M7rolfrHR+LV2bJ4n14vkLPnDH4+W49J/W1Y0pmIiMhHDR4sT5c2nf4VBRgyxHN98nejRsn6plu2yBqgixd33V4tWeCqeraADAYPGwYcPCiDxNddZ/+2/ud/5GJbljjzuFKzbH/9a2PdWG/jDb9flvoAAAMGOG8fx44BX30lX9u99zpvu+ReFRUVaG9vR2Jiotn9iYmJOHz4sMXnlJaWWmxfWlpqeFy9r7M2HS1btgxLly694P7q6mqUl5cHdN18vV6P6upqCCECdhwKzl34jZOAQEFFQadlPFzRB9MAXaD2wRt4wzh4Qx9U/vQZUVtba1U7nwnakuM0GgVLbxiJkxX1GJMe4+nuEBERudySJfJUZkUxnjYthPH0dnKN++6TQduVK4E//QnQdvEXp6vr2arGj5dB25077Q/a/uc/wGOPGX9WjyfVFVc41kdVYyOwapW87c31U73h96tjH0y1tgLBwY7v4/XX5fW0aYADayQTAQAWLVpklr1bU1OD9PR0REdHIyEhwecDEY7Q6/VQFAXx8fEBOw5Deg7B/vL9F2Q1Du01FAkJCeyDG/vgDbxhHLyhDyp/+owIDbWuXKlvv0qyWXRYMAO2REQUMGbOBNavB0aPBkJD5XVODjBjhqd75t9uvFHW/iwqkrVAOyOEMdPW1UFbR+vaHjkC3HKLzLK9+27g44+Nx5X6P8uKFYDJ+rZ2+/BD4Px5oE8foJsTyTzKG36/OvZhyBB5ffAg8PDDjm+/qck3AujUvV69eiEoKAhlZWVm95eVlSEpKcnic5KSkrpsr17bsk2dToeoqCizCwAoigKNRhPwl0AfhyWXLTGUAgBgOC19yaVL2Ac398EbLt4wDt7QB9OLP31GWINBWyIiIvJrM2cCeXkyezEvjwFbd9DpZO1PoOsFyc6cAcrLZSbumDGu7ZMaFN6588KMzO5UVQHXXw9UVwOTJwOvvCKzO9XjqrgYuPZaGeC74Qagk7OiraaO2T33AEFBjm3L1bzh98u0D4cPGxcne/VVY5asvT7+GDh3DkhPl+8x+a6QkBCMGzcOmzZtMtyn1+uxadMmZGdnW3xOdna2WXsA2Lhxo6F9v379kJSUZNampqYG27dv73SbRF2ZOWwm1t+8HqMSR0EXpMOoxFHIuTkHM4a578NV7cPoxNEI1YZidOJoj/XBk+PgDbxhHLzheAhkLI9ARERERE53773A3/4ma4EeOwYMHHhhGzXLduRIICzMtf0ZM0YGhysqgNOnZRarNdrbgdtukwtbpaXJTNKOC1EFBQHvvw9MmgQcOiQDl5s327dg1d69wPbt8rT+u++2/fkky188+6wszbFggaxnfMkl9m3LlwLo1L2FCxdizpw5GD9+PCZOnIgXXngB9fX1mDt3LgDgjjvuQGpqKpYtWwYAeOihh3DppZfiH//4B6699lqsXbsWu3btwsqVKwHI7NiHH34YzzzzDAYNGoR+/frhqaeeQkpKCqZPn+6pl0k+buawmZg+ZDrKy8s9VjJj5rCZmDlsptv327EPnh4Hb+AN4+ANx0OgCsyjnoiIiIhcqn9/WQMU6DzbcfdueaqdKxchU4WGykXSANtKJCxaBGzYIIPKn30GdFhvyCAqCvj8cyA2Fti2DZg/3/aMXsAYJJw5s/N9Ufcefxy49VagrU1mRZ88afs2fvoJ2LpVBvt/9zund5E84JZbbsHf//53LF68GGPHjkVeXh42bNhgWEjs9OnTKCkpMbSfPHky3n//faxcuRJjxozBxx9/jE8//RQjR440tPnjH/+IBx54APfccw8mTJiAuro6bNiwwep6hURERJ1h0JaIiIiIXEKtAbpqlSwd0JG76tmqTEskWOPdd2W2MACsXg1kZnbdfuBAYN06QKOR7V94wbb+VVcDa9bI26yf6hhFAd56S75nFRWybEVdnW3bUAPoM2YAnZQnJR+0YMECnDp1Cs3Nzdi+fTuysrIMj23evBmrV682a3/TTTehoKAAzc3NOHDgAH7961+bPa4oCp5++mmUlpaiqakJX3/9NQYPHuyOl0JERH6OQVsiIiIicolrr5W1QM+dk7VBTQlhXLTLHZm2pvuxJtN2+3Zg3jx5+8kngZtvtm4fV10FPP+8vP2HP8jyENZ6912goQEYPtz+0/nJKDwc+PRTmbH800/AHXfIheSsUVsLvPeevM0AOhEREXkCg7ZERERE5BJBQbIWKHDhgmSnTgWhqkqBTidr2rqDmmm7a1fXwbviYpld2dwsMzSXLrVtPw8+KBdi0+uBW24Bjhzp/jlCGMdo/nyZKUqOS08HPvkECAmR108/bd3z3ntPZuYOGQJcdplLu0hERERkEYO2REREROQyd98ta4Ju3SqzHVV5ecEAgLFj5aJb7jBypFwcrLoa+Plny20aG4Hp04GSEmDECJn9auuaH4oCvPoqMHkyUFUFXH+93GdXfvwRyM+X2aF33GHb/qhr2dnAa6/J20uXAuvXd92eAXQiIiLyBgzaEhEREZHLJCfLIChgnm27b5+M1Lqrni0gg8Njx8rbluraCiEzg3fuBOLi5MJiPXrYty+dDsjJAdLSgIIC4LbbgPb2zturY/Ob3wDR0fbtkzo3dy7w8MPy9h13APv2dd5261Zg/365+NycOW7pHhEREdEFGLQlIiIiIpdSa4K+956sFQoYM23dVc9W1VVd27//XfYxKEjW4O3f37F9JSYCn30mg3///jfwpz9Zbldebqz5O3++Y/ukzv3tb7LmcEODzH4uL7fcTs3KvfVWIDbWff0jIiIiMsWgLRERERG51OWXy9qgdXUyKNreDuzfrwXg3kxb0/11zLT98kvgv/9b3n7pJdlnZ8jMBFatkrefe864uJWpVauA1lYZUB43zjn7pQtptcC6dcDAgcDp08CNNwItLeZtKiqADz+Ut7kAGREREXkSg7ZERERE5FKKYswgXbFClguor9cgIkJg6FD39kXNtN2zx1iu4PBhWb5ALY/g7GDdLbcATzwhb//ud8COHcbH2tuBlStl0VQGCV0vNlaWvYiKAn74AViwQL7vqlWrZCB33Dj3Z4ETERERmWLQloiIiLr1yiuvoG/fvggNDUVWVhZ2mEadiKwwZ44sE7B/P/DSSzJImZkpSxG405AhQESEPEX+0CHg/Hl5qnxNDfCrXwEvv+yahaeeflrup7lZ1vgtLpb3b94cgpMnFcTEyOAuud6wYcAHH8j3+Y035KJxAKDXA6+/Lm8zgE5ERESexqAtERERdWndunVYuHAhlixZgj179mDMmDGYNm0ayjsrCElkQWysrBEKAG++Ka89UQogKEgGiwFg2zYZKD16FOjTB1i/HggJcc1+NRrg3XeBESOAkhJgxgygqQl4551wAMCddwLh4a7ZN13o178Gli+Xtx96CPjmG2DjRuDnn+VCcOqxSkREROQpDNoSERFRl55//nnMmzcPc+fOxfDhw/Haa68hPDwcb7/9tqe7Rj5GzV4UQqayrl8P5OS4vx8xMfJ63jwZqAsJkQuGxce7dr9RUXI/cXGyREJSkoKNG3UAHF/0jGz32GPA7NmyRMUNNwAzZ8r7tVrgP//xbN+IiIiIGLQlIiKiTrW0tGD37t2YMmWK4T6NRoMpU6YgNzfXgz0jX1RYaP7zmTPArFnuDdzm5AD/+pf5fS0tMsPSHQYMAB58UN6urVUAKAAEHnzQMwHsQKaWRxgwQC6S19Ag76+sdP9xSURERNSR1tMd8Afil9ULampqPNwTx+j1etTW1iI0NBQaDeP5Ko6LZRwXyzgulvnbuKif98J09Ro/VVFRgfb2diQmJprdn5iYiMOHD1/Qvrm5Gc3NzYafq6urAQC1tbWoqqryi/ffEXq9HjU1NQgJCQnIsVi8WC0WK6/lr5DA4sXAFVe45/epYx8k9/bho4883wdv4unfi6Agzx+XKk+PhbME0jzpKHWM6urqUFNT49Pvu6P87e9FR3AsJI6DxHGQ/GkcrJ0nGbR1gtraWgBAenq6h3tCRETuVFtbi+joaE93w6ssW7YMS5cuveD+cZ4oXko+4+BBWfOWffB8H8iI74fjOE92T/1fMlMttk1ERAGju3mSQVsnSElJQWFhIXr06AHFFcsNu0lNTQ3S09NRWFiIqKgoT3fHa3BcLOO4WMZxsczfxkUIgdraWqSkpHi6Ky7Xq1cvBAUFoayszOz+srIyJCUlXdB+0aJFWLhwoeFnvV6PU6dOYezYsX7z/jvC334X7MVxkDgOEsfByF/GIpDmSUelpKQgPz8fw4cP9/n33VH+cvw7A8dC4jhIHAfJn8bB2nmSQVsn0Gg0SEtL83Q3nCYqKsrnfwFcgeNiGcfFMo6LZf40LoGSORQSEoJx48Zh06ZNmD59OgAZiN20aRMWLFhwQXudTgedTmd2n3r6kj+9/47iWEgcB4njIHEcjPxhLAJlnnSURqNBamoqAP94352B42DEsZA4DhLHQfKXcbBmnmTQloiIiLq0cOFCzJkzB+PHj8fEiRPxwgsvoL6+HnPnzvV014iIiIiIiPwSg7ZERETUpVtuuQVnz57F4sWLUVpairFjx2LDhg0XLE5GREREREREzsGgLRnodDosWbLkgtNaAx3HxTKOi2UcF8s4Lr5vwYIFFsshWIPvvxHHQuI4SBwHieNgxLEITHzfJY6DEcdC4jhIHAcpEMdBEUIIT3eCiIiIiIiIiIiIiCSNpztAREREREREREREREYM2hIRERERERERERF5EQZtiYiIiIiIiIiIiLwIg7Y+bNmyZZgwYQJ69OiBhIQETJ8+HQUFBWZtmpqacP/996Nnz56IjIzErFmzUFZWZtbm9OnTuPbaaxEeHo6EhAQ89thjaGtrM2uzefNmZGZmQqfTYeDAgVi9evUF/XnllVfQt29fhIaGIisrCzt27HD6a7bH8uXLoSgKHn74YcN9gTouRUVF+O1vf4uePXsiLCwMo0aNwq5duwyPCyGwePFiJCcnIywsDFOmTMHRo0fNtlFZWYnZs2cjKioKMTExuPvuu1FXV2fW5qeffsKvfvUrhIaGIj09Hc8999wFffnoo48wdOhQhIaGYtSoUfjyyy9d86K70d7ejqeeegr9+vVDWFgYBgwYgD//+c8wLfcdCOPy/fff47rrrkNKSgoURcGnn35q9rg3jYE1fSHv4k2fg7biXGtZIM+tnEsDe+7kfEmu4C2f7bbiHGlZIM+RAOdJgPMk50knEuSzpk2bJlatWiUOHDgg8vLyxK9//WvRu3dvUVdXZ2gzf/58kZ6eLjZt2iR27dolJk2aJCZPnmx4vK2tTYwcOVJMmTJF7N27V3z55ZeiV69eYtGiRYY2x48fF+Hh4WLhwoUiPz9fvPzyyyIoKEhs2LDB0Gbt2rUiJCREvP322+LgwYNi3rx5IiYmRpSVlblnMDqxY8cO0bdvXzF69Gjx0EMPGe4PxHGprKwUffr0EXfeeafYvn27OH78uPjPf/4jjh07ZmizfPlyER0dLT799FOxb98+cf3114t+/fqJxsZGQ5urr75ajBkzRmzbtk388MMPYuDAgeK2224zPF5dXS0SExPF7NmzxYEDB8QHH3wgwsLCxOuvv25os2XLFhEUFCSee+45kZ+fL5588kkRHBws9u/f757BMPHss8+Knj17ii+++EKcOHFCfPTRRyIyMlK8+OKLhjaBMC5ffvmleOKJJ0ROTo4AID755BOzx71pDKzpC3kPb/octAfn2gsF8tzKuVQK5LmT8yU5m7d8ttuDc+SFAnmOFILzpIrzJOdJZ2HQ1o+Ul5cLAOK7774TQghRVVUlgoODxUcffWRoc+jQIQFA5ObmCiHkL5RGoxGlpaWGNitWrBBRUVGiublZCCHEH//4RzFixAizfd1yyy1i2rRphp8nTpwo7r//fsPP7e3tIiUlRSxbtsz5L9RKtbW1YtCgQWLjxo3i0ksvNUyagTou//3f/y0uvvjiTh/X6/UiKSlJ/O1vfzPcV1VVJXQ6nfjggw+EEELk5+cLAGLnzp2GNv/+97+FoiiiqKhICCHEq6++KmJjYw3jpO57yJAhhp9vvvlmce2115rtPysrS9x7772OvUg7XHvtteKuu+4yu2/mzJli9uzZQojAHJeOk6s3jYE1fSHv4k2fg84Q6HNtoM+tnEslzp0S50tyBm/4bHcWzpGBPUcKwXlSxXlS4jzpOJZH8CPV1dUAgLi4OADA7t270draiilTphjaDB06FL1790Zubi4AIDc3F6NGjUJiYqKhzbRp01BTU4ODBw8a2phuQ22jbqOlpQW7d+82a6PRaDBlyhRDG0+4//77ce21117Q90Adl88//xzjx4/HTTfdhISEBGRkZOCNN94wPH7ixAmUlpaa9Tc6OhpZWVlm4xITE4Px48cb2kyZMgUajQbbt283tLnkkksQEhJiaDNt2jQUFBTg/PnzhjZdjZ07TZ48GZs2bcKRI0cAAPv27cOPP/6Ia665BkDgjospbxoDa/pC3sPbPgedIdDn2kCfWzmXSpw7LfOm18350jd4+jPN2ThHBvYcCXCeVHGetMybXrevzJMM2voJvV6Phx9+GBdddBFGjhwJACgtLUVISAhiYmLM2iYmJqK0tNTQxnRiUB9XH+uqTU1NDRobG1FRUYH29naLbdRtuNvatWuxZ88eLFu27ILHAnVcjh8/jhUrVmDQoEH4z3/+g/vuuw8PPvgg3nnnHQDG19VVf0tLS5GQkGD2uFarRVxcnFPGzhPj8vjjj+PWW2/F0KFDERwcjIyMDDz88MOYPXu2WZ8DbVxMedMYWNMX8h7e9jnoqECfazm3ci5Vce60zJteN+dL3+DpzzRn4hzJORLgPKniPGmZN71uX5kntZ7uADnH/fffjwMHDuDHH3/0dFc8rrCwEA899BA2btyI0NBQT3fHa+j1eowfPx5/+ctfAAAZGRk4cOAAXnvtNcyZM8fDvfOcDz/8EGvWrMH777+PESNGIC8vDw8//DBSUlICelyI6EKBPNdybpU4l0qcO4moI86RnCMBzpMqzpPkLMy09QMLFizAF198gW+//RZpaWmG+5OSktDS0oKqqiqz9mVlZUhKSjK06bhqpfpzd22ioqIQFhaGXr16ISgoyGIbdRvutHv3bpSXlyMzMxNarRZarRbfffcdXnrpJWi1WiQmJgbkuCQnJ2P48OFm9w0bNgynT58GYHxdXfU3KSkJ5eXlZo+3tbWhsrLSKWPniXF57LHHDN+Ejho1CrfffjseeeQRw7fkgTouprxpDKzpC3kPb/scdESgz7WcWyXOpRLnTsu86XVzvvQNnv5McxbOkZwjVZwnJc6TlnnT6/aVeZJBWx8mhMCCBQvwySef4JtvvkG/fv3MHh83bhyCg4OxadMmw30FBQU4ffo0srOzAQDZ2dnYv3+/2S/Fxo0bERUVZfiwzc7ONtuG2kbdRkhICMaNG2fWRq/XY9OmTYY27nTllVdi//79yMvLM1zGjx+P2bNnG24H4rhcdNFFKCgoMLvvyJEj6NOnDwCgX79+SEpKMutvTU0Ntm/fbjYuVVVV2L17t6HNN998A71ej6ysLEOb77//Hq2trYY2GzduxJAhQxAbG2to09XYuVNDQwM0GvOPwqCgIOj1egCBOy6mvGkMrOkLeQ9v+xy0B+daiXOrxLlU4txpmTe9bs6XvsHTn2mO4hwpcY404jwpcZ60zJtet8/Mkx5eCI0ccN9994no6GixefNmUVJSYrg0NDQY2syfP1/07t1bfPPNN2LXrl0iOztbZGdnGx5va2sTI0eOFFOnThV5eXliw4YNIj4+XixatMjQ5vjx4yI8PFw89thj4tChQ+KVV14RQUFBYsOGDYY2a9euFTqdTqxevVrk5+eLe+65R8TExJitfulJpqt3ChGY47Jjxw6h1WrFs88+K44ePSrWrFkjwsPDxXvvvWdos3z5chETEyM+++wz8dNPP4kbbrhB9OvXTzQ2NhraXH311SIjI0Ns375d/Pjjj2LQoEHitttuMzxeVVUlEhMTxe233y4OHDgg1q5dK8LDw8Xrr79uaLNlyxah1WrF3//+d3Ho0CGxZMkSERwcLPbv3++ewTAxZ84ckZqaKr744gtx4sQJkZOTI3r16iX++Mc/GtoEwrjU1taKvXv3ir179woA4vnnnxd79+4Vp06d8roxsKYv5D286XPQHpxrOxeIcyvnUimQ507Ol+Rs3vbZbgvOkZ0LxDlSCM6TKs6TnCedhUFbHwbA4mXVqlWGNo2NjeL3v/+9iI2NFeHh4WLGjBmipKTEbDsnT54U11xzjQgLCxO9evUSjz76qGhtbTVr8+2334qxY8eKkJAQ0b9/f7N9qF5++WXRu3dvERISIiZOnCi2bdvmipdtl46TZqCOy7/+9S8xcuRIodPpxNChQ8XKlSvNHtfr9eKpp54SiYmJQqfTiSuvvFIUFBSYtTl37py47bbbRGRkpIiKihJz584VtbW1Zm327dsnLr74YqHT6URqaqpYvnz5BX358MMPxeDBg0VISIgYMWKE+L//+z/nv2Ar1NTUiIceekj07t1bhIaGiv79+4snnnhCNDc3G9oEwrh8++23Fj9P5syZI4TwrjGwpi/kXbzpc9BWnGs7F6hzK+fSwJ47OV+SK3jTZ7stOEd2LlDnSCE4TwrBeZLzpPMoQgjh2lxeIiIiIiIiIiIiIrIWa9oSEREREREREREReREGbYmIiIiIiIiIiIi8CIO2RERERERERERERF6EQVsiIiIiIiIiIiIiL8KgLREREREREREREZEXYdCWiIiIiIiIiIiIyIswaEtERERERERERETkRRi0JSIiIiIiIiIiIvIiDNoSEREREREREREReREGbYkC2NmzZ3Hfffehd+/e0Ol0SEpKwrRp07BlyxYAgKIo+PTTTz3bSSIiIg/gHElERNQ5zpNErqf1dAeIyHNmzZqFlpYWvPPOO+jfvz/KysqwadMmnDt3ztNdIyIi8ijOkURERJ3jPEnkesy0JQpQVVVV+OGHH/DXv/4Vl19+Ofr06YOJEydi0aJFuP7669G3b18AwIwZM6AoiuFnAPjss8+QmZmJ0NBQ9O/fH0uXLkVbW5vhcUVRsGLFClxzzTUICwtD//798fHHHxseb2lpwYIFC5CcnIzQ0FD06dMHy5Ytc9dLJyIi6hLnSCIios5xniRyDwZtiQJUZGQkIiMj8emnn6K5ufmCx3fu3AkAWLVqFUpKSgw///DDD7jjjjvw0EMPIT8/H6+//jpWr16NZ5991uz5Tz31FGbNmoV9+/Zh9uzZuPXWW3Ho0CEAwEsvvYTPP/8cH374IQoKCrBmzRqziZyIiMiTOEcSERF1jvMkkXsoQgjh6U4QkWesX78e8+bNQ2NjIzIzM3HppZfi1ltvxejRowHIbzk/+eQTTJ8+3fCcKVOm4Morr8SiRYsM97333nv44x//iOLiYsPz5s+fjxUrVhjaTJo0CZmZmXj11Vfx4IMP4uDBg/j666+hKIp7XiwREZENOEcSERF1jvMkkesx05YogM2aNQvFxcX4/PPPcfXVV2Pz5s3IzMzE6tWrO33Ovn378PTTTxu+XY2MjMS8efNQUlKChoYGQ7vs7Gyz52VnZxu+Hb3zzjuRl5eHIUOG4MEHH8RXX33lktdHRERkL86RREREneM8SeR6DNoSBbjQ0FBcddVVeOqpp7B161bceeedWLJkSaft6+rqsHTpUuTl5Rku+/fvx9GjRxEaGmrVPjMzM3HixAn8+c9/RmNjI26++WbceOONznpJRERETsE5koiIqHOcJ4lci0FbIjIzfPhw1NfXAwCCg4PR3t5u9nhmZiYKCgowcODACy4ajfEjZdu2bWbP27ZtG4YNG2b4OSoqCrfccgveeOMNrFu3DuvXr0dlZaULXxkREZFjOEcSERF1jvMkkXNpPd0BIvKMc+fO4aabbsJdd92F0aNHo0ePHti1axeee+453HDDDQCAvn37YtOmTbjoooug0+kQGxuLxYsX47/+67/Qu3dv3HjjjdBoNNi3bx8OHDiAZ555xrD9jz76COPHj8fFF1+MNWvWYMeOHXjrrbcAAM8//zySk5ORkZEBjUaDjz76CElJSYiJifHEUBAREZnhHElERNQ5zpNEbiKIKCA1NTWJxx9/XGRmZoro6GgRHh4uhgwZIp588knR0NAghBDi888/FwMHDhRarVb06dPH8NwNGzaIyZMni7CwMBEVFSUmTpwoVq5caXgcgHjllVfEVVddJXQ6nejbt69Yt26d4fGVK1eKsWPHioiICBEVFSWuvPJKsWfPHre9diIioq5wjiQiIuoc50ki91CEEMLDcWMi8jOWVgolIiIizpFERERd4TxJZMSatkRERERERERERERehEFbIiIiIiIiIiIiIi/C8ghEREREREREREREXoSZtkRERERERERERERehEFbIiIiIiIiIiIiIi/CoC0RERERERERERGRF2HQloiIiIiIiIiIiMiLMGhLRERERERERERE5EUYtCUiIiIiIiIiIiLyIgzaEhEREREREREREXkRBm2JiIiIiIiIiIiIvAiDtkRERERERERERERe5P8D7uU93bfbn20AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Eval ep 0: steps=10000, final_dist=3.417, success=False\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Eval ep 0: steps=10000, final_dist=3.417, success=False\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Eval ep 1: steps=10000, final_dist=2.594, success=False\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Eval ep 1: steps=10000, final_dist=2.594, success=False\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Eval ep 2: steps=247, final_dist=0.449, success=True\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Eval ep 2: steps=247, final_dist=0.449, success=True\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# VISUALIZATION: Learning Curves by Maze Size\n",
        "# ============================================================================\n",
        "\n",
        "def plot_learning_curves_by_maze(\n",
        "    tier1_df, tier2_df, sac_df, tqc_df, tier3_df,\n",
        "    save_dir: str = \"./logs\"\n",
        "):\n",
        "    \"\"\"Plot learning curves grouped by maze size.\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(25, 10))\n",
        "    colors = plt.cm.Set2.colors\n",
        "\n",
        "    for row, maze_size in enumerate(['small', 'large']):\n",
        "        maze_name = MAZE_CONFIGS[maze_size]['name']\n",
        "\n",
        "        # Tier 1: DQN Dense\n",
        "        ax = axes[row, 0]\n",
        "        ax.set_title(f'{maze_name} - DQN (Dense)', fontsize=10)\n",
        "        if len(tier1_df) > 0:\n",
        "            subset = tier1_df[tier1_df['maze_size'] == maze_size]\n",
        "            if len(subset) > 0:\n",
        "                agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "                ax.plot(agg['timestep'], agg['mean'], color=colors[0], linewidth=2, label='DQN Dense')\n",
        "                ax.fill_between(agg['timestep'],\n",
        "                               agg['mean'] - agg['std'].fillna(0),\n",
        "                               agg['mean'] + agg['std'].fillna(0),\n",
        "                               color=colors[0], alpha=0.2)\n",
        "        ax.set_xlabel('Steps')\n",
        "        ax.set_ylabel('Success Rate')\n",
        "        ax.set_ylim(-0.05, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(fontsize=8)\n",
        "\n",
        "        # Tier 2: DQN +/- HER\n",
        "        ax = axes[row, 1]\n",
        "        ax.set_title(f'{maze_name} - DQN +/- HER', fontsize=10)\n",
        "        if len(tier2_df) > 0:\n",
        "            for j, use_her in enumerate([False, True]):\n",
        "                subset = tier2_df[(tier2_df['maze_size'] == maze_size) & (tier2_df['use_her'] == use_her)]\n",
        "                if len(subset) > 0:\n",
        "                    agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "                    label = 'DQN+HER' if use_her else 'DQN'\n",
        "                    ax.plot(agg['timestep'], agg['mean'], color=colors[j+1], linewidth=2, label=label)\n",
        "                    ax.fill_between(agg['timestep'],\n",
        "                                   agg['mean'] - agg['std'].fillna(0),\n",
        "                                   agg['mean'] + agg['std'].fillna(0),\n",
        "                                   color=colors[j+1], alpha=0.2)\n",
        "        ax.set_xlabel('Steps')\n",
        "        ax.set_ylabel('Success Rate')\n",
        "        ax.set_ylim(-0.05, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(fontsize=8)\n",
        "\n",
        "        # SAC +/- HER\n",
        "        ax = axes[row, 2]\n",
        "        ax.set_title(f'{maze_name} - SAC +/- HER', fontsize=10)\n",
        "        if len(sac_df) > 0:\n",
        "            for j, use_her in enumerate([False, True]):\n",
        "                subset = sac_df[(sac_df['maze_size'] == maze_size) & (sac_df['use_her'] == use_her)]\n",
        "                if len(subset) > 0:\n",
        "                    agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "                    label = 'SAC+HER' if use_her else 'SAC'\n",
        "                    ax.plot(agg['timestep'], agg['mean'], color=colors[j+3], linewidth=2, label=label)\n",
        "                    ax.fill_between(agg['timestep'],\n",
        "                                   agg['mean'] - agg['std'].fillna(0),\n",
        "                                   agg['mean'] + agg['std'].fillna(0),\n",
        "                                   color=colors[j+3], alpha=0.2)\n",
        "        ax.set_xlabel('Steps')\n",
        "        ax.set_ylabel('Success Rate')\n",
        "        ax.set_ylim(-0.05, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(fontsize=8)\n",
        "\n",
        "        # TQC +/- HER\n",
        "        ax = axes[row, 3]\n",
        "        ax.set_title(f'{maze_name} - TQC +/- HER', fontsize=10)\n",
        "        if len(tqc_df) > 0:\n",
        "            for j, use_her in enumerate([False, True]):\n",
        "                subset = tqc_df[(tqc_df['maze_size'] == maze_size) & (tqc_df['use_her'] == use_her)]\n",
        "                if len(subset) > 0:\n",
        "                    agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "                    label = 'TQC+HER' if use_her else 'TQC'\n",
        "                    ax.plot(agg['timestep'], agg['mean'], color=colors[j+5], linewidth=2, label=label)\n",
        "                    ax.fill_between(agg['timestep'],\n",
        "                                   agg['mean'] - agg['std'].fillna(0),\n",
        "                                   agg['mean'] + agg['std'].fillna(0),\n",
        "                                   color=colors[j+5], alpha=0.2)\n",
        "        ax.set_xlabel('Steps')\n",
        "        ax.set_ylabel('Success Rate')\n",
        "        ax.set_ylim(-0.05, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(fontsize=8)\n",
        "\n",
        "        # HAC +/- HER\n",
        "        ax = axes[row, 4]\n",
        "        ax.set_title(f'{maze_name} - HAC +/- HER', fontsize=10)\n",
        "        if len(tier3_df) > 0:\n",
        "            for j, use_her in enumerate([False, True]):\n",
        "                subset = tier3_df[(tier3_df['maze_size'] == maze_size) & (tier3_df['use_her'] == use_her)]\n",
        "                if len(subset) > 0:\n",
        "                    agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "                    label = 'HAC+HER' if use_her else 'HAC'\n",
        "                    ax.plot(agg['timestep'], agg['mean'], color=colors[(j+7) % len(colors)], linewidth=2, label=label)\n",
        "                    ax.fill_between(agg['timestep'],\n",
        "                                   agg['mean'] - agg['std'].fillna(0),\n",
        "                                   agg['mean'] + agg['std'].fillna(0),\n",
        "                                   color=colors[(j+7) % len(colors)], alpha=0.2)\n",
        "        ax.set_xlabel('Steps')\n",
        "        ax.set_ylabel('Success Rate')\n",
        "        ax.set_ylim(-0.05, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    plt.savefig(os.path.join(save_dir, 'learning_curves_all.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_all_methods_combined(all_dfs, maze_size, ax):\n",
        "    \"\"\"Plot all methods on one axis for direct comparison.\"\"\"\n",
        "    method_configs = [\n",
        "        (tier1_df, 'DQN Dense', False, 0),\n",
        "        (tier2_df, 'DQN+HER', True, 1),\n",
        "        (sac_df, 'SAC+HER', True, 2),\n",
        "        (tqc_df, 'TQC+HER', True, 3),\n",
        "        (tier3_df, 'HAC+HER', True, 4),\n",
        "    ]\n",
        "    # Plot only +HER variants for cleaner comparison\n",
        "    for df, label, filter_her, color_idx in method_configs:\n",
        "        if len(df) == 0:\n",
        "            continue\n",
        "        if filter_her:\n",
        "            subset = df[(df['maze_size'] == maze_size) & (df['use_her'] == True)]\n",
        "        else:\n",
        "            subset = df[df['maze_size'] == maze_size]\n",
        "        if len(subset) == 0:\n",
        "            continue\n",
        "        agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "        ax.plot(agg['timestep'], agg['mean'], linewidth=2, label=label)\n",
        "    ax.legend()\n",
        "    ax.set_title(f'{maze_size.title()} Maze - All Methods (+HER)')\n",
        "\n",
        "# Plot results\n",
        "plot_learning_curves_by_maze(tier1_df, tier2_df, sac_df, tqc_df, tier3_df, config.log_dir)"
      ],
      "metadata": {
        "id": "zStDrVoi5yt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# EXPERIMENT SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPERIMENT SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def print_final_metrics(df: pd.DataFrame, name: str, maze_size: str = None):\n",
        "    \"\"\"Print final metrics for a method.\"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        print(f\"\\n{name}: No data\")\n",
        "        return\n",
        "\n",
        "    if maze_size:\n",
        "        df = df[df['maze_size'] == maze_size]\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(f\"\\n{name}: No data for {maze_size} maze\")\n",
        "        return\n",
        "\n",
        "    final_timestep = df['timestep'].max()\n",
        "    final_data = df[df['timestep'] == final_timestep]\n",
        "\n",
        "    success_mean = final_data['success_rate'].mean()\n",
        "    success_std = final_data['success_rate'].std()\n",
        "    steps_mean = final_data['mean_steps'].mean()\n",
        "    efficiency_mean = final_data['mean_path_efficiency'].mean()\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Success Rate: {success_mean:.1%} ± {success_std:.1%}\" if not np.isnan(success_std) else f\"  Success Rate: {success_mean:.1%}\")\n",
        "    print(f\"  Mean Steps: {steps_mean:.1f}\")\n",
        "    print(f\"  Path Efficiency: {efficiency_mean:.2f}\")\n",
        "\n",
        "for maze_size in ['small', 'large']:\n",
        "    print(f\"\\n{'=' * 40}\")\n",
        "    print(f\"  {MAZE_CONFIGS[maze_size]['name']} MAZE\")\n",
        "    print(f\"{'=' * 40}\")\n",
        "\n",
        "    print_final_metrics(tier1_df, \"DQN (Dense Reward)\", maze_size)\n",
        "\n",
        "    if len(tier2_df) > 0:\n",
        "        no_her = tier2_df[tier2_df['use_her'] == False]\n",
        "        with_her = tier2_df[tier2_df['use_her'] == True]\n",
        "        print_final_metrics(no_her, \"DQN without HER (Sparse)\", maze_size)\n",
        "        print_final_metrics(with_her, \"DQN with HER (Sparse)\", maze_size)\n",
        "\n",
        "    if len(sac_df) > 0:\n",
        "        no_her = sac_df[sac_df['use_her'] == False]\n",
        "        with_her = sac_df[sac_df['use_her'] == True]\n",
        "        print_final_metrics(no_her, \"SAC without HER (Continuous)\", maze_size)\n",
        "        print_final_metrics(with_her, \"SAC with HER (Continuous)\", maze_size)\n",
        "\n",
        "    if len(tqc_df) > 0:\n",
        "        no_her = tqc_df[tqc_df['use_her'] == False]\n",
        "        with_her = tqc_df[tqc_df['use_her'] == True]\n",
        "        print_final_metrics(no_her, \"TQC without HER (Continuous)\", maze_size)\n",
        "        print_final_metrics(with_her, \"TQC with HER (Continuous)\", maze_size)\n",
        "\n",
        "    if len(tier3_df) > 0:\n",
        "        no_her = tier3_df[tier3_df['use_her'] == False]\n",
        "        with_her = tier3_df[tier3_df['use_her'] == True]\n",
        "        print_final_metrics(no_her, \"HAC without HER (Continuous)\", maze_size)\n",
        "        print_final_metrics(with_her, \"HAC with HER (Continuous)\", maze_size)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"KEY FINDINGS\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "1. DQN (Discrete Actions):\n",
        "   - Dense reward: Baseline with reward shaping\n",
        "   - Sparse + HER: Learns via hindsight relabeling\n",
        "\n",
        "2. SAC (Continuous Actions):\n",
        "   - Actor-critic with entropy regularization\n",
        "   - WITHOUT HER: Standard SAC on goal-conditioned task\n",
        "   - WITH HER: SAC + hindsight relabeling\n",
        "\n",
        "3. TQC (Continuous Actions):\n",
        "   - Extends SAC with distributional critics\n",
        "   - Truncated quantile estimation reduces overestimation\n",
        "   - Generally more stable than SAC\n",
        "\n",
        "4. HAC (Hierarchical, Continuous Actions):\n",
        "   - Two-level hierarchy: high-level subgoals + low-level actions\n",
        "   - WITHOUT HER: Hierarchical decomposition only\n",
        "   - WITH HER: Full HAC with HER for both levels\n",
        "\n",
        "EXPERIMENTAL NOTES:\n",
        "- DQN uses discrete actions via wrapper\n",
        "- SAC, TQC, HAC use native continuous actions\n",
        "- Small maze provides easier baseline for debugging\n",
        "- Large maze tests long-horizon planning capability\n",
        "\"\"\")\n",
        "\n",
        "# Save all results\n",
        "os.makedirs(config.log_dir, exist_ok=True)\n",
        "\n",
        "if len(tier1_df) > 0:\n",
        "    tier1_df.to_csv(os.path.join(config.log_dir, 'tier1_results.csv'), index=False)\n",
        "if len(tier2_df) > 0:\n",
        "    tier2_df.to_csv(os.path.join(config.log_dir, 'tier2_results.csv'), index=False)\n",
        "if len(sac_df) > 0:\n",
        "    sac_df.to_csv(os.path.join(config.log_dir, 'sac_results.csv'), index=False)\n",
        "if len(tqc_df) > 0:\n",
        "    tqc_df.to_csv(os.path.join(config.log_dir, 'tqc_results.csv'), index=False)\n",
        "if len(tier3_df) > 0:\n",
        "    tier3_df.to_csv(os.path.join(config.log_dir, 'tier3_results.csv'), index=False)\n",
        "\n",
        "print(f\"\\nAll results saved to: {config.log_dir}\")"
      ],
      "metadata": {
        "id": "VPxjRQpN50JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# COMPARISON PLOT: All Methods on Both Mazes\n",
        "# ============================================================================\n",
        "\n",
        "def plot_all_methods_comparison(tier1_df, tier2_df, sac_df, tqc_df, tier3_df, save_dir: str = \"./logs\"):\n",
        "    \"\"\"Create a comprehensive comparison plot of all methods.\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "    # Color scheme for all methods\n",
        "    colors = {\n",
        "        'DQN (Dense)': '#1f77b4',\n",
        "        'DQN (no HER)': '#aec7e8',\n",
        "        'DQN + HER': '#ff7f0e',\n",
        "        'SAC (no HER)': '#2ca02c',\n",
        "        'SAC + HER': '#98df8a',\n",
        "        'TQC (no HER)': '#d62728',\n",
        "        'TQC + HER': '#ff9896',\n",
        "        'HAC (no HER)': '#9467bd',\n",
        "        'HAC + HER': '#c5b0d5',\n",
        "    }\n",
        "\n",
        "    for idx, maze_size in enumerate(['small', 'large']):\n",
        "        ax = axes[idx]\n",
        "        maze_name = MAZE_CONFIGS[maze_size]['name']\n",
        "        ax.set_title(f'{maze_name} Maze - All Methods Comparison', fontsize=12)\n",
        "\n",
        "        # Define all methods to plot\n",
        "        methods_data = [\n",
        "            (tier1_df, None, 'DQN (Dense)'),\n",
        "            (tier2_df, False, 'DQN (no HER)'),\n",
        "            (tier2_df, True, 'DQN + HER'),\n",
        "            (sac_df, False, 'SAC (no HER)'),\n",
        "            (sac_df, True, 'SAC + HER'),\n",
        "            (tqc_df, False, 'TQC (no HER)'),\n",
        "            (tqc_df, True, 'TQC + HER'),\n",
        "            (tier3_df, False, 'HAC (no HER)'),\n",
        "            (tier3_df, True, 'HAC + HER'),\n",
        "        ]\n",
        "\n",
        "        for df, use_her, label in methods_data:\n",
        "            if df is None or len(df) == 0:\n",
        "                continue\n",
        "\n",
        "            subset = df[df['maze_size'] == maze_size]\n",
        "            if use_her is not None:\n",
        "                subset = subset[subset['use_her'] == use_her]\n",
        "\n",
        "            if len(subset) == 0:\n",
        "                continue\n",
        "\n",
        "            agg = subset.groupby('timestep')['success_rate'].agg(['mean', 'std']).reset_index()\n",
        "            color = colors.get(label, '#000000')\n",
        "            ax.plot(agg['timestep'], agg['mean'], color=color, linewidth=2, label=label)\n",
        "            ax.fill_between(agg['timestep'],\n",
        "                           agg['mean'] - agg['std'].fillna(0),\n",
        "                           agg['mean'] + agg['std'].fillna(0),\n",
        "                           color=color, alpha=0.15)\n",
        "\n",
        "        ax.set_xlabel('Training Steps', fontsize=11)\n",
        "        ax.set_ylabel('Success Rate', fontsize=11)\n",
        "        ax.set_ylim(-0.05, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='lower right', fontsize=9, ncol=2)\n",
        "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    plt.savefig(os.path.join(save_dir, 'all_methods_comparison.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot comparison\n",
        "plot_all_methods_comparison(tier1_df, tier2_df, sac_df, tqc_df, tier3_df, config.log_dir)"
      ],
      "metadata": {
        "id": "OGHz6ks351cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BCmZgEoqtTXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}